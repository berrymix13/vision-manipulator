## LLM to Json

import os, re
import json 
import openai
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
load_dotenv("/home/ros/llm_robot/.env")
openai.api_key = os.getenv("OPENAI_API_KEY")

PROMPT_PATH = "/home/ros/llm_robot/prompt/llm2yolo_json.txt"

def strip_codefence(text: str) -> str:
    """
    ```json\n{...}\n```  ë˜ëŠ”  ```\n{...}\n```  í˜•íƒœì—ì„œ {...} ë¶€ë¶„ë§Œ ëŒë ¤ì¤€ë‹¤.
    ì½”ë“œíœìŠ¤ê°€ ì—†ìœ¼ë©´ ì›ë¬¸ ê·¸ëŒ€ë¡œ ë°˜í™˜.
    """
    # ```json â€¦ ```  ë˜ëŠ”  ``` â€¦ ```
    m = re.search(r"```(?:json)?\s*(\{.*?\})\s*```", text, flags=re.S)
    return m.group(1) if m else text.strip()



# GPT-4oì—ê²Œ ì½”ë“œ ìš”ì²­
def parse_command(user_input: str) -> dict:
    """ ìì—°ì–´ ëª…ë ¹ì„ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜ """
    with open(PROMPT_PATH, "r", encoding="utf-8") as f:
        system_prompt = f.read()

    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_input}
        ],
        temperature=0.2,
        max_tokens=500
    )

    raw = response.choices[0].message.content
    json_str = strip_codefence(raw)

    try:
        return json.loads(json_str)
    except Exception as e:
        print("âŒ JSON íŒŒì‹± ì˜¤ë¥˜:", e)
        print("ğŸ“„ GPT ì‘ë‹µ ì›ë¬¸:\n", raw)
        return {}