#!/usr/bin/env python3
import cv2
import json
import time
import math
import numpy as np
import pyrealsense2 as rs
from datetime import datetime
from pathlib import Path
from typing import List, Tuple, Optional, Dict, Any
from pymycobot import MyCobot280
from camera import capture_d455_images, load_intrinsics


class CamToGripperCalibrator:
    """
    Cam-to-Gripper calibrationì„ ìˆ˜í–‰í•˜ëŠ” í´ë˜ìŠ¤
    
    ChArUco ë³´ë“œë¥¼ End-Effectorì— ê³ ì •í•˜ê³  ë‹¤ì–‘í•œ í¬ì¦ˆì—ì„œ ì´ë¯¸ì§€ë¥¼ ìº¡ì²˜í•˜ì—¬
    ì¹´ë©”ë¼ì™€ ë¡œë´‡ Gripper ê°„ì˜ ë³€í™˜ í–‰ë ¬ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, 
                 robot_port: str = "/dev/ttyACM0",
                 robot_baud: int = 115200,
                 save_dir: str = "/home/ros/llm_robot/data/Calibration/Cam-to-Gripper",
                 charuco_squares_x: int = 9,   # ê°€ë¡œ ì‚¬ê°í˜• ê°œìˆ˜ (columns)
                 charuco_squares_y: int = 6,   # ì„¸ë¡œ ì‚¬ê°í˜• ê°œìˆ˜ (rows)
                 charuco_square_length: float = 28.0,  # mm
                 charuco_marker_length: float = 21.0,  # mm
                 min_charuco_corners: int = 25,  # ìµœì†Œ ChArUco ì½”ë„ˆ ê°œìˆ˜
                 min_detection_confidence: float = 0.5,  # ìµœì†Œ ê²€ì¶œ ì‹ ë¢°ë„
                 max_distance_threshold: float = 0.7):  # ìµœëŒ€ ê±°ë¦¬ ì„ê³„ê°’ (ë¯¸í„°)
        """
        Cam-to-Gripper calibration ì´ˆê¸°í™”
        
        Args:
            robot_port: ë¡œë´‡ ì‹œë¦¬ì–¼ í¬íŠ¸
            robot_baud: ë¡œë´‡ í†µì‹  ë³´ë“œë ˆì´íŠ¸
            save_dir: ìº¡ì²˜ëœ ì´ë¯¸ì§€ì™€ í¬ì¦ˆ ë°ì´í„° ì €ì¥ ë””ë ‰í† ë¦¬
            charuco_squares_x: ChArUco ë³´ë“œ ê°€ë¡œ ì‚¬ê°í˜• ê°œìˆ˜
            charuco_squares_y: ChArUco ë³´ë“œ ì„¸ë¡œ ì‚¬ê°í˜• ê°œìˆ˜
            charuco_square_length: ChArUco ì‚¬ê°í˜• í•œ ë³€ì˜ ê¸¸ì´ (mm)
            charuco_marker_length: ChArUco ë§ˆì»¤ í•œ ë³€ì˜ ê¸¸ì´ (mm)
        """
        self.robot_port = robot_port
        self.robot_baud = robot_baud
        self.save_dir = Path(save_dir)
        self.poses_dir = self.save_dir / "poses"
        self.angles_dir = self.save_dir / "angles"
        
        # ChArUco ë³´ë“œ íŒŒë¼ë¯¸í„°
        self.charuco_squares_x = charuco_squares_x
        self.charuco_squares_y = charuco_squares_y
        self.charuco_square_length = charuco_square_length  # mm ë‹¨ìœ„ ìœ ì§€
        self.charuco_marker_length = charuco_marker_length  # mm ë‹¨ìœ„ ìœ ì§€
        
        # ì´ìƒì¹˜ ì²˜ë¦¬ íŒŒë¼ë¯¸í„°
        self.min_charuco_corners = min_charuco_corners
        self.min_detection_confidence = min_detection_confidence
        self.max_distance_threshold = max_distance_threshold
        
        # ChArUco ë”•ì…”ë„ˆë¦¬ ë° ë³´ë“œ ìƒì„±
        self.aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)
        self.charuco_board = cv2.aruco.CharucoBoard(
            size=(charuco_squares_x, charuco_squares_y),  # (ê°€ë¡œ, ì„¸ë¡œ) ìˆœì„œë¡œ ìˆ˜ì •
            squareLength=self.charuco_square_length / 1000.0,  # mmë¥¼ më¡œ ë³€í™˜
            markerLength=self.charuco_marker_length / 1000.0,  # mmë¥¼ më¡œ ë³€í™˜
            dictionary=self.aruco_dict
        )
        
        # ë¡œë´‡ ì—°ê²°
        self.robot = MyCobot280(robot_port, robot_baud)
        
        # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.save_dir.mkdir(parents=True, exist_ok=True)
        self.poses_dir.mkdir(parents=True, exist_ok=True)
        self.angles_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"Cam-to-Gripper Calibrator ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"ChArUco í¬ê¸°: {charuco_squares_x}x{charuco_squares_y}")
        print(f"ì‚¬ê°í˜• ê¸¸ì´: {charuco_square_length:.1f}mm")
        print(f"ë§ˆì»¤ ê¸¸ì´: {charuco_marker_length:.1f}mm")
        print(f"Cam-to-Gripper calibration ëª¨ë“œ")
        print(f"ì´ìƒì¹˜ ì²˜ë¦¬ íŒŒë¼ë¯¸í„°:")
        print(f"  - ìµœì†Œ ChArUco ì½”ë„ˆ: {min_charuco_corners}ê°œ")
        print(f"  - ìµœì†Œ ê²€ì¶œ ì‹ ë¢°ë„: {min_detection_confidence}")
        print(f"  - ìµœëŒ€ ê±°ë¦¬ ì„ê³„ê°’: {max_distance_threshold}m")
        print(f"ì¢Œí‘œì¶• ë³€í™˜:")
        print(f"  - ì¹´ë©”ë¼ Zì¶• â†’ ë¡œë´‡ Xì¶•")
        print(f"  - ì¹´ë©”ë¼ -Xì¶• â†’ ë¡œë´‡ Yì¶•")
        print(f"  - ì¹´ë©”ë¼ -Yì¶• â†’ ë¡œë´‡ Zì¶•")
    
    def _load_camera_intrinsics(self, intrinsics_path: str) -> Tuple[np.ndarray, np.ndarray]:
        """
        ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
        
        Args:
            intrinsics_path: ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„° JSON íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Tuple[np.ndarray, np.ndarray]: (camera_matrix, dist_coeffs)
        """
        try:
            camera_matrix, dist_coeffs = load_intrinsics(intrinsics_path)
            print(f"ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„° ë¡œë“œ ì™„ë£Œ: {intrinsics_path}")
            return camera_matrix, dist_coeffs
        except Exception as e:
            print(f"ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ì¹´ë©”ë¼ í–‰ë ¬ ì‚¬ìš© (RealSense D455 848x480 í•´ìƒë„ìš©)
            # ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸° (1280x800 í•´ìƒë„ìš©)
            camera_matrix = np.array([
                [642.947,   0.0,     644.808],
                [0.0,       642.073, 409.050],
                [0.0,       0.0,     1.0]
            ], dtype=np.float64)
            
            # ì™œê³¡ ê³„ìˆ˜ (k1, k2, p1, p2, k3)
            dist_coeffs = np.array([
                -0.05594644322991371,
                0.06878077983856201,
                -0.00011232726683374494,
                0.000743341923225671,
                -0.022005939856171608
            ], dtype=np.float64)
            return camera_matrix, dist_coeffs
    


    def detect_charuco_pose(self, image: np.ndarray, camera_matrix: np.ndarray, dist_coeffs: np.ndarray) -> Optional[Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]]:
        """
        ì´ë¯¸ì§€ì—ì„œ ChArUco ë³´ë“œì˜ í¬ì¦ˆë¥¼ ê²€ì¶œí•©ë‹ˆë‹¤.
        ChArUco ì½”ë„ˆ ê¸°ë°˜ pose ì¶”ì • ì‹¤íŒ¨ ì‹œ ArUco ë§ˆì»¤ ê¸°ë°˜ fallback ì „ëµ ì‚¬ìš©
        """
        # ì›ë³¸ ì´ë¯¸ì§€
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ (ëŒ€ë¹„ í–¥ìƒ)
        # 1. CLAHEë¡œ ëŒ€ë¹„ í–¥ìƒ (clipLimit ì¦ê°€)
        clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8,8))
        gray_enhanced = clahe.apply(gray)
        
        # ë³´ë“œ ì„¤ì • ì •ë³´ ì¶œë ¥
        print(f"\rDEBUG: Board config - size: ({self.charuco_squares_x}, {self.charuco_squares_y}), square_length: {self.charuco_square_length*1000:.1f}mm, marker_length: {self.charuco_marker_length*1000:.1f}mm", end="")
        
        # ë‹¨ìœ„ ë³€í™˜: mm -> meter (í•¨ìˆ˜ ì‹œì‘ ë¶€ë¶„ì—ì„œ ì •ì˜)
        square_length_m = self.charuco_square_length * 0.001  # mm -> m
        marker_length_m = self.charuco_marker_length * 0.001  # mm -> m
        
        # 1. ChArUco ì½”ë„ˆ ê¸°ë°˜ pose ì¶”ì • ì‹œë„
        charuco_params = cv2.aruco.CharucoParameters()
        charuco_params.minMarkers = 1
        charuco_params.tryRefineMarkers = True
        
        charuco_detector = cv2.aruco.CharucoDetector(self.charuco_board, charuco_params)
        
        # ì›ë³¸ ì´ë¯¸ì§€ë¡œ ì‹œë„
        charuco_corners, charuco_ids, marker_corners, marker_ids = charuco_detector.detectBoard(gray)
        print(f"\rDEBUG: Original image - ChArUco corners: {len(charuco_corners) if charuco_corners is not None else 0}, IDs: {len(charuco_ids) if charuco_ids is not None else 0}, markers: {len(marker_corners) if marker_corners is not None else 0}", end="")
        
        # ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë¡œ ì‹œë„
        if charuco_corners is None or len(charuco_corners) == 0:
            charuco_corners, charuco_ids, marker_corners, marker_ids = charuco_detector.detectBoard(gray_enhanced)
            print(f"\rDEBUG: Enhanced image - ChArUco corners: {len(charuco_corners) if charuco_corners is not None else 0}, IDs: {len(charuco_ids) if charuco_ids is not None else 0}, markers: {len(marker_corners) if marker_corners is not None else 0}", end="")
        
        # ChArUco ì½”ë„ˆ ê¸°ë°˜ pose ì¶”ì • ì„±ê³µ ì‹œ
        if (charuco_corners is not None and charuco_ids is not None and
            len(charuco_corners) > 2 and len(charuco_corners) == len(charuco_ids)):
            
            print(f"\rDEBUG: ChArUco corners detected: {len(charuco_corners)}, proceeding with corner-based pose estimation", end="")
            
            # ChArUco ë³´ë“œì˜ 3D ì ë“¤ ìƒì„± (ë³´ë“œ ì¢Œí‘œê³„, ë¯¸í„° ë‹¨ìœ„)
            board_points_3d = []
            for i in range(self.charuco_squares_y - 1):
                for j in range(self.charuco_squares_x - 1):
                    x = j * square_length_m  # ë¯¸í„° ë‹¨ìœ„
                    y = i * square_length_m  # ë¯¸í„° ë‹¨ìœ„
                    board_points_3d.append([x, y, 0])
            
            board_points_3d = np.array(board_points_3d, dtype=np.float32)
            
            # ê²€ì¶œëœ ì½”ë„ˆì— í•´ë‹¹í•˜ëŠ” 3D ì ë“¤ë§Œ ì„ íƒ
            detected_points_3d = []
            detected_points_2d = []
            
            for i, corner_id in enumerate(charuco_ids):
                if corner_id < len(board_points_3d):
                    detected_points_3d.append(board_points_3d[corner_id])
                    detected_points_2d.append(charuco_corners[i])
            
            if len(detected_points_3d) >= 4:
                detected_points_3d = np.array(detected_points_3d, dtype=np.float32)
                detected_points_2d = np.array(detected_points_2d, dtype=np.float32)
                
                # solvePnPë¡œ í¬ì¦ˆ ì¶”ì •
                ret, rvec, tvec = cv2.solvePnP(
                    detected_points_3d, detected_points_2d,
                    camera_matrix, dist_coeffs,
                    flags=cv2.SOLVEPNP_ITERATIVE
                )
                
                if ret:
                    print(f"\rDEBUG: ChArUco corner-based pose estimation successful", end="")
                    return rvec, tvec, charuco_corners, charuco_ids
        
        # 2. ChArUco ì½”ë„ˆ ê¸°ë°˜ pose ì¶”ì • ì‹¤íŒ¨ ì‹œ ArUco ë§ˆì»¤ ê¸°ë°˜ fallback ì „ëµ
        print(f"\rDEBUG: ChArUco corner-based pose estimation failed, trying ArUco marker-based fallback", end="")
        
        # ArUco ë§ˆì»¤ ê²€ì¶œ (ì™„í™”ëœ íŒŒë¼ë¯¸í„° ì‚¬ìš©)
        try:
            aruco_params = cv2.aruco.DetectorParameters()
            aruco_params.adaptiveThreshWinSizeMin = 3
            aruco_params.adaptiveThreshWinSizeMax = 23
            aruco_params.adaptiveThreshWinSizeStep = 10
            aruco_params.adaptiveThreshConstant = 7
            aruco_params.minMarkerPerimeterRate = 0.003  # ë§¤ìš° ì™„í™”ëœ íŒŒë¼ë¯¸í„°
            aruco_params.maxMarkerPerimeterRate = 4.0
            aruco_params.polygonalApproxAccuracyRate = 0.05
            aruco_params.minCornerDistanceRate = 0.003
            aruco_params.minMarkerDistanceRate = 0.003
            aruco_params.minDistanceToBorder = 1
            aruco_params.minOtsuStdDev = 2.0
            aruco_params.perspectiveRemovePixelPerCell = 4
            aruco_params.perspectiveRemoveIgnoredMarginPerCell = 0.13
            aruco_params.maxErroneousBitsInBorderRate = 0.35
            aruco_params.errorCorrectionRate = 0.6
            
            aruco_detector = cv2.aruco.ArucoDetector(self.aruco_dict, aruco_params)
            corners, ids, rejected = aruco_detector.detectMarkers(gray_enhanced)
        except AttributeError:
            # OpenCV 4.4 ì´í•˜ ë²„ì „
            aruco_params = cv2.aruco.DetectorParameters_create()
            aruco_params.adaptiveThreshWinSizeMin = 3
            aruco_params.adaptiveThreshWinSizeMax = 23
            aruco_params.adaptiveThreshWinSizeStep = 10
            aruco_params.adaptiveThreshConstant = 7
            aruco_params.minMarkerPerimeterRate = 0.003
            aruco_params.maxMarkerPerimeterRate = 4.0
            aruco_params.polygonalApproxAccuracyRate = 0.05
            aruco_params.minCornerDistanceRate = 0.003
            aruco_params.minMarkerDistanceRate = 0.003
            aruco_params.minDistanceToBorder = 1
            aruco_params.minOtsuStdDev = 2.0
            aruco_params.perspectiveRemovePixelPerCell = 4
            aruco_params.perspectiveRemoveIgnoredMarginPerCell = 0.13
            aruco_params.maxErroneousBitsInBorderRate = 0.35
            aruco_params.errorCorrectionRate = 0.6
            
            corners, ids, rejected = cv2.aruco.detectMarkers(gray_enhanced, self.aruco_dict, parameters=aruco_params)
        
        # ArUco ë§ˆì»¤ ê²€ì¶œ ê²°ê³¼ í™•ì¸
        if ids is not None and len(ids) >= 10:  # ìµœì†Œ 10ê°œ ë§ˆì»¤ í•„ìš”
            print(f"\rDEBUG: ArUco markers detected: {len(ids)}, proceeding with marker-based pose estimation", end="")
            
            # ArUco ë§ˆì»¤ì˜ 3D ì ë“¤ ìƒì„± (ë³´ë“œ ì¢Œí‘œê³„, ë¯¸í„° ë‹¨ìœ„)
            marker_points_3d = []
            marker_points_2d = []
            
            for i, marker_id in enumerate(ids):
                marker_id = marker_id[0]  # idsëŠ” 2D ë°°ì—´
                
                # ë§ˆì»¤ì˜ 4ê°œ ì½”ë„ˆë¥¼ 3D ì ìœ¼ë¡œ ë³€í™˜
                # ë§ˆì»¤ì˜ ì¤‘ì‹¬ ìœ„ì¹˜ ê³„ì‚° (ë³´ë“œ ì¢Œí‘œê³„)
                marker_row = marker_id // (self.charuco_squares_x - 1)
                marker_col = marker_id % (self.charuco_squares_x - 1)
                
                # ë§ˆì»¤ ì¤‘ì‹¬ì˜ 3D ì¢Œí‘œ (ë¯¸í„° ë‹¨ìœ„)
                center_x = marker_col * square_length_m  # ë¯¸í„° ë‹¨ìœ„
                center_y = marker_row * square_length_m  # ë¯¸í„° ë‹¨ìœ„
                
                # ë§ˆì»¤ì˜ 4ê°œ ì½”ë„ˆë¥¼ 3D ì ìœ¼ë¡œ ìƒì„± (ë¯¸í„° ë‹¨ìœ„)
                half_marker = marker_length_m / 2  # ë¯¸í„° ë‹¨ìœ„
                marker_corners_3d = [
                    [center_x - half_marker, center_y - half_marker, 0],  # ì¢Œìƒë‹¨
                    [center_x + half_marker, center_y - half_marker, 0],  # ìš°ìƒë‹¨
                    [center_x + half_marker, center_y + half_marker, 0],  # ìš°í•˜ë‹¨
                    [center_x - half_marker, center_y + half_marker, 0]   # ì¢Œí•˜ë‹¨
                ]
                
                # 2D ì½”ë„ˆ ì ë“¤
                marker_corners_2d = corners[i][0]  # corners[i]ëŠ” 4x2 ë°°ì—´
                
                # 3D-2D ë§¤í•‘ì— ì¶”ê°€
                marker_points_3d.extend(marker_corners_3d)
                marker_points_2d.extend(marker_corners_2d)
            
            if len(marker_points_3d) >= 12:  # ìµœì†Œ 3ê°œ ë§ˆì»¤ (3*4=12ê°œ ì )
                marker_points_3d = np.array(marker_points_3d, dtype=np.float32)
                marker_points_2d = np.array(marker_points_2d, dtype=np.float32)
                
                # solvePnPë¡œ í¬ì¦ˆ ì¶”ì •
                ret, rvec, tvec = cv2.solvePnP(
                    marker_points_3d, marker_points_2d,
                    camera_matrix, dist_coeffs,
                    flags=cv2.SOLVEPNP_ITERATIVE
                )
                
                if ret:
                    print(f"\rDEBUG: ArUco marker-based pose estimation successful with {len(ids)} markers", end="")
                    
                    # ArUco ë§ˆì»¤ ê¸°ë°˜ ê²°ê³¼ë¥¼ charuco_corners í˜•íƒœë¡œ ë³€í™˜
                    # ë§ˆì»¤ ì¤‘ì‹¬ì ë“¤ì„ charuco_cornersë¡œ ì‚¬ìš©
                    charuco_corners_from_markers = []
                    charuco_ids_from_markers = []
                    
                    for i, marker_id in enumerate(ids):
                        marker_id = marker_id[0]  # idsëŠ” 2D ë°°ì—´
                        marker_corners = corners[i][0]  # 4x2 ë°°ì—´
                        
                        # ë§ˆì»¤ì˜ ì¤‘ì‹¬ì  ê³„ì‚°
                        center_2d = np.mean(marker_corners, axis=0)
                        charuco_corners_from_markers.append(center_2d)
                        charuco_ids_from_markers.append(marker_id)
                    
                    charuco_corners_from_markers = np.array(charuco_corners_from_markers, dtype=np.float32)
                    charuco_ids_from_markers = np.array(charuco_ids_from_markers, dtype=np.int32)
                    
                    # ArUco ë§ˆì»¤ ê¸°ë°˜ ê²°ê³¼ë¥¼ ë°˜í™˜ (charuco_corners í˜•íƒœë¡œ ë³€í™˜)
                    return rvec, tvec, charuco_corners_from_markers, charuco_ids_from_markers
                else:
                    print(f"\rDEBUG: ArUco marker-based pose estimation failed", end="")
            else:
                print(f"\rDEBUG: Not enough 3D-2D correspondences for ArUco markers ({len(marker_points_3d)} < 12)", end="")
        else:
            print(f"\rDEBUG: Not enough ArUco markers detected ({len(ids) if ids is not None else 0} < 10)", end="")
        
        return None
    
    def get_robot_pose(self) -> Tuple[np.ndarray, np.ndarray]:
        """
        í˜„ì¬ ë¡œë´‡ì˜ í¬ì¦ˆë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Returns:
            Tuple[np.ndarray, np.ndarray]: (R_base2ee, t_base2ee) - ë¯¸í„° ë‹¨ìœ„
        """
        coords = self.robot.get_coords()  # [X, Y, Z, Rx, Ry, Rz] (mm, degree)
        
        # ìœ„ì¹˜ (mmë¥¼ ë¯¸í„°ë¡œ ë³€í™˜)
        position = np.array(coords[0:3]) / 1000.0  # mm -> m
        
        # íšŒì „ (ë„ë¥¼ ë¼ë””ì•ˆìœ¼ë¡œ ë³€í™˜ í›„ íšŒì „ í–‰ë ¬ ê³„ì‚°)
        rx, ry, rz = np.radians(coords[3:6])  # degree -> radian
        R_base2ee = self._euler_to_rotation_matrix(rx, ry, rz)
        
        return R_base2ee, position.reshape(3, 1)
    
    def get_robot_angles(self) -> List[float]:
        """
        í˜„ì¬ ë¡œë´‡ì˜ ê°ë„ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Returns:
            List[float]: 6ê°œ ì¡°ì¸íŠ¸ì˜ ê°ë„ (ë„)
        """
        return self.robot.get_angles()
    
    def evaluate_charuco_quality(self, charuco_corners: np.ndarray, charuco_ids: np.ndarray, 
                                rvec: np.ndarray, tvec: np.ndarray) -> Tuple[bool, str, float]:
        """
        ChArUco ê²€ì¶œ í’ˆì§ˆì„ í‰ê°€í•©ë‹ˆë‹¤.
        
        Args:
            charuco_corners: ê²€ì¶œëœ ChArUco ì½”ë„ˆ
            charuco_ids: ê²€ì¶œëœ ChArUco ID
            rvec: íšŒì „ ë²¡í„°
            tvec: ë³€ìœ„ ë²¡í„°
            
        Returns:
            Tuple[bool, str, float]: (í’ˆì§ˆ í†µê³¼ ì—¬ë¶€, í‰ê°€ ë©”ì‹œì§€, í’ˆì§ˆ ì ìˆ˜)
        """
        quality_score = 0.0
        issues = []
        
        # 1. ì½”ë„ˆ ê°œìˆ˜ ê²€ì‚¬ (ì•ˆì „í•œ ì²˜ë¦¬)
        corner_count = len(charuco_corners) if charuco_corners is not None else 0
        print(f"\rDEBUG: Evaluating quality - corners: {corner_count}, min_required: {self.min_charuco_corners}", end="")
        
        if charuco_corners is None or corner_count < self.min_charuco_corners:
            issues.append(f"ì½”ë„ˆ ê°œìˆ˜ ë¶€ì¡± ({corner_count}/{self.min_charuco_corners})")
            quality_score -= 0.1
            print(f"\rDEBUG: Corner count penalty applied, score: {quality_score:.2f}", end="")
        else:
            corner_ratio = corner_count / ((self.charuco_squares_x - 1) * (self.charuco_squares_y - 1))
            quality_score += corner_ratio * 0.6
            print(f"\rDEBUG: Corner ratio: {corner_ratio:.2f}, score: {quality_score:.2f}", end="")
        
        # 2. ê±°ë¦¬ ê²€ì‚¬
        distance = np.linalg.norm(tvec)
        if distance > self.max_distance_threshold:
            issues.append(f"ê±°ë¦¬ ë„ˆë¬´ ë©€ìŒ ({distance*1000:.1f}mm > {self.max_distance_threshold*1000:.1f}mm)")
            quality_score -= 0.2
        elif distance < 0.15:
            issues.append(f"ê±°ë¦¬ ë„ˆë¬´ ê°€ê¹Œì›€ ({distance*1000:.1f}mm < 150mm)")
            quality_score -= 0.1
        elif distance > 0.6:
            issues.append(f"ê±°ë¦¬ ë„ˆë¬´ ë©€ìŒ ({distance*1000:.1f}mm > 500mm)")
            quality_score -= 0.2
        else:
            distance_score = 1.0 - (distance - 0.15) / (0.5 - 0.15)
            quality_score += distance_score * 0.3
        
        # 3. íšŒì „ ê°ë„ ê²€ì‚¬
        rotation_matrix, _ = cv2.Rodrigues(rvec)
        z_axis = np.array([0, 0, 1])
        camera_z = rotation_matrix @ z_axis
        angle_with_z = np.arccos(np.clip(np.abs(np.dot(camera_z, z_axis)), 0, 1))
        angle_degrees = np.degrees(angle_with_z)
        
        if angle_degrees > 75:
            issues.append(f"ê°ë„ ë„ˆë¬´ ê·¹ë‹¨ì  ({angle_degrees:.1f}ë„)")
            quality_score -= 0.1
        else:
            angle_score = 1.0 - (angle_degrees / 75.0)
            quality_score += angle_score * 0.2
        
        # 4. ì½”ë„ˆ ë¶„í¬ ê²€ì‚¬ (ì•ˆì „í•œ ì²˜ë¦¬)
        if charuco_corners is not None and corner_count > 0:
            try:
                corners_array = np.array(charuco_corners).reshape(-1, 2)
                std_x = np.std(corners_array[:, 0])
                std_y = np.std(corners_array[:, 1])
                
                if std_x < 30 or std_y < 30:
                    issues.append("ì½”ë„ˆ ë¶„í¬ ì§‘ì¤‘ë¨")
                    quality_score -= 0.05
            except Exception as e:
                print(f"\rDEBUG: Corner distribution calculation failed: {e}", end="")
        
        # 5. ê¸°ë³¸ ì ìˆ˜
        quality_score += 0.3
        print(f"\rDEBUG: Base score added, final score: {quality_score:.2f}", end="")
        
        # ìµœì¢… í’ˆì§ˆ í‰ê°€
        is_good_quality = quality_score >= self.min_detection_confidence
        
        if is_good_quality:
            message = f"í’ˆì§ˆ ì–‘í˜¸ (ì ìˆ˜: {quality_score:.2f})"
        else:
            message = f"í’ˆì§ˆ ë¶ˆëŸ‰ (ì ìˆ˜: {quality_score:.2f}) - {'; '.join(issues)}"
        
        print(f"\rDEBUG: Final quality: {quality_score:.2f}, threshold: {self.min_detection_confidence}, good: {is_good_quality}", end="")
        return is_good_quality, message, quality_score
    
    def _euler_to_rotation_matrix(self, rx: float, ry: float, rz: float) -> np.ndarray:
        """
        ì˜¤ì¼ëŸ¬ ê°ë„(RPY)ë¥¼ íšŒì „ í–‰ë ¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            rx: Xì¶• íšŒì „ (ë¼ë””ì•ˆ)
            ry: Yì¶• íšŒì „ (ë¼ë””ì•ˆ)
            rz: Zì¶• íšŒì „ (ë¼ë””ì•ˆ)
            
        Returns:
            np.ndarray: 3x3 íšŒì „ í–‰ë ¬
        """
        # ê° ì¶•ì— ëŒ€í•œ íšŒì „ í–‰ë ¬
        Rx = np.array([
            [1, 0, 0],
            [0, np.cos(rx), -np.sin(rx)],
            [0, np.sin(rx), np.cos(rx)]
        ])
        
        Ry = np.array([
            [np.cos(ry), 0, np.sin(ry)],
            [0, 1, 0],
            [-np.sin(ry), 0, np.cos(ry)]
        ])
        
        Rz = np.array([
            [np.cos(rz), -np.sin(rz), 0],
            [np.sin(rz), np.cos(rz), 0],
            [0, 0, 1]
        ])
        
        # ZYX ìˆœì„œë¡œ íšŒì „ í–‰ë ¬ ê³±ì…ˆ
        return Rz @ Ry @ Rx
    
    def collect_angles_realtime(self, num_poses: int = 20) -> bool:
        """
        ì‹¤ì‹œê°„ìœ¼ë¡œ ë¡œë´‡ ê°ë„ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        
        Args:
            num_poses: ìˆ˜ì§‘í•  í¬ì¦ˆ ê°œìˆ˜
            
        Returns:
            bool: ìˆ˜ì§‘ ì„±ê³µ ì—¬ë¶€
        """
        print(f"\n=== ì‹¤ì‹œê°„ ê°ë„ ìˆ˜ì§‘ ëª¨ë“œ ===")
        print(f"ìˆ˜ì§‘í•  í¬ì¦ˆ ìˆ˜: {num_poses}")
        print("ë¡œë´‡ì„ ìˆ˜ë™ìœ¼ë¡œ ì¡°ì‘í•˜ì—¬ ë‹¤ì–‘í•œ í¬ì¦ˆì˜ ê°ë„ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
        print("ê° í¬ì¦ˆì—ì„œ Enterë¥¼ ëˆŒëŸ¬ ì €ì¥í•˜ê±°ë‚˜ 'q'ë¥¼ ëˆŒëŸ¬ ì¢…ë£Œí•˜ì„¸ìš”.")
        print("í˜„ì¬ í¬ì¦ˆ ì •ë³´ê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.")
        
        collected_poses = 0
        pose_index = 0
        
        while collected_poses < num_poses:
            try:
                # í˜„ì¬ ê°ë„ ê°€ì ¸ì˜¤ê¸°
                angles = self.get_robot_angles()
                coords = self.robot.get_coords()
                
                # ì‹¤ì‹œê°„ ì •ë³´ ì¶œë ¥
                print(f"\n{'='*50}")
                print(f"=== ì‹¤ì‹œê°„ ê°ë„ ìˆ˜ì§‘ ëª¨ë“œ ===")
                print(f"ìˆ˜ì§‘í•  í¬ì¦ˆ ìˆ˜: {num_poses}")
                print(f"í˜„ì¬ ìˆ˜ì§‘ëœ í¬ì¦ˆ: {collected_poses}")
                print(f"í˜„ì¬ í¬ì¦ˆ ì¸ë±ìŠ¤: {pose_index}")
                print(f"\ní˜„ì¬ ë¡œë´‡ ìƒíƒœ:")
                print(f"  ê°ë„: [{angles[0]:.1f}, {angles[1]:.1f}, {angles[2]:.1f}, "
                      f"{angles[3]:.1f}, {angles[4]:.1f}, {angles[5]:.1f}]")
                print(f"  ì¢Œí‘œ: [{coords[0]:.1f}, {coords[1]:.1f}, {coords[2]:.1f}]")
                print(f"\nì¡°ì‘ë²•:")
                print(f"  - Enter: í˜„ì¬ í¬ì¦ˆ ì €ì¥")
                print(f"  - q: ì¢…ë£Œ")
                print(f"  - Ctrl+C: ê°•ì œ ì¢…ë£Œ")
                print(f"{'='*50}")
                
                # ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸°
                user_input = input("\nëª…ë ¹ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip().lower()
                
                if user_input == 'q':
                    print(f"\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ì§‘ëœ í¬ì¦ˆ: {collected_poses}")
                    break
                elif user_input == '' or user_input == 's':
                    # í˜„ì¬ í¬ì¦ˆ ì €ì¥
                    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
                    
                    angle_data = {
                        "angles": angles,
                        "coords": coords,
                        "pose_index": pose_index,
                        "timestamp": timestamp
                    }
                    
                    angle_path = self.angles_dir / f"{pose_index:02d}_{timestamp}_angles.json"
                    with open(angle_path, 'w') as f:
                        json.dump(angle_data, f, indent=2)
                    
                    print(f"\nâœ… í¬ì¦ˆ {pose_index} ì €ì¥ ì™„ë£Œ: {angle_path}")
                    collected_poses += 1
                    pose_index += 1
                    
                    # ì ì‹œ ëŒ€ê¸° í›„ ê³„ì†
                    input("ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
                
            except KeyboardInterrupt:
                print(f"\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ì§‘ëœ í¬ì¦ˆ: {collected_poses}")
                break
            except Exception as e:
                print(f"\nì˜¤ë¥˜ ë°œìƒ: {e}")
                input("ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
                continue
        
        print(f"\n=== ì‹¤ì‹œê°„ ê°ë„ ìˆ˜ì§‘ ì™„ë£Œ ===")
        print(f"ì´ {collected_poses}ê°œì˜ í¬ì¦ˆ ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return collected_poses >= 10  # ìµœì†Œ 10ê°œ ì´ìƒ í•„ìš”
    
    def collect_angles_realtime_simple(self, num_poses: int = 20) -> bool:
        """
        ê°„ë‹¨í•œ ì‹¤ì‹œê°„ ê°ë„ ìˆ˜ì§‘ ëª¨ë“œ (ë” ì•ˆì •ì ì¸ ë²„ì „)
        
        Args:
            num_poses: ìˆ˜ì§‘í•  í¬ì¦ˆ ê°œìˆ˜
            
        Returns:
            bool: ìˆ˜ì§‘ ì„±ê³µ ì—¬ë¶€
        """
        print(f"\n=== ì‹¤ì‹œê°„ ê°ë„ ìˆ˜ì§‘ ëª¨ë“œ (ê°„ë‹¨ ë²„ì „) ===")
        print(f"ìˆ˜ì§‘í•  í¬ì¦ˆ ìˆ˜: {num_poses}")
        print("ë¡œë´‡ì„ ìˆ˜ë™ìœ¼ë¡œ ì¡°ì‘í•˜ì—¬ ë‹¤ì–‘í•œ í¬ì¦ˆì˜ ê°ë„ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
        print("ê° í¬ì¦ˆì—ì„œ Enterë¥¼ ëˆŒëŸ¬ ì €ì¥í•˜ê±°ë‚˜ 'q'ë¥¼ ëˆŒëŸ¬ ì¢…ë£Œí•˜ì„¸ìš”.")
        
        collected_poses = 0
        pose_index = 0
        
        while collected_poses < num_poses:
            try:
                # í˜„ì¬ ê°ë„ ê°€ì ¸ì˜¤ê¸°
                angles = self.get_robot_angles()
                coords = self.robot.get_coords()
                
                # í˜„ì¬ ìƒíƒœ ì¶œë ¥
                print(f"\n{'='*60}")
                print(f"í˜„ì¬ ìƒíƒœ: {collected_poses}/{num_poses} í¬ì¦ˆ ìˆ˜ì§‘ë¨")
                print(f"ëª©í‘œ: {num_poses}ê°œ í¬ì¦ˆ")
                print(f"í˜„ì¬ í¬ì¦ˆ ì¸ë±ìŠ¤: {pose_index}")
                print(f"\në¡œë´‡ ìƒíƒœ:")
                print(f"   ê°ë„: [{angles[0]:6.1f}, {angles[1]:6.1f}, {angles[2]:6.1f}, "
                      f"{angles[3]:6.1f}, {angles[4]:6.1f}, {angles[5]:6.1f}]")
                print(f"   ì¢Œí‘œ: [{coords[0]:6.1f}, {coords[1]:6.1f}, {coords[2]:6.1f}]")
                print(f"\nâŒ¨ì¡°ì‘ë²•:")
                print(f"   Enter: í˜„ì¬ í¬ì¦ˆ ì €ì¥")
                print(f"   q: ì¢…ë£Œ")
                print(f"   Ctrl+C: ê°•ì œ ì¢…ë£Œ")
                print(f"{'='*60}")
                
                # ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸°
                user_input = input("\nëª…ë ¹ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip().lower()
                
                if user_input == 'q':
                    print(f"\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ì§‘ëœ í¬ì¦ˆ: {collected_poses}")
                    break
                elif user_input == '' or user_input == 's':
                    # í˜„ì¬ í¬ì¦ˆ ì €ì¥
                    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
                    
                    angle_data = {
                        "angles": angles,
                        "coords": coords,
                        "pose_index": pose_index,
                        "timestamp": timestamp
                    }
                    
                    angle_path = self.angles_dir / f"{pose_index:02d}_{timestamp}_angles.json"
                    with open(angle_path, 'w') as f:
                        json.dump(angle_data, f, indent=2)
                    
                    print(f"\nâœ… í¬ì¦ˆ {pose_index} ì €ì¥ ì™„ë£Œ!")
                    print(f"   ğŸ“ ì €ì¥ ìœ„ì¹˜: {angle_path}")
                    collected_poses += 1
                    pose_index += 1
                    
                    if collected_poses < num_poses:
                        print(f"\nğŸ‰ {collected_poses}/{num_poses} í¬ì¦ˆ ìˆ˜ì§‘ ì™„ë£Œ!")
                        input("ë‹¤ìŒ í¬ì¦ˆë¡œ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
                    else:
                        print(f"\nğŸ‰ ëª¨ë“  í¬ì¦ˆ ìˆ˜ì§‘ ì™„ë£Œ!")
                
            except KeyboardInterrupt:
                print(f"\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ì§‘ëœ í¬ì¦ˆ: {collected_poses}")
                break
            except Exception as e:
                print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                input("ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
                continue
        
        print(f"\n{'='*60}")
        print(f"ì‹¤ì‹œê°„ ê°ë„ ìˆ˜ì§‘ ì™„ë£Œ")
        print(f"ì´ {collected_poses}ê°œì˜ í¬ì¦ˆ ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"{'='*60}")
        
        return collected_poses >= 10  # ìµœì†Œ 10ê°œ ì´ìƒ í•„ìš”
    
    def collect_angles_with_camera_feed(self, num_poses: int = 20) -> bool:
        """
        ì¹´ë©”ë¼ í™”ë©´ì„ ë³´ì—¬ì£¼ë©´ì„œ ì‹¤ì‹œê°„ ê°ë„ ìˆ˜ì§‘ ëª¨ë“œ (ì¹´ë©”ë¼ ìº¡ì²˜ ì—†ì´)
        
        Args:
            num_poses: ìˆ˜ì§‘í•  í¬ì¦ˆ ê°œìˆ˜
            
        Returns:
            bool: ìˆ˜ì§‘ ì„±ê³µ ì—¬ë¶€
        """
        print(f"\n=== ì‹¤ì‹œê°„ ê°ë„ ìˆ˜ì§‘ ëª¨ë“œ (ì¹´ë©”ë¼ í™”ë©´ í¬í•¨) ===")
        print(f"ìˆ˜ì§‘í•  í¬ì¦ˆ ìˆ˜: {num_poses}")
        print("ë¡œë´‡ì„ ìˆ˜ë™ìœ¼ë¡œ ì¡°ì‘í•˜ì—¬ ë‹¤ì–‘í•œ í¬ì¦ˆì˜ ê°ë„ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
        print("ì¹´ë©”ë¼ í™”ë©´ì´ ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œë˜ë©°, ChArUco ê²€ì¶œ ìƒíƒœë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("ê° í¬ì¦ˆì—ì„œ 's'ë¥¼ ëˆŒëŸ¬ ì €ì¥í•˜ê±°ë‚˜ 'q'ë¥¼ ëˆŒëŸ¬ ì¢…ë£Œí•˜ì„¸ìš”.")
        
        # RealSense ì¹´ë©”ë¼ ì´ˆê¸°í™” (1280x800 í•´ìƒë„)
        config = rs.config()
        config.enable_stream(rs.stream.color, 1280, 800, rs.format.bgr8, 30)  
        config.enable_stream(rs.stream.depth, 848, 480, rs.format.z16, 30)
        
        pipeline = None
        try:
            pipeline = rs.pipeline()
            profile = pipeline.start(config)
            print("âœ… RealSense ì¹´ë©”ë¼ ì—°ê²° ì„±ê³µ (1280x800)")
        except Exception as e:
            print(f"âŒ ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨: {e}")
            print("ì¹´ë©”ë¼ ì—†ì´ ê°ë„ ìˆ˜ì§‘ì„ ê³„ì†í•©ë‹ˆë‹¤...")
            return self.collect_angles_realtime_simple(num_poses)
        
        # ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸° (1280x800 í•´ìƒë„ìš©)
        camera_matrix = np.array([
            [642.947,   0.0,     644.808],
            [0.0,       642.073, 409.050],
            [0.0,       0.0,     1.0]
        ], dtype=np.float64)
        
        # ì™œê³¡ ê³„ìˆ˜ (k1, k2, p1, p2, k3)
        dist_coeffs = np.array([
            -0.05594644322991371,
            0.06878077983856201,
            -0.00011232726683374494,
            0.000743341923225671,
            -0.022005939856171608
        ], dtype=np.float64)
        
        collected_poses = 0
        pose_index = 0
        
        try:
            while collected_poses < num_poses:
                self.robot.release_all_servos()
                # ì¹´ë©”ë¼ í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸°
                frames = pipeline.wait_for_frames()
                color_frame = frames.get_color_frame()
                
                if not color_frame:
                    continue
                
                # ì´ë¯¸ì§€ ë³€í™˜
                color_image = np.asanyarray(color_frame.get_data())
                
                # ChArUco ê²€ì¶œ
                charuco_detected = False
                detection_info = "ê²€ì¶œ ì•ˆë¨"
                charuco_pose = None
                quality_info = ""
                quality_score = 0.0
                charuco_result = None  # ì´ˆê¸°í™” ì¶”ê°€
                distance = 0.0  # ì´ˆê¸°í™” ì¶”ê°€
                
                try:
                    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ë¡œ ë§ˆì»¤ ê²€ì¶œ ì •í™•ë„ í–¥ìƒ
                    # 1. Grayscale ë³€í™˜
                    gray = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)
                    
                    # 2. ëŒ€ë¹„ í–¥ìƒ (CLAHE - Contrast Limited Adaptive Histogram Equalization)
                    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
                    gray_enhanced = clahe.apply(gray)
                    
                    # 3. ë…¸ì´ì¦ˆ ì œê±° (ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬) - ì œê±°
                    # gray_enhanced = cv2.GaussianBlur(gray_enhanced, (3, 3), 0)
                    
                    # 4. ì´ì§„í™” (Otsu's method)
                    _, binary = cv2.threshold(gray_enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                    
                    # ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë¥¼ ì»¬ëŸ¬ë¡œ ë³€í™˜ (ì—¬ê¸°ì„œ ë¯¸ë¦¬ ìƒì„±)
                    gray_enhanced_colored = cv2.cvtColor(gray_enhanced, cv2.COLOR_GRAY2BGR)
                    
                    try:
                        aruco_params = cv2.aruco.DetectorParameters()
                        # ê²€ì¶œ íŒŒë¼ë¯¸í„° ìµœì í™”
                        aruco_params.adaptiveThreshWinSizeMin = 3
                        aruco_params.adaptiveThreshWinSizeMax = 23
                        aruco_params.adaptiveThreshWinSizeStep = 10
                        aruco_params.adaptiveThreshConstant = 7
                        aruco_params.minMarkerPerimeterRate = 0.03
                        aruco_params.maxMarkerPerimeterRate = 4.0
                        aruco_params.polygonalApproxAccuracyRate = 0.03
                        aruco_params.minCornerDistanceRate = 0.05
                        aruco_params.minMarkerDistanceRate = 0.05
                        aruco_params.minDistanceToBorder = 3
                        aruco_params.minOtsuStdDev = 5.0
                        aruco_params.perspectiveRemovePixelPerCell = 4
                        aruco_params.perspectiveRemoveIgnoredMarginPerCell = 0.13
                        aruco_params.maxErroneousBitsInBorderRate = 0.35
                        aruco_params.errorCorrectionRate = 0.6
                        
                        aruco_detector = cv2.aruco.ArucoDetector(self.aruco_dict, aruco_params)
                        corners, ids, rejected = aruco_detector.detectMarkers(gray_enhanced)
                    except AttributeError:
                        # OpenCV 4.4 ì´í•˜ ë²„ì „
                        aruco_params = cv2.aruco.DetectorParameters_create()
                        # ê²€ì¶œ íŒŒë¼ë¯¸í„° ìµœì í™”
                        aruco_params.adaptiveThreshWinSizeMin = 3
                        aruco_params.adaptiveThreshWinSizeMax = 23
                        aruco_params.adaptiveThreshWinSizeStep = 10
                        aruco_params.adaptiveThreshConstant = 7
                        aruco_params.minMarkerPerimeterRate = 0.03
                        aruco_params.maxMarkerPerimeterRate = 4.0
                        aruco_params.polygonalApproxAccuracyRate = 0.03
                        aruco_params.minCornerDistanceRate = 0.05
                        aruco_params.minMarkerDistanceRate = 0.05
                        aruco_params.minDistanceToBorder = 3
                        aruco_params.minOtsuStdDev = 5.0
                        aruco_params.perspectiveRemovePixelPerCell = 4
                        aruco_params.perspectiveRemoveIgnoredMarginPerCell = 0.13
                        aruco_params.maxErroneousBitsInBorderRate = 0.35
                        aruco_params.errorCorrectionRate = 0.6
                        
                        corners, ids, rejected = cv2.aruco.detectMarkers(gray_enhanced, self.aruco_dict, parameters=aruco_params)
                    
                    # ê²€ì¶œëœ ë§ˆì»¤ ê·¸ë¦¬ê¸° (ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ì—)
                    if ids is not None and len(ids) > 0:
                        cv2.aruco.drawDetectedMarkers(gray_enhanced_colored, corners, ids)
                        # ArUco ë§ˆì»¤ ê°œìˆ˜ ì €ì¥
                        self._last_marker_count = len(ids)
                        print(f"\rDEBUG: ArUco markers detected: {len(ids)}", end="")
                    else:
                        self._last_marker_count = 0
                    
                    # ChArUco í¬ì¦ˆ ê²€ì¶œ
                    charuco_result = self.detect_charuco_pose(color_image, camera_matrix, dist_coeffs)
                    if charuco_result is not None:
                        rvec, tvec, charuco_corners, charuco_ids = charuco_result
                        charuco_detected = True
                        distance = np.linalg.norm(tvec)
                        detection_info = f"ê²€ì¶œë¨ (ê±°ë¦¬: {distance*1000:.1f}mm)"
                        
                        # í’ˆì§ˆ í‰ê°€
                        if charuco_corners is not None and charuco_ids is not None:
                            print(f"\rDEBUG: ChArUco corners={len(charuco_corners)}, ids={len(charuco_ids)}, min_required={self.min_charuco_corners}", end="")
                            
                            is_good_quality, quality_message, quality_score = self.evaluate_charuco_quality(
                                charuco_corners, charuco_ids, rvec, tvec
                            )
                            quality_info = f"Quality: {quality_score:.2f} ({'GOOD' if is_good_quality else 'LOW'})"
                            
                            # ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥ (ì½˜ì†”)
                            print(f"\rChArUco: {len(charuco_corners)} corners, Distance: {distance*1000:.1f}mm, Quality: {quality_score:.2f}", end="")
                            
                            # í’ˆì§ˆì´ ì¢‹ì€ ê²½ìš°ì—ë§Œ ì¢Œí‘œì¶• ê·¸ë¦¬ê¸° (ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ì—)
                            if is_good_quality:
                                cv2.drawFrameAxes(gray_enhanced_colored, camera_matrix, dist_coeffs, rvec, tvec, 0.05)
                        else:
                            # ArUco ë§ˆì»¤ë§Œ ê²€ì¶œëœ ê²½ìš°ì—ë„ í’ˆì§ˆ í‰ê°€ ì‹œë„
                            print(f"\rDEBUG: ArUco markers only, trying alternative quality assessment", end="")
                            
                            # ArUco ë§ˆì»¤ ê°œìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •êµí•œ í’ˆì§ˆ í‰ê°€
                            if hasattr(self, '_last_marker_count'):
                                marker_count = self._last_marker_count
                                if marker_count >= 15:  # ì¶©ë¶„í•œ ArUco ë§ˆì»¤ê°€ ê²€ì¶œëœ ê²½ìš°
                                    quality_score = 0.5  # ë” ë†’ì€ ì ìˆ˜
                                    is_good_quality = quality_score >= self.min_detection_confidence
                                    quality_info = f"Quality: {quality_score:.2f} (ArUco: {marker_count}) ({'GOOD' if is_good_quality else 'LOW'})"
                                    print(f"\rArUco: {marker_count} markers, Quality: {quality_score:.2f}", end="")
                                elif marker_count >= 10:  # ì¤‘ê°„ ìˆ˜ì¤€ì˜ ArUco ë§ˆì»¤
                                    quality_score = 0.3
                                    is_good_quality = quality_score >= self.min_detection_confidence
                                    quality_info = f"Quality: {quality_score:.2f} (ArUco: {marker_count}) ({'GOOD' if is_good_quality else 'LOW'})"
                                    print(f"\rArUco: {marker_count} markers, Quality: {quality_score:.2f}", end="")
                                else:
                                    quality_score = 0.1
                                    is_good_quality = False
                                    quality_info = f"Quality: {quality_score:.2f} (ArUco: {marker_count}) (LOW)"
                                    print(f"\rArUco: {marker_count} markers (insufficient)", end="")
                            else:
                                quality_score = 0.0
                                is_good_quality = False
                                quality_info = "Quality: N/A (ArUco only)"
                                print(f"\rChArUco: ArUco markers only", end="")
                        
                except Exception as e:
                    detection_info = f"ê²€ì¶œ ì˜¤ë¥˜: {str(e)[:20]}"
                    # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©
                    gray_enhanced_colored = color_image.copy()
                
                # í˜„ì¬ ë¡œë´‡ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
                try:
                    angles = self.get_robot_angles()
                    coords = self.robot.get_coords()
                except Exception as e:
                    angles = [0, 0, 0, 0, 0, 0]
                    coords = [0, 0, 0, 0, 0, 0]
                    # ì‹¤ì‹œê°„ ëª¨ë“œì—ì„œëŠ” ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥í•˜ì§€ ì•ŠìŒ
                
                # í™”ë©´ì— ì •ë³´ í‘œì‹œ (ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì‚¬ìš©)
                # gray_enhanced_coloredëŠ” ì´ë¯¸ ìœ„ì—ì„œ ìƒì„±ë¨
                info_image = gray_enhanced_colored.copy()
                
                # ìƒíƒœ ì •ë³´ í…ìŠ¤íŠ¸ (ì˜ì–´ë¡œ í‘œì‹œ)
                cv2.putText(info_image, f"Pose: {collected_poses}/{num_poses}", (10, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                # ì „ì²˜ë¦¬ ì •ë³´ í‘œì‹œ
                cv2.putText(info_image, "Enhanced Image (CLAHE only)", (10, 225), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)
                
                # ChArUco ì½”ë„ˆ ê²€ì¶œ ìƒíƒœ í‘œì‹œ
                if charuco_result is not None:
                    rvec, tvec, charuco_corners, charuco_ids = charuco_result
                    corner_count = len(charuco_corners) if charuco_corners is not None else 0
                    id_count = len(charuco_ids) if charuco_ids is not None else 0
                    cv2.putText(info_image, f"ChArUco Corners: {corner_count}, IDs: {id_count}", (10, 205), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)
                else:
                    cv2.putText(info_image, "ChArUco Corners: NOT DETECTED", (10, 205), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)
                
                # ChArUco ê²€ì¶œ ìƒíƒœ í‘œì‹œ
                if charuco_detected:
                    cv2.putText(info_image, f"ChArUco: DETECTED ({distance*1000:.1f}mm)", (10, 60), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                else:
                    cv2.putText(info_image, "ChArUco: NOT DETECTED", (10, 60), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
                
                # í’ˆì§ˆ ì •ë³´ í‘œì‹œ
                if quality_info:
                    quality_color = (0, 255, 0) if quality_score >= self.min_detection_confidence else (0, 0, 255)
                    cv2.putText(info_image, f"Quality: {quality_score:.2f} ({'GOOD' if quality_score >= self.min_detection_confidence else 'LOW'})", (10, 110), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, quality_color, 1)
                
                cv2.putText(info_image, f"Angles: [{angles[0]:.1f}, {angles[1]:.1f}, {angles[2]:.1f}]", (10, 135),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                cv2.putText(info_image, f"        [{angles[3]:.1f}, {angles[4]:.1f}, {angles[5]:.1f}]", (10, 155), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                cv2.putText(info_image, f"Coords: [{coords[0]:.1f}, {coords[1]:.1f}, {coords[2]:.1f}]", (10, 180), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                
                # ì €ì¥ ê°€ëŠ¥ ì—¬ë¶€ í‘œì‹œ
                if charuco_detected:
                    cv2.putText(info_image, "Press 's' to save", (10, 250), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
                else:
                    cv2.putText(info_image, "No ChArUco detected - cannot save", (10, 250), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
                
                # í™”ë©´ í‘œì‹œ
                cv2.imshow('Cam-to-Gripper Calibration - Real-time', info_image)
                
                # í‚¤ë³´ë“œ ì…ë ¥ í™•ì¸
                key = cv2.waitKey(1) & 0xFF
                
                if key == ord('q'):
                    print(f"\n ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ì§‘ëœ í¬ì¦ˆ: {collected_poses}")
                    break
                elif key == ord('s'):
                    # ë¡œë´‡ ê³ ì • ë° ì•ˆì •í™” ëŒ€ê¸°
                    print(f"\nğŸ”’ ë¡œë´‡ì„ ê³ ì •í•˜ê³  ì•ˆì •í™” ëŒ€ê¸° ì¤‘... (1ì´ˆ)")
                    self.robot.power_on()
                    time.sleep(1.0)  # 1ì´ˆ ëŒ€ê¸°ë¡œ ë¡œë´‡ ì•ˆì •í™”
                    
                    # ì•ˆì •í™” í›„ ë‹¤ì‹œ ì¹´ë©”ë¼ í”„ë ˆì„ê³¼ ChArUco ê²€ì¶œ
                    frames = pipeline.wait_for_frames()
                    color_frame = frames.get_color_frame()
                    if color_frame:
                        color_image = np.asanyarray(color_frame.get_data())
                        charuco_result = self.detect_charuco_pose(color_image, camera_matrix, dist_coeffs)
                        
                        if charuco_result is not None:
                            rvec, tvec, charuco_corners, charuco_ids = charuco_result
                            distance = np.linalg.norm(tvec)
                            

                            
                            # í’ˆì§ˆ í‰ê°€
                            if charuco_corners is not None and charuco_ids is not None:
                                is_good_quality, quality_message, quality_score = self.evaluate_charuco_quality(
                                    charuco_corners, charuco_ids, rvec, tvec
                                )
                            else:
                                # ArUco ë§ˆì»¤ ê¸°ë°˜ fallback ê²°ê³¼ì¸ ê²½ìš°
                                is_good_quality = True  # ArUco ë§ˆì»¤ ê¸°ë°˜ì€ ê¸°ë³¸ì ìœ¼ë¡œ ì–‘í˜¸ë¡œ ê°„ì£¼
                                quality_score = 0.5
                            
                            if is_good_quality:
                                # í˜„ì¬ ë¡œë´‡ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
                                angles = self.get_robot_angles()
                                coords = self.robot.get_coords()
                                
                                # ë°ì´í„° ì €ì¥
                                timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
                                
                                # ê°ë„ ë°ì´í„° ì €ì¥
                                angle_data = {
                                    "angles": angles,
                                    "coords": coords,
                                    "pose_index": pose_index,
                                    "timestamp": timestamp,
                                    "stabilization_wait": True
                                }
                                angle_path = self.angles_dir / f"{pose_index:02d}_{timestamp}_angles.json"
                                with open(angle_path, 'w') as f:
                                    json.dump(angle_data, f, indent=2)
                                
                                # ChArUco ë°ì´í„° ì €ì¥
                                charuco_data = {
                                    "rvec": rvec.tolist(),
                                    "tvec": tvec.tolist(),
                                    "pose_index": pose_index,
                                    "timestamp": timestamp,
                                    "charuco_corners_count": len(charuco_corners) if charuco_corners is not None else 0,
                                    "charuco_ids_count": len(charuco_ids) if charuco_ids is not None else 0,
                                    "distance_mm": float(distance * 1000),
                                    "quality_score": float(quality_score),
                                    "detection_method": "charuco_corners" if charuco_corners is not None else "aruco_markers"
                                }
                                charuco_path = self.save_dir / f"{pose_index:02d}_{timestamp}_charuco.json"
                                with open(charuco_path, 'w') as f:
                                    json.dump(charuco_data, f, indent=2)
                                
                                print(f"\nâœ… í¬ì¦ˆ {pose_index} ì €ì¥ ì™„ë£Œ!")
                                print(f"  - ê±°ë¦¬: {distance*1000:.1f}mm")
                                print(f"  - í’ˆì§ˆ: {quality_score:.2f}")
                                print(f"  - ê²€ì¶œ ë°©ë²•: {'ChArUco ì½”ë„ˆ' if charuco_corners is not None else 'ArUco ë§ˆì»¤'}")
                                print(f"  - ì €ì¥ ìœ„ì¹˜: {angle_path}")
                                
                                collected_poses += 1
                                pose_index += 1
                            else:
                                print(f"\nâŒ í’ˆì§ˆì´ ë‚®ì•„ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (í’ˆì§ˆ ì ìˆ˜: {quality_score:.2f})")
                        else:
                            print(f"\nâŒ ChArUco ê²€ì¶œ ì‹¤íŒ¨ë¡œ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    
        except KeyboardInterrupt:
            print(f"\n ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ì§‘ëœ í¬ì¦ˆ: {collected_poses}")
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        finally:
            # ì¹´ë©”ë¼ ì •ë¦¬
            if pipeline is not None:
                try:
                    pipeline.stop()
                except:
                    pass
            cv2.destroyAllWindows()
        
        print(f"\n{'='*60}")
        print(f" ì‹¤ì‹œê°„ ê°ë„ ìˆ˜ì§‘ ì™„ë£Œ")
        print(f" ì´ {collected_poses}ê°œì˜ í¬ì¦ˆ ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"{'='*60}")
        
        return collected_poses >= 10  # ìµœì†Œ 10ê°œ ì´ìƒ í•„ìš”
    
    def capture_data_at_angles(self, angle_data: Dict[str, Any], pose_index: int) -> bool:
        """
        ì €ì¥ëœ ê°ë„ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œë´‡ì„ ì´ë™ì‹œí‚¤ê³  ì´ë¯¸ì§€ë¥¼ ìº¡ì²˜í•©ë‹ˆë‹¤.
        
        Args:
            angle_data: ê°ë„ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
            pose_index: í¬ì¦ˆ ì¸ë±ìŠ¤
            
        Returns:
            bool: ìº¡ì²˜ ì„±ê³µ ì—¬ë¶€
        """
        try:
            print(f"\n[{pose_index}] ìë™ ì´ë™ ëª¨ë“œ")
            
            # ì €ì¥ëœ ê°ë„ë¡œ ë¡œë´‡ ì´ë™
            angles = angle_data["angles"]
            print(f"ë¡œë´‡ì„ ê°ë„ {angles}ë¡œ ì´ë™ ì¤‘...")
            
            # ë¡œë´‡ ì´ë™ (ì†ë„ 50)
            self.robot.send_angles(angles, 50)
            time.sleep(3)  # ì´ë™ ì™„ë£Œ ëŒ€ê¸°
            
            # í˜„ì¬ ë¡œë´‡ í¬ì¦ˆ ê°€ì ¸ì˜¤ê¸°
            R_base2ee, t_base2ee = self.get_robot_pose()
            
            # ì´ë¯¸ì§€ ìº¡ì²˜
            print("ì´ë¯¸ì§€ ìº¡ì²˜ ì¤‘...")
            color_path, depth_path, intrinsics_path = capture_d455_images(
                save_dir=str(self.save_dir),
                rgb_size=(848, 480),
                depth_size=(848, 480)
            )
            
            # ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„° ë¡œë“œ
            camera_matrix, dist_coeffs = self._load_camera_intrinsics(intrinsics_path)
            
            # ì´ë¯¸ì§€ì—ì„œ ChArUco ê²€ì¶œ
            image = cv2.imread(color_path)
            charuco_pose = self.detect_charuco_pose(image, camera_matrix, dist_coeffs)
            
            if charuco_pose is None:
                print(f"[{pose_index}] ChArUco ê²€ì¶œ ì‹¤íŒ¨")
                print("ChArUco ë³´ë“œê°€ ì¹´ë©”ë¼ì— ì˜ ë³´ì´ëŠ”ì§€ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                return False
            
            rvec, tvec, charuco_corners, charuco_ids = charuco_pose
            
            # ê±°ë¦¬ ì •ë³´ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
            distance = np.linalg.norm(tvec)
            print(f"ChArUco ë³´ë“œê¹Œì§€ì˜ ê±°ë¦¬: {distance*1000:.1f}mm")
            
            # ë°ì´í„° ì €ì¥
            timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
            
            # ë¡œë´‡ í¬ì¦ˆ ì €ì¥
            pose_data = {
                "R_base2ee": R_base2ee.tolist(),
                "t_base2ee": t_base2ee.tolist(),
                "angles": angles,
                "pose_index": pose_index,
                "timestamp": timestamp
            }
            pose_path = self.poses_dir / f"{pose_index:02d}_{timestamp}_pose.json"
            
            with open(pose_path, 'w') as f:
                json.dump(pose_data, f, indent=2)
            
            # ChArUco í¬ì¦ˆ ì €ì¥ (ì¹´ë©”ë¼ -> íƒ€ê²Ÿ)
            charuco_data = {
                "rvec": rvec.tolist(),
                "tvec": tvec.tolist(),
                "pose_index": pose_index,
                "timestamp": timestamp
            }
            charuco_path = self.save_dir / f"{pose_index:02d}_{timestamp}_charuco.json"
            
            with open(charuco_path, 'w') as f:
                json.dump(charuco_data, f, indent=2)
            
            print(f"[{pose_index}] âœ… ì €ì¥ ì™„ë£Œ")
            print(f"  - ì´ë¯¸ì§€: {color_path}")
            print(f"  - ê¹Šì´: {depth_path}")
            print(f"  - ë¡œë´‡ í¬ì¦ˆ: {pose_path}")
            print(f"  - ChArUco í¬ì¦ˆ: {charuco_path}")
            
            return True
            
        except Exception as e:
            print(f"[{pose_index}] ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False
    
    def perform_automatic_calibration(self) -> bool:
        """
        ì €ì¥ëœ ê°ë„ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ìë™ìœ¼ë¡œ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Returns:
            bool: ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì„±ê³µ ì—¬ë¶€
        """
        print(f"\n=== ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª¨ë“œ ===")
        
        # ì €ì¥ëœ ê°ë„ íŒŒì¼ë“¤ ë¡œë“œ
        angle_files = list(self.angles_dir.glob("*_angles.json"))
        
        if len(angle_files) == 0:
            print("ì €ì¥ëœ ê°ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì‹¤ì‹œê°„ ê°ë„ ìˆ˜ì§‘ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.")
            return False
        
        # íŒŒì¼ ì •ë ¬ (ì¸ë±ìŠ¤ ìˆœì„œëŒ€ë¡œ)
        angle_files.sort(key=lambda x: int(x.stem.split('_')[0]))
        
        print(f"ì´ {len(angle_files)}ê°œì˜ ê°ë„ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        successful_captures = 0
        
        for i, angle_file in enumerate(angle_files):
            print(f"\n[{i+1}/{len(angle_files)}] ê°ë„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
            
            # ê°ë„ ë°ì´í„° ë¡œë“œ
            with open(angle_file, 'r') as f:
                angle_data = json.load(f)
            
            pose_index = angle_data["pose_index"]
            
            if self.capture_data_at_angles(angle_data, pose_index):
                successful_captures += 1
                print(f"âœ… í¬ì¦ˆ {pose_index} ìº¡ì²˜ ì„±ê³µ ({successful_captures}/{len(angle_files)})")
            else:
                print(f"âŒ í¬ì¦ˆ {pose_index} ìº¡ì²˜ ì‹¤íŒ¨")
                
                # ì¬ì‹œë„ ì˜µì…˜
                retry = input("ì´ í¬ì¦ˆë¥¼ ë‹¤ì‹œ ì‹œë„í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower().strip()
                if retry == 'y':
                    i -= 1  # ê°™ì€ íŒŒì¼ì„ ë‹¤ì‹œ ì²˜ë¦¬
                    continue
        
        print(f"\n=== ìë™ ìº¡ì²˜ ì™„ë£Œ ===")
        print(f"ì„±ê³µ: {successful_captures}/{len(angle_files)}")
        
        if successful_captures >= 10:  # ìµœì†Œ 10ê°œ ì´ìƒì˜ í¬ì¦ˆê°€ í•„ìš”
            return self.calculate_transformation_matrix()
        else:
            print("ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
    
    def capture_data_at_manual_pose(self, pose_index: int) -> bool:
        """
        ìˆ˜ë™ìœ¼ë¡œ ì¡°ì‘ëœ ë¡œë´‡ í¬ì¦ˆì—ì„œ ì´ë¯¸ì§€ì™€ í¬ì¦ˆ ë°ì´í„°ë¥¼ ìº¡ì²˜í•©ë‹ˆë‹¤.
        
        Args:
            pose_index: í¬ì¦ˆ ì¸ë±ìŠ¤
            
        Returns:
            bool: ìº¡ì²˜ ì„±ê³µ ì—¬ë¶€
        """
        try:
            print(f"\n[{pose_index}] ìˆ˜ë™ ì¡°ì‘ ëª¨ë“œ")
            
            # ë¡œë´‡ì„ ìˆ˜ë™ ì¡°ì‘ ëª¨ë“œë¡œ ì „í™˜
            self.robot.release_all_servos()
            
            # ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸°
            input("ë¡œë´‡ì„ ì›í•˜ëŠ” ìœ„ì¹˜ë¡œ ì´ë™í•œ í›„ Enterë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”...")
            
            # ë¡œë´‡ì„ ê³ ì • ëª¨ë“œë¡œ ì „í™˜
            self.robot.power_on()
            time.sleep(2)  # ë¡œë´‡ ì•ˆì •í™” ëŒ€ê¸°
            
            # í˜„ì¬ ë¡œë´‡ í¬ì¦ˆ ê°€ì ¸ì˜¤ê¸°
            R_base2ee, t_base2ee = self.get_robot_pose()
            
            # ì´ë¯¸ì§€ ìº¡ì²˜
            print("ì´ë¯¸ì§€ ìº¡ì²˜ ì¤‘...")
            color_path, depth_path, intrinsics_path = capture_d455_images(
                save_dir=str(self.save_dir),
                rgb_size=(848, 480),
                depth_size=(848, 480)
            )
            
            # ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„° ë¡œë“œ
            camera_matrix, dist_coeffs = self._load_camera_intrinsics(intrinsics_path)
            
            # ì´ë¯¸ì§€ì—ì„œ ChArUco ê²€ì¶œ
            image = cv2.imread(color_path)
            charuco_pose = self.detect_charuco_pose(image, camera_matrix, dist_coeffs)
            
            if charuco_pose is None:
                print(f"[{pose_index}] ChArUco ê²€ì¶œ ì‹¤íŒ¨")
                print("ChArUco ë³´ë“œê°€ ì¹´ë©”ë¼ì— ì˜ ë³´ì´ëŠ”ì§€ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                return False
            
            rvec, tvec, charuco_corners, charuco_ids = charuco_pose
            
            # ê±°ë¦¬ ì •ë³´ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
            distance = np.linalg.norm(tvec)
            print(f"ChArUco ë³´ë“œê¹Œì§€ì˜ ê±°ë¦¬: {distance*1000:.1f}mm")
            
            # ë°ì´í„° ì €ì¥
            timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
            
            # ë¡œë´‡ í¬ì¦ˆ ì €ì¥
            pose_data = {
                "R_base2ee": R_base2ee.tolist(),
                "t_base2ee": t_base2ee.tolist(),
                "pose_index": pose_index,
                "timestamp": timestamp
            }
            pose_path = self.poses_dir / f"{pose_index:02d}_{timestamp}_pose.json"
            
            with open(pose_path, 'w') as f:
                json.dump(pose_data, f, indent=2)
            
            # ChArUco í¬ì¦ˆ ì €ì¥ (ì¹´ë©”ë¼ -> íƒ€ê²Ÿ)
            charuco_data = {
                "rvec": rvec.tolist(),
                "tvec": tvec.tolist(),
                "pose_index": pose_index,
                "timestamp": timestamp
            }
            charuco_path = self.save_dir / f"{pose_index:02d}_{timestamp}_charuco.json"
            
            with open(charuco_path, 'w') as f:
                json.dump(charuco_data, f, indent=2)
            
            print(f"[{pose_index}] âœ… ì €ì¥ ì™„ë£Œ")
            print(f"  - ì´ë¯¸ì§€: {color_path}")
            print(f"  - ê¹Šì´: {depth_path}")
            print(f"  - ë¡œë´‡ í¬ì¦ˆ: {pose_path}")
            print(f"  - ChArUco í¬ì¦ˆ: {charuco_path}")
            
            return True
            
        except Exception as e:
            print(f"[{pose_index}] ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False
    
    def perform_manual_calibration(self, num_poses: int = 20) -> bool:
        """
        ìˆ˜ë™ ì¡°ì‘ì„ í†µí•œ Cam-to-Gripper calibrationì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Args:
            num_poses: ìº¡ì²˜í•  í¬ì¦ˆ ê°œìˆ˜
            
        Returns:
            bool: ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì„±ê³µ ì—¬ë¶€
        """
        print(f"\n=== ìˆ˜ë™ Eye-in-Hand Calibration ì‹œì‘ ===")
        print(f"ìº¡ì²˜í•  í¬ì¦ˆ ìˆ˜: {num_poses}")
        print("ê° í¬ì¦ˆì—ì„œ ë¡œë´‡ì„ ìˆ˜ë™ìœ¼ë¡œ ì¡°ì‘í•˜ì—¬ ChArUco ë³´ë“œë¥¼ ë‹¤ì–‘í•œ ê°ë„ì—ì„œ ì´¬ì˜í•©ë‹ˆë‹¤.")
        
        successful_captures = 0
        current_pose_index = 0
        
        while successful_captures < num_poses:
            print(f"\n[{successful_captures}/{num_poses}] í¬ì¦ˆ ìº¡ì²˜ ì¤‘...")
            
            if self.capture_data_at_manual_pose(current_pose_index):
                successful_captures += 1
                print(f"âœ… í¬ì¦ˆ {successful_captures} ìº¡ì²˜ ì„±ê³µ ({successful_captures}/{num_poses})")
                # ê²€ì¶œ ì„±ê³µ ì‹œ ìë™ìœ¼ë¡œ ë‹¤ìŒ í¬ì¦ˆë¡œ ì§„í–‰
                current_pose_index += 1
            else:
                print(f"âŒ í¬ì¦ˆ {current_pose_index} ìº¡ì²˜ ì‹¤íŒ¨")
                
                # ì¬ì‹œë„ ì˜µì…˜ (ê²€ì¶œ ì‹¤íŒ¨ ì‹œì—ë§Œ ì§ˆë¬¸)
                retry = input("ì´ í¬ì¦ˆë¥¼ ë‹¤ì‹œ ì‹œë„í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n/q): ").lower().strip()
                if retry == 'q':
                    print("ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                    break
                elif retry == 'y':
                    continue  # ê°™ì€ ì¸ë±ìŠ¤ë¡œ ë‹¤ì‹œ ì‹œë„
                else:
                    print("ì´ í¬ì¦ˆë¥¼ ê±´ë„ˆë›°ê³  ë‹¤ìŒìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
                    current_pose_index += 1
        
        print(f"\n=== ìˆ˜ë™ ìº¡ì²˜ ì™„ë£Œ ===")
        print(f"ì„±ê³µ: {successful_captures}/{num_poses}")
        
        if successful_captures >= 10:  # ìµœì†Œ 10ê°œ ì´ìƒì˜ í¬ì¦ˆê°€ í•„ìš”
            return self.calculate_transformation_matrix()
        else:
            print("ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
    
    def calculate_transformation_matrix(self) -> bool:
        """
        ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ Eye-in-Hand ë³€í™˜ í–‰ë ¬ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        print("\n=== Eye-in-Hand ë³€í™˜ í–‰ë ¬ ê³„ì‚° ì¤‘ ===")
        
        try:
            # ì €ì¥ëœ ë°ì´í„° ë¡œë“œ
            pose_files = list(self.poses_dir.glob("*_pose.json"))
            charuco_files = list(self.save_dir.glob("*_charuco.json"))
            
            if len(charuco_files) < 3:
                print(f"ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (í•„ìš”: 3ê°œ ì´ìƒ, í˜„ì¬: {len(charuco_files)}ê°œ)")
                return False
            
            # ë°ì´í„° ì •ë ¬ (ì¸ë±ìŠ¤ ìˆœì„œëŒ€ë¡œ)
            pose_files.sort(key=lambda x: int(x.stem.split('_')[0]))
            charuco_files.sort(key=lambda x: int(x.stem.split('_')[0]))
            
            T_base2ee_list = []  # ë¡œë´‡ ë² ì´ìŠ¤ -> End-Effector (ë¯¸í„° ë‹¨ìœ„)
            T_cam2target_list = []  # ì¹´ë©”ë¼ -> ChArUco íƒ€ê²Ÿ (ë¯¸í„° ë‹¨ìœ„)
            
            print(f"ì´ {len(charuco_files)}ê°œì˜ í¬ì¦ˆ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...")
            
            # ëª¨ë“  charuco íŒŒì¼ì„ ì‚¬ìš© (ChArUco ì½”ë„ˆ ê¸°ë°˜ê³¼ ArUco ë§ˆì»¤ ê¸°ë°˜ ëª¨ë‘ í¬í•¨)
            valid_pose_files = []
            valid_charuco_files = []
            
            for charuco_file in charuco_files:
                # charuco íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ì‚¬ìš©
                valid_charuco_files.append(charuco_file)
                # í•´ë‹¹í•˜ëŠ” pose íŒŒì¼ ì°¾ê¸°
                pose_index = int(charuco_file.stem.split('_')[0])
                pose_file = self.poses_dir / f"{pose_index:02d}_*_pose.json"
                pose_files_found = list(self.poses_dir.glob(f"{pose_index:02d}_*_pose.json"))
                if pose_files_found:
                    valid_pose_files.append(pose_files_found[0])
                else:
                    # pose íŒŒì¼ì´ ì—†ìœ¼ë©´ angles íŒŒì¼ì—ì„œ ê°ë„ ì •ë³´ ì‚¬ìš©
                    angle_files_found = list(self.angles_dir.glob(f"{pose_index:02d}_*_angles.json"))
                    if angle_files_found:
                        with open(angle_files_found[0], 'r') as f:
                            angle_data = json.load(f)
                        # ê°ë„ì—ì„œ pose ê³„ì‚° (ì„ì‹œ pose íŒŒì¼ ìƒì„±)
                        angles = angle_data["angles"]
                        coords = angle_data["coords"]
                        # ì—¬ê¸°ì„œ ê°ë„ë¥¼ poseë¡œ ë³€í™˜í•˜ëŠ” ë¡œì§ ì¶”ê°€ í•„ìš”
                        valid_pose_files.append(None)  # ì„ì‹œë¡œ None ì¶”ê°€
            
            print(f"ìœ íš¨í•œ í¬ì¦ˆ: {len(valid_charuco_files)}ê°œ")
            
            if len(valid_charuco_files) < 3:
                print(f"ìœ íš¨í•œ í¬ì¦ˆê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (í•„ìš”: 3ê°œ ì´ìƒ, í˜„ì¬: {len(valid_charuco_files)}ê°œ)")
                return False
            
            for i, charuco_file in enumerate(valid_charuco_files):
                # ChArUco í¬ì¦ˆ ë¡œë“œ (ì¹´ë©”ë¼ -> íƒ€ê²Ÿ)
                with open(charuco_file, 'r') as f:
                    charuco_data = json.load(f)
                
                rvec = np.array(charuco_data["rvec"])
                tvec = np.array(charuco_data["tvec"])
                
                # íšŒì „ ë²¡í„°ë¥¼ íšŒì „ í–‰ë ¬ë¡œ ë³€í™˜
                camera_rotation, _ = cv2.Rodrigues(rvec)
                
                # ì¹´ë©”ë¼ -> ChArUco íƒ€ê²Ÿ (ë¯¸í„° ë‹¨ìœ„)
                T_cam2target = np.eye(4)
                T_cam2target[:3, :3] = camera_rotation
                T_cam2target[:3, 3] = tvec.flatten()
                T_cam2target_list.append(T_cam2target)
                
                # ë¡œë´‡ í¬ì¦ˆ ì²˜ë¦¬ (pose íŒŒì¼ì´ ìˆëŠ” ê²½ìš°)
                if i < len(valid_pose_files) and valid_pose_files[i] is not None:
                    with open(valid_pose_files[i], 'r') as f:
                        pose_data = json.load(f)
                    
                    t_base2ee = np.array(pose_data["t_base2ee"])
                    R_base2ee = np.array(pose_data["R_base2ee"])
                else:
                    # angles íŒŒì¼ì—ì„œ pose ê³„ì‚°
                    angle_files_found = list(self.angles_dir.glob(f"{charuco_file.stem.split('_')[0]}_*_angles.json"))
                    if angle_files_found:
                        with open(angle_files_found[0], 'r') as f:
                            angle_data = json.load(f)
                        
                        coords = angle_data["coords"]
                        # coordsì—ì„œ pose ê³„ì‚° (ê°„ë‹¨í•œ ë³€í™˜)
                        position = np.array(coords[0:3]) / 1000.0  # mmë¥¼ më¡œ ë³€í™˜
                        rx, ry, rz = np.radians(coords[3:6])
                        R_base2ee = self._euler_to_rotation_matrix(rx, ry, rz)
                        t_base2ee = position.reshape(3, 1)
                    else:
                        print(f"í¬ì¦ˆ {i}ì— ëŒ€í•œ ê°ë„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        continue
                
                # ë¡œë´‡ ë² ì´ìŠ¤ -> End-Effector (ë¯¸í„° ë‹¨ìœ„)
                T_base2ee = np.eye(4)
                T_base2ee[:3, :3] = R_base2ee
                T_base2ee[:3, 3] = t_base2ee.flatten()
                T_base2ee_list.append(T_base2ee)
                
                # ë””ë²„ê·¸ ì •ë³´
                detection_method = charuco_data.get("detection_method", "unknown")
                distance_mm = charuco_data.get("distance_mm", 0)
                print(f"í¬ì¦ˆ {i+1}: {detection_method}, ê±°ë¦¬={distance_mm:.1f}mm")
            
            # Hand-Eye calibration ìˆ˜í–‰
            print("\nHand-Eye calibration ê³„ì‚° ì¤‘...")
            R_ee2cam, t_ee2cam = self._solve_hand_eye_calibration(
                T_cam2target_list, T_base2ee_list
            )
            
            if R_ee2cam is not None:
                # ê²°ê³¼ëŠ” ë¯¸í„° ë‹¨ìœ„ë¡œ ë°˜í™˜ë¨
                t_ee2cam_norm = np.linalg.norm(t_ee2cam)
                print(f"t_ee2cam í¬ê¸° (m): {t_ee2cam_norm:.3f}")
                
                # ë¯¸í„° ë‹¨ìœ„ë¡œ ì €ì¥ (í‘œì¤€ ë‹¨ìœ„)
                print(f"ë‹¨ìœ„: ë¯¸í„° (í‘œì¤€ ë‹¨ìœ„)")
                
                # ë³€í™˜ í–‰ë ¬ ìƒì„±
                T_ee2cam = np.eye(4)
                T_ee2cam[:3, :3] = R_ee2cam
                T_ee2cam[:3, 3] = t_ee2cam.flatten()
                
                # ê²°ê³¼ ì €ì¥ (ë¯¸í„° ë‹¨ìœ„)
                calibration_result = {
                    "R_ee2cam": R_ee2cam.tolist(),
                    "t_ee2cam": t_ee2cam.flatten().tolist(),  # ë¯¸í„° ë‹¨ìœ„ë¡œ ì €ì¥
                    "num_poses": len(T_base2ee_list),
                    "timestamp": datetime.now().isoformat(),
                    "description": "End-Effector -> ì¹´ë©”ë¼ ë³€í™˜ í–‰ë ¬ (Eye-in-Hand calibration, ë¯¸í„° ë‹¨ìœ„)",
                    "coordinate_transformation": {
                        "applied": True,
                        "description": "Z_cam â†’ X_robot, -X_cam â†’ Y_robot, -Y_cam â†’ Z_robot",
                        "transformation_matrix": [
                            [0, 0, 1],
                            [-1, 0, 0],
                            [0, -1, 0]
                        ]
                    }
                }
                
                result_path = self.save_dir / "ee2cam.json"
                with open(result_path, 'w') as f:
                    json.dump(calibration_result, f, indent=2)
                
                # numpy ë°°ì—´ì„ ì•ˆì „í•˜ê²Œ floatë¡œ ë³€í™˜
                t_x = float(t_ee2cam.flatten()[0])
                t_y = float(t_ee2cam.flatten()[1])
                t_z = float(t_ee2cam.flatten()[2])
                
                print(f"âœ… Eye-in-Hand ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ!")
                print(f"ê²°ê³¼ ì €ì¥: {result_path}")
                print(f"End-Effector -> ì¹´ë©”ë¼ ë³€í™˜ í–‰ë ¬:")
                print(f"R:\n{R_ee2cam}")
                print(f"t (m): [{t_x:.3f}, {t_y:.3f}, {t_z:.3f}]")
                
                return True
            else:
                print("âŒ ë³€í™˜ í–‰ë ¬ ê³„ì‚° ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            print(f"ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    

    
    def _solve_hand_eye_calibration(self, 
                                   T_cam2target_list: List[np.ndarray],
                                   T_base2ee_list: List[np.ndarray]) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
        """
        Hand-Eye calibration ë°©ì •ì‹ì„ í•´ê²°í•©ë‹ˆë‹¤.
        
        Args:
            T_cam2target_list: ì¹´ë©”ë¼ í¬ì¦ˆ ë¦¬ìŠ¤íŠ¸ (ì¹´ë©”ë¼ -> ChArUco íƒ€ê²Ÿ) - ë¯¸í„° ë‹¨ìœ„
            T_base2ee_list: ë¡œë´‡ í¬ì¦ˆ ë¦¬ìŠ¤íŠ¸ (ë² ì´ìŠ¤ -> End-Effector) - ë¯¸í„° ë‹¨ìœ„
            
        Returns:
            Tuple[Optional[np.ndarray], Optional[np.ndarray]]: (R_ee2cam, t_ee2cam) - ë¯¸í„° ë‹¨ìœ„
        """
        try:
            # OpenCVì˜ calibrateHandEye í•¨ìˆ˜ ì‚¬ìš©
            camera_rotations = [pose[:3, :3] for pose in T_cam2target_list]
            camera_translations = [pose[:3, 3] for pose in T_cam2target_list]
            ee_rotations = [pose[:3, :3] for pose in T_base2ee_list]
            ee_translations = [pose[:3, 3] for pose in T_base2ee_list]
            
            # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
            if len(T_cam2target_list) < 3:
                print("ì¶©ë¶„í•œ í¬ì¦ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None, None
            
            # Hand-Eye calibration ìˆ˜í–‰ (ëª¨ë“  ì…ë ¥ì€ ë¯¸í„° ë‹¨ìœ„)
            R_ee2cam, t_ee2cam = cv2.calibrateHandEye(
                ee_rotations, ee_translations,
                camera_rotations, camera_translations,
                method=cv2.CALIB_HAND_EYE_TSAI
            )
            
            # ì¢Œí‘œê³„ ì°¨ì´ë¥¼ ë°˜ì˜í•œ ì •ë ¬ í–‰ë ¬ (ì¹´ë©”ë¼ ì¢Œí‘œ â†’ ë¡œë´‡ gripper ì¢Œí‘œ)
            T_camera_to_robot_coord = np.array([
                [ 0,  0,  1],
                [-1,  0,  0],
                [ 0, -1,  0]
            ])  # Z_cam â†’ X_robot, -X_cam â†’ Y_robot, -Y_cam â†’ Z_robot

            # ë³´ì • ì ìš©: R_ee2cam ë³´ì •
            R_corrected = T_camera_to_robot_coord @ R_ee2cam
            t_corrected = T_camera_to_robot_coord @ t_ee2cam
            
            print(f"ì›ë³¸ t_ee2cam: {t_ee2cam.flatten()}")
            print(f"ë³´ì •ëœ t_ee2cam: {t_corrected.flatten()}")
            
            return R_corrected, t_corrected  # ë³´ì •ëœ ê²°ê³¼ ë°˜í™˜
            
        except Exception as e:
            print(f"Hand-Eye calibration ê³„ì‚° ì˜¤ë¥˜: {e}")
            return None, None
    
    def test_calibration(self) -> bool:
        """
        ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
        """
        print("\n=== Cam-to-Gripper ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í…ŒìŠ¤íŠ¸ ===")
        
        try:
            # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼ ë¡œë“œ
            result_path = self.save_dir / "ee2cam.json"
            if not result_path.exists():
                print("ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            with open(result_path, 'r') as f:
                calibration_data = json.load(f)
            
            R_ee2cam = np.array(calibration_data["R_ee2cam"])
            t_ee2cam = np.array(calibration_data["t_ee2cam"])  # ë¯¸í„° ë‹¨ìœ„
            
            print("ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼:")
            print(f"R_ee2cam:\n{R_ee2cam}")
            
            # ì¢Œí‘œì¶• ë³€í™˜ ì •ë³´ í™•ì¸
            if "coordinate_transformation" in calibration_data:
                coord_info = calibration_data["coordinate_transformation"]
                print(f"\nì¢Œí‘œì¶• ë³€í™˜ ì ìš©ë¨:")
                print(f"ì„¤ëª…: {coord_info['description']}")
                print(f"ë³€í™˜ í–‰ë ¬:\n{np.array(coord_info['transformation_matrix'])}")
            
            # t_ee2cam ë‹¨ìœ„ í™•ì¸
            t_ee2cam_norm = np.linalg.norm(t_ee2cam)
            print(f"\nt_ee2cam í¬ê¸° (m): {t_ee2cam_norm:.3f}")
            
            # numpy ë°°ì—´ì„ ì•ˆì „í•˜ê²Œ floatë¡œ ë³€í™˜
            t_x = float(t_ee2cam.flatten()[0])
            t_y = float(t_ee2cam.flatten()[1])
            t_z = float(t_ee2cam.flatten()[2])
            print(f"t_ee2cam (m): [{t_x:.3f}, {t_y:.3f}, {t_z:.3f}]")
            
            # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìº¡ì²˜
            print("\ní…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìº¡ì²˜ ì¤‘...")
            color_path, depth_path, intrinsics_path = capture_d455_images(
                save_dir=str(self.save_dir),
                rgb_size=(848, 480),
                depth_size=(848, 480)
            )
            
            # ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„° ë¡œë“œ
            camera_matrix, dist_coeffs = self._load_camera_intrinsics(intrinsics_path)
            
            # ChArUco ê²€ì¶œ
            image = cv2.imread(color_path)
            charuco_pose = self.detect_charuco_pose(image, camera_matrix, dist_coeffs)
            
            if charuco_pose is None:
                print("í…ŒìŠ¤íŠ¸ì—ì„œ ChArUco ê²€ì¶œ ì‹¤íŒ¨")
                return False
            
            rvec, tvec, charuco_corners, charuco_ids = charuco_pose
            
            # ì¹´ë©”ë¼ -> ChArUco ë³€í™˜ (ë¯¸í„° ë‹¨ìœ„)
            R_cam2charuco, _ = cv2.Rodrigues(rvec)
            t_cam2charuco = tvec  # ë¯¸í„° ë‹¨ìœ„
            
            # í˜„ì¬ ë¡œë´‡ í¬ì¦ˆ (ë² ì´ìŠ¤ -> Gripper)
            robot_coords = self.robot.get_coords()
            robot_position_mm = np.array(robot_coords[0:3])
            robot_rotation_deg = np.array(robot_coords[3:6])
            
            # numpy ë°°ì—´ì„ ì•ˆì „í•˜ê²Œ floatë¡œ ë³€í™˜
            robot_x = float(robot_position_mm.flatten()[0])
            robot_y = float(robot_position_mm.flatten()[1])
            robot_z = float(robot_position_mm.flatten()[2])
            robot_rx = float(robot_rotation_deg.flatten()[0])
            robot_ry = float(robot_rotation_deg.flatten()[1])
            robot_rz = float(robot_rotation_deg.flatten()[2])
            
            print(f"\nì‹¤ì œ ë¡œë´‡ ìœ„ì¹˜ (ë² ì´ìŠ¤ ê¸°ì¤€):")
            print(f"End-Effector ìœ„ì¹˜: {robot_x:.1f}, {robot_y:.1f}, {robot_z:.1f}mm")
            print(f"End-Effector íšŒì „: {robot_rx:.1f}, {robot_ry:.1f}, {robot_rz:.1f}ë„")
            
            # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ í†µí•œ ê³„ì‚°
            # ì¹´ë©”ë¼ -> End-Effector ë³€í™˜ (ì´ë¯¸ ë¯¸í„° ë‹¨ìœ„)
            # ì¢Œí‘œì¶• ë³€í™˜ì„ ê³ ë ¤í•œ ê³„ì‚°
            charuco_in_ee = R_ee2cam @ t_cam2charuco + t_ee2cam.reshape(3, 1)
            charuco_in_ee_mm = charuco_in_ee.flatten() * 1000  # m -> mm (í‘œì‹œìš©)
            
            # numpy ë°°ì—´ì„ ì•ˆì „í•˜ê²Œ floatë¡œ ë³€í™˜
            charuco_x = float(charuco_in_ee_mm.flatten()[0])
            charuco_y = float(charuco_in_ee_mm.flatten()[1])
            charuco_z = float(charuco_in_ee_mm.flatten()[2])
            
            print(f"\nìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ í†µí•œ ChArUco ìœ„ì¹˜ ê³„ì‚°:")
            print(f"ì¹´ë©”ë¼ì—ì„œ ê³„ì‚°ëœ ChArUco ìœ„ì¹˜ (End-Effector ê¸°ì¤€): {charuco_x:.1f}, {charuco_y:.1f}, {charuco_z:.1f}mm")
            
            # ê±°ë¦¬ ê³„ì‚°
            distance = np.linalg.norm(charuco_in_ee_mm)
            distance_float = float(distance)
            print(f"ì¹´ë©”ë¼ì—ì„œ ê³„ì‚°ëœ ê±°ë¦¬: {distance_float:.1f}mm")
            
            # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¶œë ¥
            print(f"\nìº˜ë¦¬ë¸Œë ˆì´ì…˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
            print(f"End-Effector -> ì¹´ë©”ë¼ ë³€í™˜ í–‰ë ¬ì´ ì„±ê³µì ìœ¼ë¡œ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print(f"ì´ì œ ì¹´ë©”ë¼ì—ì„œ ê°ì§€ëœ ê°ì²´ì˜ í”½ì…€ ì¢Œí‘œë¥¼ ë¡œë´‡ End-Effector ê¸°ì¤€ 3D ì¢Œí‘œë¡œ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            return True
            
        except Exception as e:
            print(f"ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
            return False
    



def main():
    """
    ë©”ì¸ í•¨ìˆ˜
    """
    print("Cam-to-Gripper Calibration for MyCobot280")
    print("=" * 50)
    
    # ìº˜ë¦¬ë¸Œë ˆì´í„° ì´ˆê¸°í™” (ì‹¤ì œ ë³´ë“œ í¬ê¸°ì— ë§ì¶¤)
    calibrator = CamToGripperCalibrator(
        robot_port="/dev/ttyACM0",
        robot_baud=115200,
        save_dir="/home/ros/llm_robot/data/Calibration/Eye-in-Hand9",
        charuco_squares_x=9, 
        charuco_squares_y=6,   
        charuco_square_length=28.0, #/1000,  # mm (ì‹¤ì œ ì¸¡ì •ê°’)
        charuco_marker_length=21.0, #/1000,  # mm (ì‹¤ì œ ì¸¡ì •ê°’)
        min_charuco_corners=15,  # ìµœì†Œ ChArUco ì½”ë„ˆ ê°œìˆ˜ (ë” ì™„í™”)
        min_detection_confidence=0.2,  # ìµœì†Œ ê²€ì¶œ ì‹ ë¢°ë„ (ë”ìš± ì™„í™”)
        max_distance_threshold=0.7)  # ìµœëŒ€ ê±°ë¦¬ ì„ê³„ê°’ (ë¯¸í„°)
    
    
    try:
        print("\n=== ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì˜µì…˜ ===")
        print("1. ì‹¤ì‹œê°„ ê°ë„ ìˆ˜ì§‘ ëª¨ë“œ (ì¹´ë©”ë¼ í™”ë©´ í¬í•¨)")
        print("2. ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª¨ë“œ (ì €ì¥ëœ ê°ë„ ì‚¬ìš©)")
        print("3. ìˆ˜ë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª¨ë“œ (ê¸°ì¡´ ë°©ì‹)")
        print("4. í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰")
        print("5. ì¢…ë£Œ")
        
        choice = input("ì„ íƒ (1/2/3/4/5): ").strip()
        
        if choice == "1":
            # ì‹¤ì‹œê°„ ê°ë„ ìˆ˜ì§‘ ëª¨ë“œ (ì¹´ë©”ë¼ í™”ë©´ í¬í•¨)
            num_poses = int(input("\nìˆ˜ì§‘í•  í¬ì¦ˆ ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ê¶Œì¥: 25-30): ") or "25")
            print(f"\n{num_poses}ê°œì˜ í¬ì¦ˆë¡œ ì‹¤ì‹œê°„ ê°ë„ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            print("ì¹´ë©”ë¼ í™”ë©´ì´ í‘œì‹œë˜ë©°, ChArUco ê²€ì¶œ ìƒíƒœë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            print("ê° í¬ì¦ˆì—ì„œ 's'ë¥¼ ëˆŒëŸ¬ ì €ì¥í•˜ê±°ë‚˜ 'q'ë¥¼ ëˆŒëŸ¬ ì¢…ë£Œí•˜ì„¸ìš”.")
            
            collection_success = calibrator.collect_angles_with_camera_feed(num_poses)
            
            if collection_success:
                print("\nğŸ‰ ì‹¤ì‹œê°„ ê°ë„ ìˆ˜ì§‘ ì™„ë£Œ!")
                print("\nğŸ“Š ìˆ˜ì§‘ëœ ë°ì´í„°ë¡œ ee2cam.jsonì„ ìë™ ê³„ì‚°í•©ë‹ˆë‹¤...")
                calibration_success = calibrator.calculate_transformation_matrix()
                if calibration_success:
                    print("\nğŸ‰ Cam-to-Gripper ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ!")
                    test_choice = input("\nìº˜ë¦¬ë¸Œë ˆì´ì…˜ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower().strip()
                    if test_choice == 'y':
                        calibrator.test_calibration()
                else:
                    print("\nâŒ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹¤íŒ¨")
            else:
                print("\nâŒ ê°ë„ ìˆ˜ì§‘ ì‹¤íŒ¨")
                
        elif choice == "2":
            # ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª¨ë“œ
            print("\nì €ì¥ëœ ê°ë„ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            calibration_success = calibrator.perform_automatic_calibration()
            
            if calibration_success:
                print("\nï¿½ï¿½ Cam-to-Gripper ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ!")
                test_choice = input("\nìº˜ë¦¬ë¸Œë ˆì´ì…˜ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower().strip()
                if test_choice == 'y':
                    calibrator.test_calibration()
            else:
                print("\nâŒ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹¤íŒ¨")
                
        elif choice == "3":
            # ìˆ˜ë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª¨ë“œ (ê¸°ì¡´ ë°©ì‹)
            num_poses = int(input("\nìº¡ì²˜í•  í¬ì¦ˆ ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ê¶Œì¥: 25-30): ") or "25")
            print(f"\n{num_poses}ê°œì˜ í¬ì¦ˆë¡œ ìˆ˜ë™ Cam-to-Gripper ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            calibration_success = calibrator.perform_manual_calibration(num_poses)
            
            if calibration_success:
                print("\nğŸ‰ Cam-to-Gripper ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ!")
                test_choice = input("\nìº˜ë¦¬ë¸Œë ˆì´ì…˜ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower().strip()
                if test_choice == 'y':
                    calibrator.test_calibration()
            else:
                print("\nâŒ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹¤íŒ¨")
                
        elif choice == "4":
            # í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰
            calibrator.test_calibration()
        else:
            print("\nì¢…ë£Œí•©ë‹ˆë‹¤.")
            
    except KeyboardInterrupt:
        print("\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()