{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e908a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from scipy.optimize import least_squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd6f4d2",
   "metadata": {},
   "source": [
    "# Eye-in-Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07191cab",
   "metadata": {},
   "source": [
    "## 1. 초기 R, t Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e6389dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = \"/home/ros/llm_robot/data/Calibration/Eye-to-Hand\"\n",
    "with open(f\"{MAIN_PATH}/cam2ee.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "R_cam2ee = np.array(data[\"R_cam2ee\"])\n",
    "t_cam2ee = np.array(data[\"t_cam2ee\"]).reshape(3)\n",
    "q_init = R.from_matrix(R_cam2ee).as_quat()\n",
    "x0 = np.hstack((q_init, t_cam2ee))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2b0af8",
   "metadata": {},
   "source": [
    "## 2. pose 및 charuco load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4af2e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_pose_files = sorted(glob(f\"{MAIN_PATH}/poses/*.json\"))\n",
    "sorted_charuco_files = sorted(glob(f\"{MAIN_PATH}/*.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b1c7be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_pose_files), len(sorted_charuco_files[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9286588",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_data = []\n",
    "for pf, cf in zip(sorted_pose_files, sorted_charuco_files[:-1]):\n",
    "    with open(pf) as f: pose = json.load(f)\n",
    "    with open(cf) as f: charuco = json.load(f)\n",
    "    \n",
    "    R_base2ee = np.array(pose[\"R_base2ee\"])\n",
    "    t_base2ee = np.array(pose[\"t_base2ee\"]).reshape(3)\n",
    "    \n",
    "    rvec = np.array(charuco[\"rvec_target2cam\"]).reshape(3)\n",
    "    tvec = np.array(charuco[\"tvec_target2cam\"]).reshape(3)\n",
    "    R_board2cam = R.from_rotvec(rvec).as_matrix()\n",
    "    t_board2cam = tvec\n",
    "    \n",
    "    pose_data.append({\n",
    "        \"R_base2ee\": R_base2ee,\n",
    "        \"t_base2ee\": t_base2ee,\n",
    "        \"R_board2cam\": R_board2cam,\n",
    "        \"t_board2cam\": t_board2cam\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaf9129",
   "metadata": {},
   "source": [
    "## 3. 최적화 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49d0a2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residuals(x, data):\n",
    "    q = x[:4]\n",
    "    t = x[4:]\n",
    "    R_cam2ee = R.from_quat(q).as_matrix()\n",
    "    t_cam2ee = t\n",
    "    res = []\n",
    "    for d in data:\n",
    "        # 예측: T_base2board = T_cam2ee × T_base2ee × T_ee2board\n",
    "        R_pred = R_cam2ee @ d[\"R_base2ee\"] @ d[\"R_board2cam\"]\n",
    "        t_pred = R_cam2ee @ d[\"R_base2ee\"] @ d[\"t_board2cam\"] + R_cam2ee @ d[\"t_base2ee\"] + t_cam2ee\n",
    "        \n",
    "        R_err = R.from_matrix(R_pred).as_rotvec()\n",
    "        t_err = t_pred  # 실제 board가 base 기준 원점에 있을 필요 없음\n",
    "\n",
    "        res.extend(R_err)\n",
    "        res.extend(t_err)\n",
    "    \n",
    "    res.append(np.linalg.norm(q) - 1)  # 단위 quaternion 제약\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6ca9acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     message: `ftol` termination condition is satisfied.\n",
       "     success: True\n",
       "      status: 2\n",
       "         fun: [ 2.754e-02 -3.353e-01 ...  3.159e-01  5.270e-08]\n",
       "           x: [ 6.955e-01  5.667e-01 -2.335e-01 -3.749e-01  1.104e-01\n",
       "               -1.412e-01  1.630e-01]\n",
       "        cost: 17.523990818727206\n",
       "         jac: [[-9.354e-01  6.917e-01 ...  0.000e+00  0.000e+00]\n",
       "               [-4.769e-01 -7.345e-01 ...  0.000e+00  0.000e+00]\n",
       "               ...\n",
       "               [-1.799e-01 -4.107e-02 ...  0.000e+00  1.000e+00]\n",
       "               [ 6.955e-01  5.667e-01 ...  0.000e+00  0.000e+00]]\n",
       "        grad: [ 2.136e-04 -2.105e-04 -2.530e-05  9.358e-05 -1.689e-08\n",
       "               -1.059e-09  1.488e-08]\n",
       "  optimality: 0.00021357146433181108\n",
       " active_mask: [0 0 0 0 0 0 0]\n",
       "        nfev: 65\n",
       "        njev: None"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = least_squares(residuals, x0, args=(pose_data,), method='lm')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c43637e",
   "metadata": {},
   "source": [
    "## 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75d91ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: optimized_cam2ee_LM.json\n"
     ]
    }
   ],
   "source": [
    "# === 결과 추출 ===\n",
    "q_opt = result.x[:4] / np.linalg.norm(result.x[:4])\n",
    "t_opt = result.x[4:]\n",
    "R_opt = R.from_quat(q_opt).as_matrix()\n",
    "\n",
    "# === 저장 (Eye-to-Hand 포맷)\n",
    "result_dict = {\n",
    "    \"R_cam2ee\": R_opt.tolist(),\n",
    "    \"t_cam2ee\": (t_opt / 1000).tolist()  # 단위 맞춰서 저장 (m 기준)\n",
    "}\n",
    "with open(\"optimized_cam2ee_LM.json\", \"w\") as f:\n",
    "    json.dump(result_dict, f, indent=2)\n",
    "\n",
    "print(\"✅ 저장 완료: optimized_cam2ee_LM.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3273b2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a7a5b71",
   "metadata": {},
   "source": [
    "# Eye-to-Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "526279f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = \"/home/ros/llm_robot/data/Calibration/Eye-to-Hand11\"\n",
    "\n",
    "with open(f\"{MAIN_PATH}/cam2base_table_normal_fix.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "R_cam2base_init = np.array(data[\"R_cam2base\"]).reshape(3, 3)\n",
    "t_cam2base_init = np.array(data[\"t_cam2base\"]).reshape(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38da98f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_pose_files = sorted(glob(f\"{MAIN_PATH}/poses/*.json\"))\n",
    "sorted_charuco_files = sorted(glob(f\"{MAIN_PATH}/*_charuco.json\"))\n",
    "len(sorted_pose_files), len(sorted_charuco_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b666a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_data = []\n",
    "for pf, cf in zip(sorted_pose_files, sorted_charuco_files):\n",
    "    with open(pf) as f: pose = json.load(f)\n",
    "    with open(cf) as f: charuco = json.load(f)\n",
    "    \n",
    "    R_base2ee = np.array(pose[\"R_base2ee\"])\n",
    "    t_base2ee = np.array(pose[\"t_base2ee\"]).reshape(3)\n",
    "    \n",
    "    rvec = np.array(charuco[\"rvec_target2cam\"]).reshape(3)\n",
    "    tvec = np.array(charuco[\"tvec_target2cam\"]).reshape(3, 1)\n",
    "    R_board2cam = R.from_rotvec(rvec).as_matrix()\n",
    "    t_board2cam = tvec\n",
    "    \n",
    "    pose_data.append({\n",
    "        \"R_base2ee\": R_base2ee,\n",
    "        \"t_base2ee\": t_base2ee,\n",
    "        \"R_board2cam\": R_board2cam,\n",
    "        \"t_board2cam\": t_board2cam\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f6d018",
   "metadata": {},
   "source": [
    "## 초기값 추정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7af8d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residuals(x, pose_data):\n",
    "    # x: [rvec(3), tvec(3)]\n",
    "    rvec_cam2base = x[:3]\n",
    "    tvec_cam2base = x[3:]\n",
    "    \n",
    "    R_cam2base, _ = cv2.Rodrigues(rvec_cam2base)\n",
    "    t_cam2base = tvec_cam2base.reshape(3, 1)\n",
    "    \n",
    "    T_cam2base = np.eye(4)\n",
    "    T_cam2base[:3, :3] = R_cam2base\n",
    "    T_cam2base[:3, 3] = t_cam2base.flatten()\n",
    "\n",
    "    all_residuals = []\n",
    "    for data in pose_data:\n",
    "        # Construct the known transformation matrices for the current pose\n",
    "        R_base2ee = data[\"R_base2ee\"]\n",
    "        t_base2ee = data[\"t_base2ee\"].reshape(3, 1)\n",
    "        T_base2ee = np.eye(4)\n",
    "        T_base2ee[:3, :3] = R_base2ee\n",
    "        T_base2ee[:3, 3] = t_base2ee.flatten()\n",
    "\n",
    "        R_board2cam = data[\"R_board2cam\"]\n",
    "        t_board2cam = data[\"t_board2cam\"].reshape(3, 1)\n",
    "        T_board2cam = np.eye(4)\n",
    "        T_board2cam[:3, :3] = R_board2cam\n",
    "        T_board2cam[:3, 3] = t_board2cam.flatten()\n",
    "\n",
    "        # Calculate the left and right sides of the core hand-eye equation\n",
    "        LHS = T_base2ee @ T_cam2base\n",
    "        RHS = T_cam2base @ T_board2cam\n",
    "\n",
    "        # Compute the error between the two sides\n",
    "        # The error is the transformation required to go from RHS to LHS.\n",
    "        error_matrix = np.linalg.inv(RHS) @ LHS\n",
    "        \n",
    "        # Convert the error matrix into a rotation vector and translation vector\n",
    "        # These vectors form the residuals to be minimized\n",
    "        error_rvec, _ = cv2.Rodrigues(error_matrix[:3, :3])\n",
    "        error_tvec = error_matrix[:3, 3]\n",
    "\n",
    "        # Add the rotation and translation errors to the list of residuals\n",
    "        all_residuals.extend(error_rvec.flatten())\n",
    "        all_residuals.extend(error_tvec.flatten())\n",
    "\n",
    "    return np.array(all_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a38417f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized cam2base saved.\n"
     ]
    }
   ],
   "source": [
    "rvec_init, _ = cv2.Rodrigues(R_cam2base_init)\n",
    "x0 = np.concatenate((rvec_init.flatten(), t_cam2base_init.flatten()))\n",
    "\n",
    "# Run the optimization\n",
    "res = least_squares(residuals, x0, args=(pose_data,), method='lm')\n",
    "\n",
    "# Extract and save the optimal result\n",
    "r_opt = res.x[:3]\n",
    "t_opt = res.x[3:].reshape(3, 1)\n",
    "R_opt, _ = cv2.Rodrigues(r_opt)\n",
    "\n",
    "output = {\n",
    "    \"R_cam2base\": R_opt.tolist(),\n",
    "    \"t_cam2base\": t_opt.flatten().tolist()\n",
    "}\n",
    "\n",
    "with open(f\"{MAIN_PATH}/cam2base_LM.json\", \"w\") as f:\n",
    "    json.dump(output, f, indent=4)\n",
    "\n",
    "print(\"Optimized cam2base saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6a2a0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R_cam2base': [[0.014074200871944553, 0.611250353865447, -0.791312151915527],\n",
       "  [0.17873624888877834, 0.7771063002381774, 0.6034560062368264],\n",
       "  [0.9837963560630753, -0.1499293267826468, -0.0983154452134426]],\n",
       " 't_cam2base': [-0.07404576929589952,\n",
       "  0.02806981208166249,\n",
       "  0.06507380795569544]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d79642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
