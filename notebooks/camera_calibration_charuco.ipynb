{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c68b664f",
   "metadata": {},
   "source": [
    "### 카메라 내부 캘리브레이션\n",
    "- 갖고있는 데이터를 활용하여 캘리브레이션을 진행해보자.\n",
    "- 보드: 차루코보드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a70db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(\"/home/ros/llm_robot/\")\n",
    "from utils.camera import capture_d455_images, load_intrinsics\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fb5dc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_charuco_board():\n",
    "    # 1. ArUco 딕셔너리 정의\n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_50)\n",
    "\n",
    "    # 2. ChArUco 보드 생성\n",
    "    charuco_board = cv2.aruco.CharucoBoard(\n",
    "        size=(7, 5),\n",
    "        squareLength=0.028,     # m\n",
    "        markerLength=0.013,     # m\n",
    "        dictionary=aruco_dict\n",
    "    )\n",
    "    return charuco_board\n",
    "\n",
    "def read_gray_image(c_path):\n",
    "    # 4. 이미지 로드 및 그레이스케일 변환 + CLAHE 적용\n",
    "    #    조명 조건에 관계없이 안정적으로 코너를 검출하도록 대비 향상\n",
    "    img = cv2.imread(c_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    \n",
    "    return gray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d67288f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 25)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAIN_DIR = \"/home/ros/llm_robot/data/Calibration/Eye-to-Hand11\"\n",
    "\n",
    "intr_dir = sorted(glob(f\"{MAIN_DIR}/intrinsics/*.json\"))\n",
    "c_dir = sorted(glob(f\"{MAIN_DIR}/color/*.jpg\"))\n",
    "\n",
    "len(intr_dir), len(c_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "961e7699",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_matrix, dist_coeffs = load_intrinsics(intr_dir[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30228cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCorners = []\n",
    "allIds = []\n",
    "imgSize = None  \n",
    "\n",
    "for c_path in c_dir:\n",
    "    # 3. ChArUco 디텍터 생성\n",
    "    charuco_board = get_charuco_board()\n",
    "    detector = cv2.aruco.CharucoDetector(charuco_board)\n",
    "    gray = read_gray_image(c_path)\n",
    "\n",
    "    # 5. 내부 코너 및 마커 검출 (detectBoard)\n",
    "    charuco_corners, charuco_ids, marker_corners, marker_ids = detector.detectBoard(gray)\n",
    "    \n",
    "    if charuco_corners is not None and charuco_ids is not None and len(charuco_corners) > 0:\n",
    "        allCorners.append(charuco_corners)\n",
    "        allIds.append(charuco_ids)\n",
    "        imgSize = gray.shape[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02fa6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, camera_matrix2, dist_coeffs2, rvecs, tvecs = cv2.aruco.calibrateCameraCharuco(\n",
    "    allCorners, allIds,\n",
    "    charuco_board, imgSize,\n",
    "    camera_matrix, dist_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e50d38c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[425.4894 ,   0.     , 427.1854 ],\n",
       "        [  0.     , 424.91083, 245.99588],\n",
       "        [  0.     ,   0.     ,   1.     ]], dtype=float32),\n",
       " array([-0.05594644,  0.06878078, -0.00011233,  0.00074334, -0.02200594],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_matrix, dist_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a4622e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[420.75176178,   0.        , 429.06025809],\n",
       "        [  0.        , 420.24855903, 244.88823229],\n",
       "        [  0.        ,   0.        ,   1.        ]]),\n",
       " array([[-0.06766468],\n",
       "        [ 0.07548154],\n",
       "        [-0.00126559],\n",
       "        [ 0.0005072 ],\n",
       "        [-0.02807756]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_matrix2, dist_coeffs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "140f2612",
   "metadata": {},
   "outputs": [],
   "source": [
    "fx = camera_matrix2[0,0]\n",
    "fy = camera_matrix2[1,1]\n",
    "ppx = camera_matrix2[0,2]\n",
    "ppy = camera_matrix2[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "514b9a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'color_intrinsics': {'width': 848,\n",
       "  'height': 480,\n",
       "  'fx': np.float64(420.7517617775355),\n",
       "  'fy': np.float64(420.24855903289927),\n",
       "  'ppx': np.float64(429.0602580915742),\n",
       "  'ppy': np.float64(244.8882322853532),\n",
       "  'distortion_model': 'distortion.inverse_brown_conrady',\n",
       "  'distortion_coeffs': [-0.06766467955296547,\n",
       "   0.07548153843496587,\n",
       "   -0.0012655901589318334,\n",
       "   0.0005071996336020576,\n",
       "   -0.02807756171443588]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 저장 (미터 단위)\n",
    "camera_intrinsics_result = {\n",
    "  \"color_intrinsics\": {\n",
    "    \"width\": 848,\n",
    "    \"height\": 480,\n",
    "    \"fx\": fx,\n",
    "    \"fy\": fy,\n",
    "    \"ppx\": ppx,\n",
    "    \"ppy\": ppy,\n",
    "    \"distortion_model\": \"distortion.inverse_brown_conrady\",\n",
    "    \"distortion_coeffs\": dist_coeffs2.flatten().tolist()\n",
    "  }\n",
    "}\n",
    "camera_intrinsics_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cbe496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = f\"{MAIN_DIR}/camera_intrinsics_result.json\"\n",
    "with open(result_path, 'w') as f:\n",
    "    json.dump(camera_intrinsics_result, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42d257a",
   "metadata": {},
   "source": [
    "## 새롭게 정의한 calibration 결과로 재계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e3d0db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 25)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장된 데이터 로드\n",
    "pose_dir = sorted(glob(f\"{MAIN_DIR}/poses/*.json\"))\n",
    "charuco_dir = sorted(glob(f\"{MAIN_DIR}/*.json\"))[:25]\n",
    "len(charuco_dir), len(pose_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2cf465c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 25개의 포즈 데이터를 로드합니다...\n",
      "포즈 1: charuco_corners, 거리=579.7mm, 품질=0.801\n",
      "포즈 2: charuco_corners, 거리=509.8mm, 품질=0.359\n",
      "포즈 3: charuco_corners, 거리=344.2mm, 품질=1.122\n",
      "포즈 4: charuco_corners, 거리=369.6mm, 품질=0.399\n",
      "포즈 5: charuco_corners, 거리=464.1mm, 품질=0.423\n",
      "포즈 6: charuco_corners, 거리=614.9mm, 품질=0.738\n",
      "포즈 7: charuco_corners, 거리=553.4mm, 품질=0.829\n",
      "포즈 8: charuco_corners, 거리=336.5mm, 품질=1.093\n",
      "포즈 9: charuco_corners, 거리=426.7mm, 품질=0.382\n",
      "포즈 10: charuco_corners, 거리=345.8mm, 품질=0.963\n",
      "포즈 11: charuco_corners, 거리=497.2mm, 품질=0.328\n",
      "포즈 12: charuco_corners, 거리=396.8mm, 품질=1.163\n",
      "포즈 13: charuco_corners, 거리=290.4mm, 품질=1.037\n",
      "포즈 14: charuco_corners, 거리=373.2mm, 품질=1.029\n",
      "포즈 15: charuco_corners, 거리=296.5mm, 품질=1.076\n",
      "포즈 16: charuco_corners, 거리=446.6mm, 품질=0.418\n",
      "포즈 17: charuco_corners, 거리=323.0mm, 품질=1.164\n",
      "포즈 18: charuco_corners, 거리=382.1mm, 품질=1.142\n",
      "포즈 19: charuco_corners, 거리=244.3mm, 품질=1.282\n",
      "포즈 20: charuco_corners, 거리=428.2mm, 품질=0.360\n",
      "포즈 21: charuco_corners, 거리=376.6mm, 품질=1.125\n",
      "포즈 22: charuco_corners, 거리=349.8mm, 품질=1.110\n",
      "포즈 23: charuco_corners, 거리=296.5mm, 품질=1.221\n",
      "포즈 24: charuco_corners, 거리=280.0mm, 품질=0.550\n",
      "포즈 25: charuco_corners, 거리=258.4mm, 품질=0.540\n",
      "\n",
      "품질 점수 기반 가중치:\n",
      "  포즈 1: 품질=0.039, 가중치=0.039\n",
      "  포즈 2: 품질=0.017, 가중치=0.017\n",
      "  포즈 3: 품질=0.054, 가중치=0.054\n",
      "  포즈 4: 품질=0.019, 가중치=0.019\n",
      "  포즈 5: 품질=0.020, 가중치=0.020\n",
      "  포즈 6: 품질=0.036, 가중치=0.036\n",
      "  포즈 7: 품질=0.040, 가중치=0.040\n",
      "  포즈 8: 품질=0.053, 가중치=0.053\n",
      "  포즈 9: 품질=0.019, 가중치=0.019\n",
      "  포즈 10: 품질=0.047, 가중치=0.047\n",
      "  포즈 11: 품질=0.016, 가중치=0.016\n",
      "  포즈 12: 품질=0.056, 가중치=0.056\n",
      "  포즈 13: 품질=0.050, 가중치=0.050\n",
      "  포즈 14: 품질=0.050, 가중치=0.050\n",
      "  포즈 15: 품질=0.052, 가중치=0.052\n",
      "  포즈 16: 품질=0.020, 가중치=0.020\n",
      "  포즈 17: 품질=0.056, 가중치=0.056\n",
      "  포즈 18: 품질=0.055, 가중치=0.055\n",
      "  포즈 19: 품질=0.062, 가중치=0.062\n",
      "  포즈 20: 품질=0.017, 가중치=0.017\n",
      "  포즈 21: 품질=0.054, 가중치=0.054\n",
      "  포즈 22: 품질=0.054, 가중치=0.054\n",
      "  포즈 23: 품질=0.059, 가중치=0.059\n",
      "  포즈 24: 품질=0.027, 가중치=0.027\n",
      "  포즈 25: 품질=0.026, 가중치=0.026\n"
     ]
    }
   ],
   "source": [
    "T_base2ee_list = []  # 로봇 베이스 -> End-Effector (미터 단위)\n",
    "T_cam2target_list = []  # 카메라 -> ChArUco 타겟 (미터 단위)\n",
    "quality_weights = []  # 품질 점수를 가중치로 사용\n",
    "\n",
    "print(f\"총 {len(charuco_dir)}개의 포즈 데이터를 로드합니다...\")\n",
    "\n",
    "# 모든 charuco 파일을 사용 (ChArUco 코너 기반과 ArUco 마커 기반 모두 포함)\n",
    "valid_charuco_files = []\n",
    "\n",
    "for i, charuco_file in enumerate(charuco_dir):\n",
    "    # ChArUco 포즈 로드 (타겟 -> 카메라) - Eye-to-Hand 구조\n",
    "    with open(charuco_file, 'r') as f:\n",
    "        charuco_data = json.load(f)\n",
    "    \n",
    "    # 품질 점수를 가중치로 사용\n",
    "    quality_score = charuco_data.get(\"quality_score\", 0.5)  # 기본값 0.5\n",
    "    quality_weights.append(quality_score)\n",
    "    \n",
    "    # 새로운 형식에서는 target2cam 데이터를 사용\n",
    "    if \"rvec_target2cam\" in charuco_data:\n",
    "        rvec = np.array(charuco_data[\"rvec_target2cam\"])\n",
    "        tvec = np.array(charuco_data[\"tvec_target2cam\"])\n",
    "    else:\n",
    "        # 기존 형식 호환성을 위해 역행렬 계산\n",
    "        rvec_old = np.array(charuco_data[\"rvec\"])\n",
    "        tvec_old = np.array(charuco_data[\"tvec\"])\n",
    "        R_cam2target, _ = cv2.Rodrigues(rvec_old)\n",
    "        R_target2cam = R_cam2target.T\n",
    "        t_target2cam = -R_target2cam @ tvec_old\n",
    "        rvec = cv2.Rodrigues(R_target2cam)[0]\n",
    "        tvec = t_target2cam\n",
    "    \n",
    "    # 회전 벡터를 회전 행렬로 변환\n",
    "    R_cam2target, _ = cv2.Rodrigues(rvec)\n",
    "    \n",
    "    # 카메라 -> 타겟 (미터 단위) - Eye-to-Hand 구조에 맞게 수정\n",
    "    T_cam2target = np.eye(4)\n",
    "    T_cam2target[:3, :3] = R_cam2target.T  # 역행렬\n",
    "    T_cam2target[:3, 3] = -R_cam2target.T @ tvec.flatten()  # 역변환\n",
    "    T_cam2target_list.append(T_cam2target)\n",
    "    \n",
    "    # 로봇 포즈 처리 (pose 파일이 있는 경우)\n",
    "    if i < len(pose_dir) and pose_dir[i] is not None:\n",
    "        with open(pose_dir[i], 'r') as f:\n",
    "            pose_data = json.load(f)\n",
    "        \n",
    "        t_base2ee = np.array(pose_data[\"t_base2ee\"])\n",
    "        R_base2ee = np.array(pose_data[\"R_base2ee\"])\n",
    "    \n",
    "    # 로봇 베이스 -> End-Effector (미터 단위)\n",
    "    T_base2ee = np.eye(4)\n",
    "    T_base2ee[:3, :3] = R_base2ee\n",
    "    T_base2ee[:3, 3] = t_base2ee.flatten()\n",
    "    T_base2ee_list.append(T_base2ee)\n",
    "    \n",
    "    # 디버그 정보\n",
    "    detection_method = charuco_data.get(\"detection_method\", \"unknown\")\n",
    "    distance_mm = charuco_data.get(\"distance_mm\", 0)\n",
    "    print(f\"포즈 {i+1}: {detection_method}, 거리={distance_mm:.1f}mm, 품질={quality_score:.3f}\")\n",
    "\n",
    "# 품질 점수 기반 가중치 정규화\n",
    "quality_weights = np.array(quality_weights)\n",
    "quality_weights = quality_weights / np.sum(quality_weights)  # 합이 1이 되도록 정규화\n",
    "\n",
    "print(f\"\\n품질 점수 기반 가중치:\")\n",
    "for i, (weight, score) in enumerate(zip(quality_weights, quality_weights * np.sum(quality_weights))):\n",
    "    print(f\"  포즈 {i+1}: 품질={score:.3f}, 가중치={weight:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae15d53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eye-to-Hand calibration 계산 중...\n"
     ]
    }
   ],
   "source": [
    "# Eye-to-Hand calibration 수행 (가중치 포함)\n",
    "print(\"\\nEye-to-Hand calibration 계산 중...\")\n",
    "R_cam2base_list = []\n",
    "t_cam2base_list = []\n",
    "\n",
    "for i, (T_cam2target, T_base2ee) in enumerate(zip(T_cam2target_list, T_base2ee_list)):\n",
    "    # T_cam2base = T_cam2target * T_base2ee.inverse()\n",
    "    T_base2ee_inv = np.linalg.inv(T_base2ee)\n",
    "    T_cam2base = T_cam2target @ T_base2ee_inv\n",
    "    \n",
    "    R_cam2base = T_cam2base[:3, :3]\n",
    "    t_cam2base = T_cam2base[:3, 3]\n",
    "    \n",
    "    R_cam2base_list.append(R_cam2base)\n",
    "    t_cam2base_list.append(t_cam2base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d03e9048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_cam2base 크기 (m): 0.568\n",
      "단위: 미터 (표준 단위)\n"
     ]
    }
   ],
   "source": [
    "if R_cam2base is not None:\n",
    "    # 결과는 미터 단위로 반환됨\n",
    "    t_cam2base_norm = np.linalg.norm(t_cam2base)\n",
    "    print(f\"t_cam2base 크기 (m): {t_cam2base_norm:.3f}\")\n",
    "    \n",
    "    # 미터 단위로 저장 (표준 단위)\n",
    "    print(f\"단위: 미터 (표준 단위)\")\n",
    "    \n",
    "    # 변환 행렬 생성\n",
    "    T_cam2base = np.eye(4)\n",
    "    T_cam2base[:3, :3] = R_cam2base\n",
    "    T_cam2base[:3, 3] = t_cam2base.flatten()\n",
    "    \n",
    "    # 결과 저장 (미터 단위)\n",
    "    calibration_result = {\n",
    "        \"R_cam2base\": R_cam2base.tolist(),\n",
    "        \"t_cam2base\": t_cam2base.flatten().tolist(),  # 미터 단위로 저장\n",
    "        \"num_poses\": len(T_base2ee_list),\n",
    "        \"description\": \"카메라 -> 로봇 베이스 변환 행렬 (Eye-to-Hand calibration, 미터 단위, 품질 가중치 적용)\",\n",
    "        \"coordinate_transformation\": {\n",
    "            \"applied\": False,\n",
    "            \"description\": \"축보정 미적용 - 원본 카메라 좌표계 유지\"\n",
    "        },\n",
    "        \"quality_weighting\": {\n",
    "            \"applied\": True,\n",
    "            \"description\": \"품질 점수 기반 가중치 적용\",\n",
    "            \"weights\": quality_weights.tolist(),\n",
    "            \"quality_scores\": (quality_weights * np.sum(quality_weights)).tolist()\n",
    "        }\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2679dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R_cam2base': [[0.01537349129400446,\n",
       "   0.999876060574215,\n",
       "   -0.0033940029496022056],\n",
       "  [0.9901820721987494, -0.014752607420565604, 0.13900296568953274],\n",
       "  [0.13893566734868304, -0.005497641756554601, -0.9902861486830423]],\n",
       " 't_cam2base': [0.11749627956124493, -0.11307452232903055, 0.5436150456837687],\n",
       " 'num_poses': 25,\n",
       " 'description': '카메라 -> 로봇 베이스 변환 행렬 (Eye-to-Hand calibration, 미터 단위, 품질 가중치 적용)',\n",
       " 'coordinate_transformation': {'applied': False,\n",
       "  'description': '축보정 미적용 - 원본 카메라 좌표계 유지'},\n",
       " 'quality_weighting': {'applied': True,\n",
       "  'description': '품질 점수 기반 가중치 적용',\n",
       "  'weights': [0.03878858110019707,\n",
       "   0.017393150512256404,\n",
       "   0.054337339230141224,\n",
       "   0.019330329023867433,\n",
       "   0.020455039517460916,\n",
       "   0.035731402239442024,\n",
       "   0.04015702022070649,\n",
       "   0.05290544182717898,\n",
       "   0.018513709311729968,\n",
       "   0.046631036292397024,\n",
       "   0.015886561685427094,\n",
       "   0.05632195608584499,\n",
       "   0.050181412000155974,\n",
       "   0.04982087645185263,\n",
       "   0.05210830324865061,\n",
       "   0.020214553466307367,\n",
       "   0.05635547545788029,\n",
       "   0.05526380430245772,\n",
       "   0.06208442347166379,\n",
       "   0.01742120179280785,\n",
       "   0.054466166274560295,\n",
       "   0.053757491535861956,\n",
       "   0.05909636152157709,\n",
       "   0.026612869683657663,\n",
       "   0.026165493745917236],\n",
       "  'quality_scores': [0.03878858110019707,\n",
       "   0.017393150512256404,\n",
       "   0.054337339230141224,\n",
       "   0.019330329023867433,\n",
       "   0.020455039517460916,\n",
       "   0.035731402239442024,\n",
       "   0.04015702022070649,\n",
       "   0.05290544182717898,\n",
       "   0.018513709311729968,\n",
       "   0.046631036292397024,\n",
       "   0.015886561685427094,\n",
       "   0.05632195608584499,\n",
       "   0.050181412000155974,\n",
       "   0.04982087645185263,\n",
       "   0.05210830324865061,\n",
       "   0.020214553466307367,\n",
       "   0.05635547545788029,\n",
       "   0.05526380430245772,\n",
       "   0.06208442347166379,\n",
       "   0.01742120179280785,\n",
       "   0.054466166274560295,\n",
       "   0.053757491535861956,\n",
       "   0.05909636152157709,\n",
       "   0.026612869683657663,\n",
       "   0.026165493745917236]}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibration_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b457547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Eye-to-Hand 캘리브레이션 완료!\n",
      "결과 저장: /home/ros/llm_robot/data/Calibration/Eye-to-Hand10/cam2base2.json\n",
      "카메라 -> 로봇 베이스 변환 행렬:\n",
      "R:\n",
      "[[ 0.01537349  0.99987606 -0.003394  ]\n",
      " [ 0.99018207 -0.01475261  0.13900297]\n",
      " [ 0.13893567 -0.00549764 -0.99028615]]\n",
      "t (m): [0.117, -0.113, 0.544]\n",
      "품질 가중치 적용됨: 25개 포즈\n"
     ]
    }
   ],
   "source": [
    "result_path = f\"{MAIN_DIR}/cam2base2.json\"\n",
    "with open(result_path, 'w') as f:\n",
    "    json.dump(calibration_result, f, indent=2)\n",
    "\n",
    "# numpy 배열을 안전하게 float로 변환\n",
    "t_x = float(t_cam2base.flatten()[0])\n",
    "t_y = float(t_cam2base.flatten()[1])\n",
    "t_z = float(t_cam2base.flatten()[2])\n",
    "\n",
    "print(f\"✅ Eye-to-Hand 캘리브레이션 완료!\")\n",
    "print(f\"결과 저장: {result_path}\")\n",
    "print(f\"카메라 -> 로봇 베이스 변환 행렬:\")\n",
    "print(f\"R:\\n{R_cam2base}\")\n",
    "print(f\"t (m): [{t_x:.3f}, {t_y:.3f}, {t_z:.3f}]\")\n",
    "print(f\"품질 가중치 적용됨: {len(quality_weights)}개 포즈\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bd2d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
