{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2be28df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from glob import glob\n",
    "import os\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1e2e65",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ff1d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_pose_files = sorted(glob(\"/home/ros/llm_robot/data/Calibration/Eye-in-Hand2/poses/*.json\"))\n",
    "sorted_charuco_files = sorted(glob(\"/home/ros/llm_robot/data/Calibration/Eye-in-Hand2/*.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cfdaa7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 21)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_pose_files), len(sorted_charuco_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c3d774",
   "metadata": {},
   "source": [
    "## 2. Pose, Charuco 로드 및 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f6f6f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_gripper2base_all = []\n",
    "t_gripper2base_all = []\n",
    "R_target2cam_all = []\n",
    "t_target2cam_all = []\n",
    "\n",
    "for pf, cf in zip(sorted_pose_files, sorted_charuco_files[:-1]):\n",
    "    with open(pf, \"r\") as f:\n",
    "        pose = json.load(f)\n",
    "    with open(cf, \"r\") as f:\n",
    "        charuco = json.load(f)\n",
    "\n",
    "    R_base2ee = np.array(pose[\"R_base2ee\"])\n",
    "    t_base2ee = np.array(pose[\"t_base2ee\"]).reshape(3)\n",
    "\n",
    "    rvec = np.array(charuco[\"rvec\"]).reshape(3)\n",
    "    tvec = np.array(charuco[\"tvec\"]).reshape(3)\n",
    "    R_board2cam = cv2.Rodrigues(rvec)[0]\n",
    "    t_board2cam = tvec\n",
    "\n",
    "    R_gripper2base_all.append(R_base2ee.T)\n",
    "    t_gripper2base_all.append(-R_base2ee.T @ t_base2ee)\n",
    "    R_target2cam_all.append(R_board2cam)\n",
    "    t_target2cam_all.append(t_board2cam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2477f10c",
   "metadata": {},
   "source": [
    "## 3. RNASAC 기반 Tsai-Lenz 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd7a2291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ransac_handeye(Rg2b_all, tg2b_all, Rt2c_all, tt2c_all, n_iter=100, sample_size=6, threshold=0.01):\n",
    "    best_inliers = []\n",
    "    best_R = None\n",
    "    best_t = None\n",
    "    n_total = len(Rg2b_all)\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        if n_total < sample_size:\n",
    "            continue\n",
    "        indices = random.sample(range(n_total), sample_size)\n",
    "        Rg2b = [Rg2b_all[i] for i in indices]\n",
    "        tg2b = [tg2b_all[i] for i in indices]\n",
    "        Rt2c = [Rt2c_all[i] for i in indices]\n",
    "        tt2c = [tt2c_all[i] for i in indices]\n",
    "\n",
    "        try:\n",
    "            R_est, t_est = cv2.calibrateHandEye(Rg2b, tg2b, Rt2c, tt2c, method=cv2.CALIB_HAND_EYE_TSAI)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        inliers = []\n",
    "        for i in range(n_total):\n",
    "            R_pred = Rg2b_all[i] @ R_est\n",
    "            R_err = R_pred @ R_target2cam_all[i].T\n",
    "            angle_error = np.linalg.norm(cv2.Rodrigues(R_err)[0])\n",
    "            if angle_error < threshold:\n",
    "                inliers.append(i)\n",
    "\n",
    "        if len(inliers) > len(best_inliers):\n",
    "            best_inliers = inliers\n",
    "            best_R = R_est\n",
    "            best_t = t_est\n",
    "\n",
    "    return best_R, best_t, best_inliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c2b429",
   "metadata": {},
   "source": [
    "## 4.RANSAC 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "068767fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANSAC 실패: 적절한 해를 찾지 못함\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR:0@655.656] global calibration_handeye.cpp:335 calibrateHandEyeTsai Hand-eye calibration failed! Not enough informative motions--include larger rotations.\n"
     ]
    }
   ],
   "source": [
    "sample_size = max(3, min(6, len(R_gripper2base_all)))\n",
    "\n",
    "best_R, best_t, inliers = ransac_handeye(\n",
    "    R_gripper2base_all, t_gripper2base_all,\n",
    "    R_target2cam_all, t_target2cam_all,\n",
    "    n_iter=200,\n",
    "    sample_size=sample_size,\n",
    "    threshold=0.01\n",
    ")\n",
    "\n",
    "# ==== 결과 저장 ====\n",
    "if best_R is not None and best_t is not None:\n",
    "    result = {\n",
    "        \"R_cam2ee\": best_R.tolist(),\n",
    "        \"t_cam2ee\": best_t.tolist(),\n",
    "        \"description\": \"RANSAC 기반 Tsai-Lenz (Camera → EE), 단위: meter\"\n",
    "    }\n",
    "    with open(\"optimized_cam2ee_RANSAC.json\", \"w\") as f:\n",
    "        json.dump(result, f, indent=2)\n",
    "    print(\"저장 완료: optimized_cam2ee_RANSAC.json\")\n",
    "else:\n",
    "    print(\"RANSAC 실패: 적절한 해를 찾지 못함\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f307a763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
