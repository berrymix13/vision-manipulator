{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8da881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os, cv2\n",
    "import json\n",
    "from ultralytics import YOLO\n",
    "from yolo_detector import detect_objects\n",
    "from camera import capture_d455_images, load_intrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f203f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymycobot import MyCobot280\n",
    "\n",
    "mc = MyCobot280(\"/dev/ttyACM0\", 115200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb076615",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.get_servo_temps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3cf3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.release_all_servos()\n",
    "input(\"Press Enter to continue...\")\n",
    "mc.power_on()\n",
    "mc.get_angles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf14bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_angle = [0.0, 27.33, -30.23, -48.51, -1.84, 1.84]\n",
    "mc.send_angles([0, 0, 0, -75, -10, 0], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69781a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel Real Sense 캡쳐 수행\n",
      "Saved: /home/ros/llm_robot/data/captures/color/2025-07-30_10-21-03.jpg /home/ros/llm_robot/data/captures/depth/2025-07-30_10-21-03.npy\n"
     ]
    }
   ],
   "source": [
    "print(\"Intel Real Sense 캡쳐 수행\")\n",
    "c_path, d_path, intr_path = capture_d455_images()\n",
    "coords = [81.6, -67.5, 299.4, -171.96, -3.71, -94.06]\n",
    "print(\"Saved:\", c_path, d_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ea879c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 YOLO 대상 객체: ['cube']\n",
      "\n",
      "image 1/1 /home/ros/llm_robot/data/captures/color/2025-07-30_10-21-03.jpg: 384x640 (no detections), 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "📦 추출된 객체 정보\n"
     ]
    }
   ],
   "source": [
    "# RGB에서 YOLO로 바운딩 박스 얻기\n",
    "best_model = \"/home/ros/llm_robot/yolo11_seg_cube_best.pt\"\n",
    "target_list = [\"cube\"]\n",
    "print(\"🎯 YOLO 대상 객체:\", target_list)\n",
    "\n",
    "# bbox: 바운딩 박스 모서리\n",
    "# pixel_xy: 박스 중앙 픽셀\n",
    "# cam_xyz: 카메라 좌표 (실제 3D위치)\n",
    "camera_matrix, dist_coeffs = load_intrinsics(intr_path)\n",
    "\n",
    "outputs = detect_objects(\n",
    "    c_path=c_path,\n",
    "    d_path=d_path,\n",
    "    target_list=target_list,\n",
    "    camera_matrix=camera_matrix,\n",
    "    dist_coeffs=dist_coeffs,\n",
    "    best_model=best_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6beb53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 YOLO 대상 객체: ['apple']\n",
      "\n",
      "image 1/1 /home/ros/llm_robot/data/captures/color/2025-07-30_10-21-03.jpg: 384x640 1 apple, 1 laptop, 10.5ms\n",
      "Speed: 0.9ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "📦 추출된 객체 정보\n",
      "apple       z=0.351 m  cam=(-0.247, -0.136, 0.351)\n"
     ]
    }
   ],
   "source": [
    "# RGB에서 YOLO로 바운딩 박스 얻기\n",
    "target_list = [\"apple\"]\n",
    "print(\"🎯 YOLO 대상 객체:\", target_list)\n",
    "\n",
    "# bbox: 바운딩 박스 모서리\n",
    "# pixel_xy: 박스 중앙 픽셀\n",
    "# cam_xyz: 카메라 좌표 (실제 3D위치)\n",
    "camera_matrix, dist_coeffs = load_intrinsics(intr_path)\n",
    "\n",
    "outputs = detect_objects(\n",
    "    c_path=c_path,\n",
    "    d_path=d_path,\n",
    "    target_list=target_list,\n",
    "    camera_matrix=camera_matrix,\n",
    "    dist_coeffs=dist_coeffs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad1e1c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ros/llm_robot/data/captures/color/2025-07-30_10-21-03.jpg: 384x640 1 apple, 1 laptop, 10.5ms\n",
      "Speed: 1.0ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"/home/ros/llm_robot/yolo11x.pt\")\n",
    "model(c_path)[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54b1315f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지에서 원하는 점을 클릭하세요. ESC를 누르면 종료됩니다.\n",
      "클릭한 점: (120, 80)\n",
      "\n",
      "📊 클릭한 점의 카메라 좌표:\n",
      "   픽셀 좌표: (120, 80)\n",
      "   왜곡보정 픽셀: (-0.73, -0.40)\n",
      "   깊이: 0.348 m (348.0 mm)\n",
      "   카메라 XYZ: (-0.255, -0.138, 0.348) m\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Optional\n",
    "\n",
    "def get_clicked_point_cam_xyz(c_path: str, d_path: str, camera_matrix: np.ndarray, \n",
    "                             dist_coeffs: np.ndarray, depth_scale: float = 0.001) -> Optional[List[float]]:\n",
    "    \"\"\"\n",
    "    이미지에서 클릭한 점의 카메라 좌표계 XYZ를 구하는 함수\n",
    "    \n",
    "    Args:\n",
    "        c_path (str): 컬러 이미지 파일 경로\n",
    "        d_path (str): 깊이 이미지 파일 경로 (.npy)\n",
    "        camera_matrix (np.ndarray): 카메라 내부 파라미터 행렬 (3x3)\n",
    "        dist_coeffs (np.ndarray): 왜곡 계수\n",
    "        depth_scale (float): 깊이 스케일 (기본값: 0.001, mm -> m 변환)\n",
    "    \n",
    "    Returns:\n",
    "        Optional[List[float]]: 카메라 좌표계 XYZ [x, y, z] (미터 단위), 클릭하지 않으면 None\n",
    "    \"\"\"\n",
    "    \n",
    "    # 이미지와 깊이 데이터 로드\n",
    "    color_img = cv2.imread(c_path)\n",
    "    if color_img is None:\n",
    "        raise ValueError(f\"이미지를 로드할 수 없습니다: {c_path}\")\n",
    "    \n",
    "    depth_raw = np.load(d_path)\n",
    "    \n",
    "    # 클릭한 점을 저장할 변수\n",
    "    clicked_point = None\n",
    "    \n",
    "    def mouse_callback(event: int, x: int, y: int, flags: int, param) -> None:\n",
    "        \"\"\"마우스 클릭 콜백 함수\"\"\"\n",
    "        nonlocal clicked_point\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            clicked_point = (x, y)\n",
    "            print(f\"클릭한 점: ({x}, {y})\")\n",
    "    \n",
    "    # 윈도우 생성 및 마우스 콜백 설정\n",
    "    window_name = \"Click to get camera XYZ\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.setMouseCallback(window_name, mouse_callback)\n",
    "    \n",
    "    # 이미지 표시\n",
    "    cv2.imshow(window_name, color_img)\n",
    "    print(\"이미지에서 원하는 점을 클릭하세요. ESC를 누르면 종료됩니다.\")\n",
    "    \n",
    "    while True:\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        # ESC 키로 종료\n",
    "        if key == 27:\n",
    "            break\n",
    "        \n",
    "        # 클릭한 점이 있으면 처리\n",
    "        if clicked_point is not None:\n",
    "            x, y = clicked_point\n",
    "            \n",
    "            # 깊이값 가져오기 (ROI 주변 평균 사용)\n",
    "            roi_size = 5\n",
    "            y1, y2 = max(0, y - roi_size), min(depth_raw.shape[0], y + roi_size + 1)\n",
    "            x1, x2 = max(0, x - roi_size), min(depth_raw.shape[1], x + roi_size + 1)\n",
    "            \n",
    "            roi = depth_raw[y1:y2, x1:x2]\n",
    "            valid_depths = roi[roi > 0]\n",
    "            \n",
    "            if valid_depths.size == 0:\n",
    "                print(f\"[경고] 점 ({x}, {y})에서 유효한 깊이값을 찾을 수 없습니다.\")\n",
    "                clicked_point = None\n",
    "                continue\n",
    "            \n",
    "            # 깊이값 계산 (중간값 사용)\n",
    "            z_mm = np.median(valid_depths)\n",
    "            z_m = z_mm * depth_scale\n",
    "            \n",
    "            # 카메라 내부 파라미터\n",
    "            # fx = camera_matrix[0, 0]\n",
    "            # fy = camera_matrix[1, 1]\n",
    "            # ppx = camera_matrix[0, 2]\n",
    "            # ppy = camera_matrix[1, 2]\n",
    "            \n",
    "            # 왜곡 보정\n",
    "            pixel = np.array([[[x, y]]], dtype=np.float32)\n",
    "            undistorted = cv2.undistortPoints(pixel, camera_matrix, dist_coeffs)\n",
    "            x_u, y_u = undistorted[0][0]\n",
    "            \n",
    "            # 픽셀 좌표를 카메라 좌표계로 변환\n",
    "            x_cam = x_u * z_m \n",
    "            y_cam = y_u * z_m\n",
    "            z_cam = z_m\n",
    "            \n",
    "            outputs = []\n",
    "            outputs.append(\n",
    "                {\"pixel_xy\": [x_u, y_u],\n",
    "                \"depth_m\": z_m,\n",
    "                \"cam_xyz\": np.round([x_cam, y_cam, z_cam], 3).tolist(),\n",
    "                \"undistroted_xyz\": np.round([x_u, y_u, z_cam], 3).tolist()}\n",
    "            )\n",
    "            # 결과 출력\n",
    "            print(f\"\\n📊 클릭한 점의 카메라 좌표:\")\n",
    "            print(f\"   픽셀 좌표: ({x}, {y})\")\n",
    "            print(f\"   왜곡보정 픽셀: ({x_u:.2f}, {y_u:.2f})\")\n",
    "            print(f\"   깊이: {z_m:.3f} m ({z_mm:.1f} mm)\")\n",
    "            print(f\"   카메라 XYZ: ({x_cam:.3f}, {y_cam:.3f}, {z_cam:.3f}) m\")\n",
    "            \n",
    "            cv2.destroyAllWindows()\n",
    "            return outputs\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    return None\n",
    "# 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 클릭한 점의 카메라 좌표 구하기\n",
    "    outputs = get_clicked_point_cam_xyz(c_path, d_path, camera_matrix, dist_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b61694",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/ros/llm_robot/data/Calibration/Eye-in-Hand2/ee2cam.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "R_ee2cam = np.array(data[\"R_ee2cam\"])\n",
    "t_ee2cam = np.array(data[\"t_ee2cam\"]).reshape(3, 1)\n",
    "\n",
    "# ▶ 변환 행렬 만들기: T_ee2cam (End-Effector → Camera)\n",
    "T_ee2cam = np.eye(4)\n",
    "T_ee2cam[:3, :3] = R_ee2cam\n",
    "T_ee2cam[:3, 3] = t_ee2cam.flatten()\n",
    "\n",
    "# ▶ T_cam2ee = inverse(T_ee2cam)\n",
    "T_cam2ee = np.linalg.inv(T_ee2cam)\n",
    "\n",
    "# ▶ 현재 로봇 포즈 가져오기 (coords 사용)\n",
    "position = np.array(coords[0:3]).reshape(3, 1) / 1000.0  # mm → m\n",
    "rx, ry, rz = np.radians(coords[3:6])\n",
    "\n",
    "# ▶ 오일러각 → 회전행렬\n",
    "def euler_to_rotation_matrix(rx, ry, rz):\n",
    "    Rx = np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, np.cos(rx), -np.sin(rx)],\n",
    "        [0, np.sin(rx), np.cos(rx)]\n",
    "    ])\n",
    "    Ry = np.array([\n",
    "        [np.cos(ry), 0, np.sin(ry)],\n",
    "        [0, 1, 0],\n",
    "        [-np.sin(ry), 0, np.cos(ry)]\n",
    "    ])\n",
    "    Rz = np.array([\n",
    "        [np.cos(rz), -np.sin(rz), 0],\n",
    "        [np.sin(rz), np.cos(rz), 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    return Rz @ Ry @ Rx\n",
    "\n",
    "R_base2ee = euler_to_rotation_matrix(rx, ry, rz)\n",
    "\n",
    "# ▶ T_base2ee 행렬 구성\n",
    "T_base2ee = np.eye(4)\n",
    "T_base2ee[:3, :3] = R_base2ee\n",
    "T_base2ee[:3, 3] = position.flatten()\n",
    "\n",
    "cam_xyz = np.array(outputs[0][\"cam_xyz\"]).reshape(3, 1)\n",
    "cam_xyz_h = np.vstack([cam_xyz, [[1]]])  # 4x1 homogeneous vectr\n",
    "\n",
    "# ▶ base_xyz 계산\n",
    "base_xyz_h = T_base2ee @ T_cam2ee @ cam_xyz_h\n",
    "base_xyz = base_xyz_h[:3].flatten()*1000  # 최종 좌표 (단위: m)\n",
    "\n",
    "# ▶ 출력\n",
    "print(f\"카메라 기준 위치: {cam_xyz.flatten()} (m)\")\n",
    "print(f\"로봇 base 기준 위치: {base_xyz} (mm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3078bb7",
   "metadata": {},
   "source": [
    "### opt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035824e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_ee2cam = np.array([\n",
    "    [\n",
    "      0.963012911220828,\n",
    "      0.08414759983479521,\n",
    "      0.25597912857111765\n",
    "    ],\n",
    "    [\n",
    "      -0.10328391381709258,\n",
    "      0.9927031691143532,\n",
    "      0.06223223583436019\n",
    "    ],\n",
    "    [\n",
    "      -0.2488745988818646,\n",
    "      -0.08636897285694212,\n",
    "      0.9646770623162074\n",
    "    ]\n",
    "  ])\n",
    "\n",
    "t_ee2cam = np.array([\n",
    "    0.013816857444894276,\n",
    "    -0.08734156453328717,\n",
    "    0.044766342262393864\n",
    "  ]).reshape(3, 1)\n",
    "\n",
    "# ▶ 변환 행렬 만들기: T_ee2cam (End-Effector → Camera)\n",
    "T_ee2cam = np.eye(4)\n",
    "T_ee2cam[:3, :3] = R_ee2cam\n",
    "T_ee2cam[:3, 3] = t_ee2cam.flatten()\n",
    "\n",
    "# ▶ T_cam2ee = inverse(T_ee2cam)\n",
    "T_cam2ee = np.linalg.inv(T_ee2cam)\n",
    "\n",
    "# ▶ 현재 로봇 포즈 가져오기 (coords 사용)\n",
    "position = np.array(coords[0:3]).reshape(3, 1) / 1000.0  # mm → m\n",
    "rx, ry, rz = np.radians(coords[3:6])\n",
    "\n",
    "# ▶ 오일러각 → 회전행렬\n",
    "def euler_to_rotation_matrix(rx, ry, rz):\n",
    "    Rx = np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, np.cos(rx), -np.sin(rx)],\n",
    "        [0, np.sin(rx), np.cos(rx)]\n",
    "    ])\n",
    "    Ry = np.array([\n",
    "        [np.cos(ry), 0, np.sin(ry)],\n",
    "        [0, 1, 0],\n",
    "        [-np.sin(ry), 0, np.cos(ry)]\n",
    "    ])\n",
    "    Rz = np.array([\n",
    "        [np.cos(rz), -np.sin(rz), 0],\n",
    "        [np.sin(rz), np.cos(rz), 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    return Rz @ Ry @ Rx\n",
    "\n",
    "R_base2ee = euler_to_rotation_matrix(rx, ry, rz)\n",
    "\n",
    "# ▶ T_base2ee 행렬 구성\n",
    "T_base2ee = np.eye(4)\n",
    "T_base2ee[:3, :3] = R_base2ee\n",
    "T_base2ee[:3, 3] = position.flatten()\n",
    "\n",
    "cam_xyz = np.array(outputs[0][\"cam_xyz\"]).reshape(3, 1)\n",
    "cam_xyz_h = np.vstack([cam_xyz, [[1]]])  # 4x1 homogeneous vectr\n",
    "\n",
    "# ▶ base_xyz 계산\n",
    "base_xyz_h = T_base2ee @ T_cam2ee @ cam_xyz_h\n",
    "base_xyz = base_xyz_h[:3].flatten()*1000  # 최종 좌표 (단위: m)\n",
    "\n",
    "# ▶ 출력\n",
    "print(f\"카메라 기준 위치: {cam_xyz.flatten()} (m)\")\n",
    "print(f\"로봇 base 기준 위치: {base_xyz} (mm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53489bb1",
   "metadata": {},
   "source": [
    "### opt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f63eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_ee2cam = np.array([\n",
    "    [\n",
    "      0.963012911220828,\n",
    "      0.08414759983479521,\n",
    "      0.25597912857111765\n",
    "    ],\n",
    "    [\n",
    "      -0.10328391381709258,\n",
    "      0.9927031691143532,\n",
    "      0.06223223583436019\n",
    "    ],\n",
    "    [\n",
    "      -0.2488745988818646,\n",
    "      -0.08636897285694212,\n",
    "      0.9646770623162074\n",
    "    ]\n",
    "  ])\n",
    "t_ee2cam = np.array([\n",
    "    0.0418,\n",
    "    -0.0019,\n",
    "    -0.0239\n",
    "  ]).reshape(3, 1)\n",
    "\n",
    "# ▶ 변환 행렬 만들기: T_ee2cam (End-Effector → Camera)\n",
    "T_ee2cam = np.eye(4)\n",
    "T_ee2cam[:3, :3] = R_ee2cam\n",
    "T_ee2cam[:3, 3] = t_ee2cam.flatten()\n",
    "\n",
    "# ▶ T_cam2ee = inverse(T_ee2cam)\n",
    "T_cam2ee = np.linalg.inv(T_ee2cam)\n",
    "\n",
    "# ▶ 현재 로봇 포즈 가져오기 (coords 사용)\n",
    "position = np.array(coords[0:3]).reshape(3, 1) / 1000.0  # mm → m\n",
    "rx, ry, rz = np.radians(coords[3:6])\n",
    "\n",
    "# ▶ 오일러각 → 회전행렬\n",
    "def euler_to_rotation_matrix(rx, ry, rz):\n",
    "    Rx = np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, np.cos(rx), -np.sin(rx)],\n",
    "        [0, np.sin(rx), np.cos(rx)]\n",
    "    ])\n",
    "    Ry = np.array([\n",
    "        [np.cos(ry), 0, np.sin(ry)],\n",
    "        [0, 1, 0],\n",
    "        [-np.sin(ry), 0, np.cos(ry)]\n",
    "    ])\n",
    "    Rz = np.array([\n",
    "        [np.cos(rz), -np.sin(rz), 0],\n",
    "        [np.sin(rz), np.cos(rz), 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    return Rz @ Ry @ Rx\n",
    "\n",
    "R_base2ee = euler_to_rotation_matrix(rx, ry, rz)\n",
    "\n",
    "# ▶ T_base2ee 행렬 구성\n",
    "T_base2ee = np.eye(4)\n",
    "T_base2ee[:3, :3] = R_base2ee\n",
    "T_base2ee[:3, 3] = position.flatten()\n",
    "\n",
    "cam_xyz = np.array(outputs[0][\"cam_xyz\"]).reshape(3, 1)\n",
    "cam_xyz_h = np.vstack([cam_xyz, [[1]]])  # 4x1 homogeneous vectr\n",
    "\n",
    "# ▶ base_xyz 계산\n",
    "base_xyz_h = T_base2ee @ T_cam2ee @ cam_xyz_h\n",
    "base_xyz = base_xyz_h[:3].flatten()*1000  # 최종 좌표 (단위: m)\n",
    "\n",
    "# ▶ 출력\n",
    "print(f\"카메라 기준 위치: {cam_xyz.flatten()} (m)\")\n",
    "print(f\"로봇 base 기준 위치: {base_xyz} (mm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f2f3c6",
   "metadata": {},
   "source": [
    "### opt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcb8597",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_ee2cam = np.array([\n",
    "    [\n",
    "      0.963012911220828,\n",
    "      0.08414759983479521,\n",
    "      0.25597912857111765\n",
    "    ],\n",
    "    [\n",
    "      -0.10328391381709258,\n",
    "      0.9927031691143532,\n",
    "      0.06223223583436019\n",
    "    ],\n",
    "    [\n",
    "      -0.2488745988818646,\n",
    "      -0.08636897285694212,\n",
    "      0.9646770623162074\n",
    "    ]\n",
    "  ])\n",
    "t_ee2cam = np.array([\n",
    "    -0.036555485369370394,\n",
    "    0.0024818389059779213,\n",
    "    0.07577704859934829\n",
    "  ]).reshape(3, 1)\n",
    "\n",
    "# ▶ 변환 행렬 만들기: T_ee2cam (End-Effector → Camera)\n",
    "T_ee2cam = np.eye(4)\n",
    "T_ee2cam[:3, :3] = R_ee2cam\n",
    "T_ee2cam[:3, 3] = t_ee2cam.flatten()\n",
    "\n",
    "# ▶ T_cam2ee = inverse(T_ee2cam)\n",
    "T_cam2ee = np.linalg.inv(T_ee2cam)\n",
    "\n",
    "# ▶ 현재 로봇 포즈 가져오기 (coords 사용)\n",
    "position = np.array(coords[0:3]).reshape(3, 1) / 1000.0  # mm → m\n",
    "rx, ry, rz = np.radians(coords[3:6])\n",
    "\n",
    "# ▶ 오일러각 → 회전행렬\n",
    "def euler_to_rotation_matrix(rx, ry, rz):\n",
    "    Rx = np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, np.cos(rx), -np.sin(rx)],\n",
    "        [0, np.sin(rx), np.cos(rx)]\n",
    "    ])\n",
    "    Ry = np.array([\n",
    "        [np.cos(ry), 0, np.sin(ry)],\n",
    "        [0, 1, 0],\n",
    "        [-np.sin(ry), 0, np.cos(ry)]\n",
    "    ])\n",
    "    Rz = np.array([\n",
    "        [np.cos(rz), -np.sin(rz), 0],\n",
    "        [np.sin(rz), np.cos(rz), 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    return Rz @ Ry @ Rx\n",
    "\n",
    "R_base2ee = euler_to_rotation_matrix(rx, ry, rz)\n",
    "\n",
    "# ▶ T_base2ee 행렬 구성\n",
    "T_base2ee = np.eye(4)\n",
    "T_base2ee[:3, :3] = R_base2ee\n",
    "T_base2ee[:3, 3] = position.flatten()\n",
    "\n",
    "cam_xyz = np.array(outputs[0][\"cam_xyz\"]).reshape(3, 1)\n",
    "cam_xyz_h = np.vstack([cam_xyz, [[1]]])  # 4x1 homogeneous vectr\n",
    "\n",
    "# ▶ base_xyz 계산\n",
    "base_xyz_h = T_base2ee @ T_cam2ee @ cam_xyz_h\n",
    "base_xyz = base_xyz_h[:3].flatten()*1000  # 최종 좌표 (단위: m)\n",
    "\n",
    "# ▶ 출력\n",
    "print(f\"카메라 기준 위치: {cam_xyz.flatten()} (m)\")\n",
    "print(f\"로봇 base 기준 위치: {base_xyz} (mm)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a5e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.set_gripper_value(40,40)\n",
    "mc.send_coords([100, 100, 100, -179, 0, 0], 40,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f724e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mc.release_all_servos()\n",
    "# input(\"Press Enter to continue...\")\n",
    "# mc.power_on()\n",
    "mc.get_coords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16564733",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.send_angles([0, 0, 0, -0, -10, 0],40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
