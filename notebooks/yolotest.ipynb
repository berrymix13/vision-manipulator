{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8da881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os, cv2\n",
    "import json\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"/home/ros/llm_robot\"))\n",
    "from utils.pixel_to_cam_coords import detect_objects\n",
    "from utils.camera import capture_d455_images, load_intrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f203f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymycobot import MyCobot280\n",
    "\n",
    "mc = MyCobot280(\"/dev/ttyACM1\", 115200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fb076615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28, 28, 28, 45, 34, 40]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.get_servo_temps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6e3cf3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([35.8, -62.6, 421.9, -88.32, -1.76, -88.9],\n",
       " [0.87, 2.98, -1.31, 0.0, 0.26, -1.75])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.release_all_servos()\n",
    "input(\"Press Enter to continue...\")\n",
    "mc.power_on()\n",
    "mc.get_coords(), mc.get_angles() #2.9 -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3bc77655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.send_coords([172,-19.43,200,-179,0,0],20,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "69781a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel Real Sense Ï∫°Ï≥ê ÏàòÌñâ\n",
      "Saved: /home/ros/llm_robot/data/captures/color/2025-08-27_12-27-14.jpg /home/ros/llm_robot/data/captures/depth/2025-08-27_12-27-14.npy\n"
     ]
    }
   ],
   "source": [
    "print(\"Intel Real Sense Ï∫°Ï≥ê ÏàòÌñâ\")\n",
    "c_path, d_path, intr_path = capture_d455_images()\n",
    "# coords = [81.6, -67.5, 299.4, -171.96, -3.71, -94.06]\n",
    "print(\"Saved:\", c_path, d_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4ea879c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ YOLO ÎåÄÏÉÅ Í∞ùÏ≤¥: ['cube']\n",
      "\n",
      "image 1/1 /home/ros/llm_robot/data/captures/color/2025-08-27_12-27-14.jpg: 384x640 1 cube, 5.9ms\n",
      "Speed: 0.9ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "üì¶ Ï∂îÏ∂úÎêú Í∞ùÏ≤¥ Ï†ïÎ≥¥\n",
      "cube        z=0.536 m  cam=(0.468, 0.074, 0.536)\n"
     ]
    }
   ],
   "source": [
    "# RGBÏóêÏÑú YOLOÎ°ú Î∞îÏö¥Îî© Î∞ïÏä§ ÏñªÍ∏∞\n",
    "best_model = \"/home/ros/llm_robot/yolo/runs/pose/yolo11n_640_500ep/weights/best.pt\"\n",
    "target_list = [\"cube\"]\n",
    "print(\"üéØ YOLO ÎåÄÏÉÅ Í∞ùÏ≤¥:\", target_list)\n",
    "\n",
    "# bbox: Î∞îÏö¥Îî© Î∞ïÏä§ Î™®ÏÑúÎ¶¨\n",
    "# pixel_xy: Î∞ïÏä§ Ï§ëÏïô ÌîΩÏÖÄ\n",
    "# cam_xyz: Ïπ¥Î©îÎùº Ï¢åÌëú (Ïã§Ï†ú 3DÏúÑÏπò)\n",
    "camera_matrix, dist_coeffs = load_intrinsics(intr_path)\n",
    "\n",
    "outputs = detect_objects(\n",
    "    c_path=c_path,\n",
    "    d_path=d_path,\n",
    "    target_list=target_list,\n",
    "    camera_matrix=camera_matrix,\n",
    "    dist_coeffs=dist_coeffs,\n",
    "    best_model=best_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54b1315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Optional\n",
    "\n",
    "def get_cam_xyz(x, y, depth_raw, camera_matrix, dist_coeffs, depth_scale=0.001):\n",
    "    \n",
    "    # ÍπäÏù¥Í∞í Í∞ÄÏ†∏Ïò§Í∏∞ (ROI Ï£ºÎ≥Ä ÌèâÍ∑† ÏÇ¨Ïö©)\n",
    "    roi_size = 5\n",
    "    y1, y2 = max(0, y - roi_size), min(depth_raw.shape[0], y + roi_size + 1)\n",
    "    x1, x2 = max(0, x - roi_size), min(depth_raw.shape[1], x + roi_size + 1)\n",
    "    \n",
    "    roi = depth_raw[y1:y2, x1:x2]\n",
    "    valid_depths = roi[roi > 0]\n",
    "    \n",
    "    if valid_depths.size == 0:\n",
    "        print(f\"[Í≤ΩÍ≥†] Ï†ê ({x}, {y})ÏóêÏÑú Ïú†Ìö®Ìïú ÍπäÏù¥Í∞íÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.\")\n",
    "        clicked_point = None\n",
    "        return None\n",
    "    \n",
    "    # ÍπäÏù¥Í∞í Í≥ÑÏÇ∞ (Ï§ëÍ∞ÑÍ∞í ÏÇ¨Ïö©)\n",
    "    z_mm = np.median(valid_depths)\n",
    "    z_m = z_mm * depth_scale\n",
    "    \n",
    "    # Ïπ¥Î©îÎùº ÎÇ¥Î∂Ä ÌååÎùºÎØ∏ÌÑ∞\n",
    "    # fx = camera_matrix[0, 0]\n",
    "    # fy = camera_matrix[1, 1]\n",
    "    # ppx = camera_matrix[0, 2]\n",
    "    # ppy = camera_matrix[1, 2]\n",
    "    \n",
    "    # ÏôúÍ≥° Î≥¥Ï†ï\n",
    "    pixel = np.array([[[x, y]]], dtype=np.float32)\n",
    "    undistorted = cv2.undistortPoints(pixel, camera_matrix, dist_coeffs)\n",
    "    x_u, y_u = undistorted[0][0]\n",
    "    \n",
    "    # ÌîΩÏÖÄ Ï¢åÌëúÎ•º Ïπ¥Î©îÎùº Ï¢åÌëúÍ≥ÑÎ°ú Î≥ÄÌôò\n",
    "    x_cam = x_u * z_m\n",
    "    y_cam = y_u * z_m\n",
    "    z_cam = z_m\n",
    "    \n",
    "    outputs = []\n",
    "    outputs.append(\n",
    "        {\"pixel_xy\": [x_u, y_u],\n",
    "        \"depth_m\": z_m,\n",
    "        \"cam_xyz\": np.round([x_cam, y_cam, z_cam], 3).tolist(),\n",
    "        \"undistroted_xyz\": np.round([x_u, y_u, z_cam], 3).tolist()}\n",
    "    )\n",
    "    # Í≤∞Í≥º Ï∂úÎ†•\n",
    "    print(f\"\\nüìä ÌÅ¥Î¶≠Ìïú Ï†êÏùò Ïπ¥Î©îÎùº Ï¢åÌëú:\")\n",
    "    print(f\"   ÌîΩÏÖÄ Ï¢åÌëú: ({x}, {y})\")\n",
    "    print(f\"   ÏôúÍ≥°Î≥¥Ï†ï ÌîΩÏÖÄ: ({x_u:.2f}, {y_u:.2f})\")\n",
    "    print(f\"   ÍπäÏù¥: {z_m:.3f} m ({z_mm:.1f} mm)\")\n",
    "    print(f\"   Ïπ¥Î©îÎùº XYZ: ({x_cam:.3f}, {y_cam:.3f}, {z_cam:.3f}) m\")\n",
    "    \n",
    "    return outputs\n",
    "    \n",
    "\n",
    "def get_clicked_point_cam_xyz(c_path: str, d_path: str, camera_matrix: np.ndarray, \n",
    "                             dist_coeffs: np.ndarray, depth_scale: float = 0.001) -> Optional[List[float]]:\n",
    "    \"\"\"\n",
    "    Ïù¥ÎØ∏ÏßÄÏóêÏÑú ÌÅ¥Î¶≠Ìïú Ï†êÏùò Ïπ¥Î©îÎùº Ï¢åÌëúÍ≥Ñ XYZÎ•º Íµ¨ÌïòÎäî Ìï®Ïàò\n",
    "    \n",
    "    Args:\n",
    "        c_path (str): Ïª¨Îü¨ Ïù¥ÎØ∏ÏßÄ ÌååÏùº Í≤ΩÎ°ú\n",
    "        d_path (str): ÍπäÏù¥ Ïù¥ÎØ∏ÏßÄ ÌååÏùº Í≤ΩÎ°ú (.npy)\n",
    "        camera_matrix (np.ndarray): Ïπ¥Î©îÎùº ÎÇ¥Î∂Ä ÌååÎùºÎØ∏ÌÑ∞ ÌñâÎ†¨ (3x3)\n",
    "        dist_coeffs (np.ndarray): ÏôúÍ≥° Í≥ÑÏàò\n",
    "        depth_scale (float): ÍπäÏù¥ Ïä§ÏºÄÏùº (Í∏∞Î≥∏Í∞í: 0.001, mm -> m Î≥ÄÌôò)\n",
    "    \n",
    "    Returns:\n",
    "        Optional[List[float]]: Ïπ¥Î©îÎùº Ï¢åÌëúÍ≥Ñ XYZ [x, y, z] (ÎØ∏ÌÑ∞ Îã®ÏúÑ), ÌÅ¥Î¶≠ÌïòÏßÄ ÏïäÏúºÎ©¥ None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ïù¥ÎØ∏ÏßÄÏôÄ ÍπäÏù¥ Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "    color_img = cv2.imread(c_path)\n",
    "    if color_img is None:\n",
    "        raise ValueError(f\"Ïù¥ÎØ∏ÏßÄÎ•º Î°úÎìúÌï† Ïàò ÏóÜÏäµÎãàÎã§: {c_path}\")\n",
    "    \n",
    "    depth_raw = np.load(d_path)\n",
    "    \n",
    "    # ÌÅ¥Î¶≠Ìïú Ï†êÏùÑ Ï†ÄÏû•Ìï† Î≥ÄÏàò\n",
    "    clicked_point = None\n",
    "    \n",
    "    def mouse_callback(event: int, x: int, y: int, flags: int, param) -> None:\n",
    "        \"\"\"ÎßàÏö∞Ïä§ ÌÅ¥Î¶≠ ÏΩúÎ∞± Ìï®Ïàò\"\"\"\n",
    "        nonlocal clicked_point\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            clicked_point = (x, y)\n",
    "            print(f\"ÌÅ¥Î¶≠Ìïú Ï†ê: ({x}, {y})\")\n",
    "    \n",
    "    # ÏúàÎèÑÏö∞ ÏÉùÏÑ± Î∞è ÎßàÏö∞Ïä§ ÏΩúÎ∞± ÏÑ§Ï†ï\n",
    "    window_name = \"Click to get camera XYZ\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.setMouseCallback(window_name, mouse_callback)\n",
    "    \n",
    "    # Ïù¥ÎØ∏ÏßÄ ÌëúÏãú\n",
    "    cv2.imshow(window_name, color_img)\n",
    "    print(\"Ïù¥ÎØ∏ÏßÄÏóêÏÑú ÏõêÌïòÎäî Ï†êÏùÑ ÌÅ¥Î¶≠ÌïòÏÑ∏Ïöî. ESCÎ•º ÎàÑÎ•¥Î©¥ Ï¢ÖÎ£åÎê©ÎãàÎã§.\")\n",
    "    \n",
    "    while True:\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        # ESC ÌÇ§Î°ú Ï¢ÖÎ£å\n",
    "        if key == 27:\n",
    "            break\n",
    "        \n",
    "        # ÌÅ¥Î¶≠Ìïú Ï†êÏù¥ ÏûàÏúºÎ©¥ Ï≤òÎ¶¨\n",
    "        if clicked_point is not None:\n",
    "            x, y = clicked_point\n",
    "            outputs = get_cam_xyz(x, y, depth_raw, camera_matrix, dist_coeffs, depth_scale)\n",
    "            cv2.destroyAllWindows()\n",
    "            return outputs\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    return None\n",
    "\n",
    "def get_cam_xyz_by_input(c_path: str, d_path: str, camera_matrix: np.ndarray, \n",
    "                             dist_coeffs: np.ndarray, depth_scale: float = 0.001) -> Optional[List[float]]:\n",
    "    \n",
    "    color_img = cv2.imread(c_path)\n",
    "    depth_raw = np.load(d_path)\n",
    "    \n",
    "    x = int(input(\"Enter x: \"))\n",
    "    y = int(input(\"Enter y: \"))\n",
    "    \n",
    "    outputs = get_cam_xyz(x, y, depth_raw, camera_matrix, dist_coeffs, depth_scale)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7bcaa29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ïù¥ÎØ∏ÏßÄÏóêÏÑú ÏõêÌïòÎäî Ï†êÏùÑ ÌÅ¥Î¶≠ÌïòÏÑ∏Ïöî. ESCÎ•º ÎàÑÎ•¥Î©¥ Ï¢ÖÎ£åÎê©ÎãàÎã§.\n",
      "ÌÅ¥Î¶≠Ìïú Ï†ê: (656, 79)\n",
      "\n",
      "üìä ÌÅ¥Î¶≠Ìïú Ï†êÏùò Ïπ¥Î©îÎùº Ï¢åÌëú:\n",
      "   ÌîΩÏÖÄ Ï¢åÌëú: (656, 79)\n",
      "   ÏôúÍ≥°Î≥¥Ï†ï ÌîΩÏÖÄ: (0.54, -0.40)\n",
      "   ÍπäÏù¥: 0.554 m (554.0 mm)\n",
      "   Ïπ¥Î©îÎùº XYZ: (0.301, -0.220, 0.554) m\n",
      "\n",
      "üìä ÌÅ¥Î¶≠Ìïú Ï†êÏùò Ïπ¥Î©îÎùº Ï¢åÌëú:\n",
      "   ÌîΩÏÖÄ Ï¢åÌëú: (656, 79)\n",
      "   ÏôúÍ≥°Î≥¥Ï†ï ÌîΩÏÖÄ: (0.54, -0.40)\n",
      "   ÍπäÏù¥: 0.277 m (554.0 mm)\n",
      "   Ïπ¥Î©îÎùº XYZ: (0.151, -0.110, 0.277) m\n"
     ]
    }
   ],
   "source": [
    "intr_path2 = \"/home/ros/llm_robot/data/Calibration/Eye-to-Hand11/camera_intrinsics_result.json\"\n",
    "camera_matrix2, dist_coeffs2 = load_intrinsics(intr_path2)\n",
    "\n",
    "intr_path3 = \"/home/ros/Eye-to-Hand/data/camera_calibration3/camera_params.json\"\n",
    "camera_matrix3, dist_coeffs3 = load_intrinsics(intr_path3)\n",
    "\n",
    "outputs = get_clicked_point_cam_xyz(c_path, d_path, camera_matrix, dist_coeffs,0.001)\n",
    "# outputs2 = get_cam_xyz_by_input(c_path, d_path, camera_matrix2, dist_coeffs2,0.001)\n",
    "# outputs3 = get_cam_xyz_by_input(c_path, d_path, camera_matrix3, dist_coeffs3,0.001)\n",
    "outputs3 = get_cam_xyz_by_input(c_path, d_path, camera_matrix, dist_coeffs,0.0005)\n",
    "# outputs4 = get_cam_xyz_by_input(c_path, d_path, camera_matrix, dist_coeffs,0.00085)\n",
    "# outputs5 = get_cam_xyz_by_input(c_path, d_path, camera_matrix, dist_coeffs,0.0008)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5534bd",
   "metadata": {},
   "source": [
    "# Eye-in-Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f14f6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ñ∂ Ïò§ÏùºÎü¨Í∞Å ‚Üí ÌöåÏ†ÑÌñâÎ†¨\n",
    "def euler_to_rotation_matrix(rx, ry, rz):\n",
    "    Rx = np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, np.cos(rx), -np.sin(rx)],\n",
    "        [0, np.sin(rx), np.cos(rx)]\n",
    "    ])\n",
    "    Ry = np.array([\n",
    "        [np.cos(ry), 0, np.sin(ry)],\n",
    "        [0, 1, 0],\n",
    "        [-np.sin(ry), 0, np.cos(ry)]\n",
    "    ])\n",
    "    Rz = np.array([\n",
    "        [np.cos(rz), -np.sin(rz), 0],\n",
    "        [np.sin(rz), np.cos(rz), 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    return Rz @ Ry @ Rx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "66b61694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     156.08,       294.6,      524.38])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam2ee_path = \"/home/ros/llm_robot/data/Calibration/Eye-to-Hand/cam2ee.json\"\n",
    "cam2ee_path2 = \"/home/ros/llm_robot/notebooks/optimized_cam2ee_RANSAC.json\"\n",
    "with open(cam2ee_path2, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "R_cam2ee = np.array(data[\"R_cam2ee\"])\n",
    "R_ee2cam = np.linalg.inv(R_cam2ee)\n",
    "t_cam2ee = np.array(data[\"t_cam2ee\"]).reshape(3, 1)\n",
    "\n",
    "T_cam2ee = np.eye(4)\n",
    "T_cam2ee[:3, :3] = R_cam2ee\n",
    "T_cam2ee[:3, 3] = t_cam2ee.flatten()\n",
    "T_ee2cam = np.linalg.inv(T_cam2ee) \n",
    "\n",
    "# ÌòÑÏû¨ Î°úÎ¥á Ìè¨Ï¶à Í∞ÄÏ†∏Ïò§Í∏∞ (coords ÏÇ¨Ïö©)\n",
    "position = np.array(coords[0:3]).reshape(3, 1) / 1000.0  # mm ‚Üí m\n",
    "rx, ry, rz = np.radians(coords[3:6])\n",
    "\n",
    "R_base2ee = euler_to_rotation_matrix(rx, ry, rz)\n",
    "\n",
    "# --- Base XYZ Í≥ÑÏÇ∞ ---\n",
    "# T_base2ee ÌñâÎ†¨ Íµ¨ÏÑ±\n",
    "T_base2ee = np.eye(4)\n",
    "T_base2ee[:3, :3] = R_base2ee\n",
    "T_base2ee[:3, 3] = position.flatten()\n",
    "\n",
    "cam_xyz = np.array(outputs[0][\"cam_xyz\"]).reshape(3, 1)\n",
    "cam_xyz_h = np.vstack([cam_xyz, [[1]]])  # 4x1 homogeneous vectr\n",
    "\n",
    "# base_xyz Í≥ÑÏÇ∞\n",
    "base_xyz_h = T_base2ee @ T_cam2ee @ cam_xyz_h\n",
    "base_xyz = base_xyz_h[:3].flatten()*1000  # ÏµúÏ¢Ö Ï¢åÌëú (Îã®ÏúÑ: m)\n",
    "\n",
    "R_correction = np.array([\n",
    "    [0, 1, 0],\n",
    "    [1, 0, 0],\n",
    "    [0, 0, -1]\n",
    "])\n",
    "base_xyz_corrected = R_correction @ base_xyz\n",
    "base_xyz_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19be4862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ïπ¥Î©îÎùº Í∏∞Ï§Ä ÏúÑÏπò: [       0.17      -0.051       0.457] (m)\n",
      "Î°úÎ¥á base Í∏∞Ï§Ä ÏúÑÏπò: [     48.646     -270.92      717.04] (mm)\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/ros/llm_robot/notebooks/optimized_cam2ee_icp_point.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "R_cam2ee = np.array(data[\"R_cam2ee\"])\n",
    "t_cam2ee = np.array(data[\"t_cam2ee\"]).reshape(3, 1)\n",
    "\n",
    "T_cam2ee = np.eye(4)\n",
    "T_cam2ee[:3, :3] = R_cam2ee\n",
    "T_cam2ee[:3, 3] = t_cam2ee.flatten()\n",
    "\n",
    "\n",
    "# ‚ñ∂ ÌòÑÏû¨ Î°úÎ¥á Ìè¨Ï¶à Í∞ÄÏ†∏Ïò§Í∏∞ (coords ÏÇ¨Ïö©)\n",
    "position = np.array(coords[0:3]).reshape(3, 1) / 1000.0  # mm ‚Üí m\n",
    "rx, ry, rz = np.radians(coords[3:6])\n",
    "\n",
    "R_base2ee = euler_to_rotation_matrix(rx, ry, rz)\n",
    "\n",
    "# ‚ñ∂ T_base2ee ÌñâÎ†¨ Íµ¨ÏÑ±\n",
    "T_base2ee = np.eye(4)\n",
    "T_base2ee[:3, :3] = R_base2ee\n",
    "T_base2ee[:3, 3] = position.flatten()\n",
    "\n",
    "cam_xyz = np.array(outputs[0][\"cam_xyz\"]).reshape(3, 1)\n",
    "cam_xyz_h = np.vstack([cam_xyz, [[1]]])  # 4x1 homogeneous vectr\n",
    "\n",
    "# ‚ñ∂ base_xyz Í≥ÑÏÇ∞\n",
    "base_xyz_h = T_base2ee @ T_cam2ee @ cam_xyz_h\n",
    "base_xyz = base_xyz_h[:3].flatten()*1000  # ÏµúÏ¢Ö Ï¢åÌëú (Îã®ÏúÑ: m)\n",
    "\n",
    "# ‚ñ∂ Ï∂úÎ†•\n",
    "print(f\"Ïπ¥Î©îÎùº Í∏∞Ï§Ä ÏúÑÏπò: {cam_xyz.flatten()} (m)\")\n",
    "print(f\"Î°úÎ¥á base Í∏∞Ï§Ä ÏúÑÏπò: {base_xyz} (mm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd751eb",
   "metadata": {},
   "source": [
    "# Eye-to-Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "682e5c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = \"/home/ros/llm_robot/data/Calibration/Eye-to-Hand11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8fdb0666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cam2base_correction(cam2base_path, outputs):\n",
    "    with open(cam2base_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    R_cam2base = np.array(data[\"R_cam2base\"]).reshape(3, 3)\n",
    "    t_cam2base = np.array(data[\"t_cam2base\"]).reshape(3, 1)\n",
    "\n",
    "    T_cam2base = np.eye(4)\n",
    "    T_cam2base[:3, :3] = R_cam2base\n",
    "    T_cam2base[:3, 3] = t_cam2base.flatten()\n",
    "    \n",
    "    T_camera_to_robot_coord = np.array([\n",
    "    [ 1,  0,  0],\n",
    "    [0,  1,  0],\n",
    "    [ 0, 0,  1]\n",
    "    ]) \n",
    "\n",
    "    # Î≥¥Ï†ï Ï†ÅÏö©\n",
    "    R_corrected = T_camera_to_robot_coord @ R_cam2base\n",
    "    t_corrected = T_camera_to_robot_coord @ t_cam2base\n",
    "\n",
    "    T_cam2base_corrected = np.eye(4)\n",
    "    T_cam2base_corrected[:3, :3] = R_corrected\n",
    "    T_cam2base_corrected[:3, 3] = t_corrected.flatten()\n",
    "\n",
    "    cam_xyz = np.array(outputs[0][\"cam_xyz\"]).reshape(3,1)\n",
    "    cam_homog = np.append(cam_xyz, 1.0)\n",
    "    base_homog =   T_cam2base_corrected @ cam_homog\n",
    "    base_xyz_homog = base_homog[:3]*1000      # X, Y, Z (Î≥ëÏßÑ Ìè¨Ìï®)\n",
    "    print(f\"Base XYZ (Homogeneous): {base_xyz_homog}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805a174c",
   "metadata": {},
   "source": [
    "### pure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6240e656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base XYZ (Homogeneous): [    -78.233      242.26       24.05]\n",
      "Base XYZ (Homogeneous): [    -97.643      145.99     -31.751]\n",
      "Base XYZ (Homogeneous): [    -88.533      242.35       21.79]\n",
      "Base XYZ (Homogeneous): [     335.42      113.61     -16.201]\n",
      "Base XYZ (Homogeneous): [     342.61      117.74     -9.2285]\n"
     ]
    }
   ],
   "source": [
    "cam2base_path = f\"{MAIN_DIR}/cam2base_icp_point.json\"\n",
    "cam2base_correction(cam2base_path, outputs)\n",
    "\n",
    "cam2base_path2 = f\"{MAIN_DIR}/cam2base_table_normal_fix.json\"\n",
    "cam2base_correction(cam2base_path2, outputs)\n",
    "# cam2base_correction(cam2base_path, outputs2)\n",
    "# cam2base_correction(cam2base_path, outputs3)\n",
    "\n",
    "cam2base_path3 = f\"{MAIN_DIR}/cam2base_calibrated.json\"\n",
    "cam2base_correction(cam2base_path3, outputs)\n",
    "\n",
    "# cam2base_path4 = f\"{MAIN_DIR}/cam2base_table_normal_fix_ransac2.json\"\n",
    "# cam2base_correction(cam2base_path4, outputs)\n",
    "\n",
    "cam2base_path5 = f\"../data/Calibration/Eye-to-Hand12/cam2base.json\"\n",
    "cam2base_correction(cam2base_path5, outputs)\n",
    "\n",
    "cam2base_path6 = f\"../data/Calibration/Eye-to-Hand12/cam2base_icp_point.json\"\n",
    "cam2base_correction(cam2base_path6, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daaf5b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base XYZ (Homogeneous): [     97.511     -43.467     -15.392]\n",
      "Base XYZ (Homogeneous): [     98.526      -45.42     -15.786]\n",
      "Base XYZ (Homogeneous): [     107.48     -39.441     -14.745]\n"
     ]
    }
   ],
   "source": [
    "cam2base_path2 = f\"{MAIN_DIR}/cam2base_icp.json\"\n",
    "cam2base_correction(cam2base_path2, outputs)\n",
    "cam2base_correction(cam2base_path2, outputs2)\n",
    "cam2base_correction(cam2base_path2, outputs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbf6bb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cam2base_correction(cam2base_path, outputs3)\n",
    "# cam2base_correction(cam2base_path, outputs4)\n",
    "# cam2base_correction(cam2base_path, outputs5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "154e83ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base XYZ (Homogeneous): [     88.931     -77.429       -24.7]\n",
      "Base XYZ (Homogeneous): [     94.053     -81.715      3.2175]\n",
      "Base XYZ (Homogeneous): [     95.202     -84.941      30.093]\n",
      "Base XYZ (Homogeneous): [     97.326     -89.242      57.913]\n",
      "Base XYZ (Homogeneous): [     98.475     -92.468      84.788]\n"
     ]
    }
   ],
   "source": [
    "cam2base_path = f\"{MAIN_DIR}/cam2base_icp_point_refined.json\"\n",
    "cam2base_correction(cam2base_path, outputs)\n",
    "cam2base_correction(cam2base_path, outputs2)\n",
    "cam2base_correction(cam2base_path, outputs3)\n",
    "cam2base_correction(cam2base_path, outputs4)\n",
    "cam2base_correction(cam2base_path, outputs5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3185adae",
   "metadata": {},
   "source": [
    "### ICP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ad49a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base XYZ (Homogeneous): [    -86.776      235.61     -24.686]\n"
     ]
    }
   ],
   "source": [
    "cam2base_path = f\"{MAIN_DIR}/cam2base_icp.json\"\n",
    "with open(cam2base_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "R_cam2base = np.array(data[\"R_cam2base\"])\n",
    "t_cam2base = np.array(data[\"t_cam2base\"]).reshape(3, 1)\n",
    "\n",
    "T_cam2base = np.eye(4)\n",
    "T_cam2base[:3, :3] = R_cam2base\n",
    "T_cam2base[:3, 3] = t_cam2base.flatten()\n",
    "\n",
    "T_camera_to_robot_coord = np.array([\n",
    "    [ 1,  0,  0],\n",
    "    [0,  1,  0],\n",
    "    [ 0, 0,  -1]\n",
    "]) \n",
    "\n",
    "# Î≥¥Ï†ï Ï†ÅÏö©\n",
    "R_corrected = T_camera_to_robot_coord @ R_cam2base\n",
    "t_corrected = T_camera_to_robot_coord @ t_cam2base\n",
    "\n",
    "T_cam2base_corrected = np.eye(4)\n",
    "T_cam2base_corrected[:3, :3] = R_corrected\n",
    "T_cam2base_corrected[:3, 3] = t_corrected.flatten()\n",
    "\n",
    "cam_xyz = np.array(outputs[0][\"cam_xyz\"]).reshape(3, 1)\n",
    "cam_homog = np.append(cam_xyz, 1.0)\n",
    "base_homog =   T_cam2base_corrected @ cam_homog2\n",
    "base_xyz_homog = base_homog[:3]*1000      # X, Y, Z (Î≥ëÏßÑ Ìè¨Ìï®)\n",
    "print(f\"Base XYZ (Homogeneous): {base_xyz_homog}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b96e4956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base XYZ (Homogeneous): [     203.16     -28.635     -61.315]\n"
     ]
    }
   ],
   "source": [
    "cam2base_path = f\"{MAIN_DIR}/cam2base_icp_point.json\"\n",
    "with open(cam2base_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "R_cam2base = np.array(data[\"R_cam2base\"])\n",
    "t_cam2base = np.array(data[\"t_cam2base\"]).reshape(3, 1)\n",
    "\n",
    "T_cam2base = np.eye(4)\n",
    "T_cam2base[:3, :3] = R_cam2base\n",
    "T_cam2base[:3, 3] = t_cam2base.flatten()\n",
    "\n",
    "T_camera_to_robot_coord = np.array([\n",
    "    [ 1,  0,  0],\n",
    "    [0,  1,  0],\n",
    "    [ 0, 0,  -1]\n",
    "]) \n",
    "\n",
    "# Î≥¥Ï†ï Ï†ÅÏö©\n",
    "R_corrected = T_camera_to_robot_coord @ R_cam2base\n",
    "t_corrected = T_camera_to_robot_coord @ t_cam2base\n",
    "\n",
    "T_cam2base_corrected = np.eye(4)\n",
    "T_cam2base_corrected[:3, :3] = R_corrected\n",
    "T_cam2base_corrected[:3, 3] = t_corrected.flatten()\n",
    "\n",
    "cam_xyz = np.array(outputs[0][\"cam_xyz\"]).reshape(3, 1)\n",
    "cam_homog = np.append(cam_xyz, 1.0)\n",
    "base_homog =   T_cam2base_corrected @ cam_homog\n",
    "base_xyz_homog = base_homog[:3]*1000      # X, Y, Z (Î≥ëÏßÑ Ìè¨Ìï®)\n",
    "print(f\"Base XYZ (Homogeneous): {base_xyz_homog}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4c0f122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base XYZ (Homogeneous): [      210.1      60.259      -27.35]\n"
     ]
    }
   ],
   "source": [
    "cam2base_path = \"/home/ros/llm_robot/data/Calibration/Eye-to-Hand5/cam2base_icp_point1.json\"\n",
    "with open(cam2base_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "R_cam2base = np.array(data[\"R_cam2base\"])\n",
    "t_cam2base = np.array(data[\"t_cam2base\"]).reshape(3, 1)\n",
    "\n",
    "T_cam2base = np.eye(4)\n",
    "T_cam2base[:3, :3] = R_cam2base\n",
    "T_cam2base[:3, 3] = t_cam2base.flatten()\n",
    "\n",
    "T_camera_to_robot_coord = np.array([\n",
    "    [ 1,  0,  0],\n",
    "    [0,  1,  0],\n",
    "    [ 0, 0,  -1]\n",
    "]) \n",
    "\n",
    "# Î≥¥Ï†ï Ï†ÅÏö©\n",
    "R_corrected = T_camera_to_robot_coord @ R_cam2base\n",
    "t_corrected = T_camera_to_robot_coord @ t_cam2base\n",
    "\n",
    "T_cam2base_corrected = np.eye(4)\n",
    "T_cam2base_corrected[:3, :3] = R_corrected\n",
    "T_cam2base_corrected[:3, 3] = t_corrected.flatten()\n",
    "\n",
    "cam_xyz = np.array(outputs[0][\"cam_xyz\"]).reshape(3, 1)\n",
    "cam_homog = np.append(cam_xyz, 1.0)\n",
    "base_homog =   T_cam2base_corrected @ cam_homog\n",
    "base_xyz_homog = base_homog[:3]*1000      # X, Y, Z (Î≥ëÏßÑ Ìè¨Ìï®)\n",
    "print(f\"Base XYZ (Homogeneous): {base_xyz_homog}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3636b2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3f134286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "def cam2base(cam_xyz, cam2base_path):\n",
    "    with open(cam2base_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    R_cam2base = np.array(data[\"R_cam2base\"]).reshape(3,3)\n",
    "    t_cam2base = np.array(data[\"t_cam2base\"]).reshape(3, 1)\n",
    "\n",
    "    cam_xyz = np.array(cam_xyz).reshape(3, 1)\n",
    "    cam_xyz_h = np.vstack([cam_xyz, [[1]]])  # 4x1 homogeneous vectr\n",
    "    \n",
    "    T_cam2base = np.eye(4)\n",
    "    T_cam2base[:3, :3] = R_cam2base\n",
    "    T_cam2base[:3, 3] = t_cam2base.flatten()\n",
    "\n",
    "    # base_xyz Í≥ÑÏÇ∞\n",
    "    base_xyz_h = T_cam2base @ cam_xyz_h\n",
    "    base_xyz = base_xyz_h[:3].flatten()*1000  # ÏµúÏ¢Ö Ï¢åÌëú (Îã®ÏúÑ: m)\n",
    "    \n",
    "    return base_xyz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e26d2364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.0607), np.float64(0.0354), np.float64(0.517)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0][\"cam_xyz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "15c7dfb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     197.43,      52.929,     -7.5923])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam2base(outputs[0][\"cam_xyz\"], cam2base_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
