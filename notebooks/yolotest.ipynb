{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8da881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os, cv2\n",
    "import json\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"/home/ros/llm_robot\"))\n",
    "from utils.pixel_to_cam_coords import detect_objects\n",
    "from utils.camera import capture_d455_images, load_intrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f203f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymycobot import MyCobot280\n",
    "\n",
    "mc = MyCobot280(\"/dev/ttyACM1\", 115200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fb076615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28, 28, 28, 45, 34, 40]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.get_servo_temps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6e3cf3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([35.8, -62.6, 421.9, -88.32, -1.76, -88.9],\n",
       " [0.87, 2.98, -1.31, 0.0, 0.26, -1.75])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.release_all_servos()\n",
    "input(\"Press Enter to continue...\")\n",
    "mc.power_on()\n",
    "mc.get_coords(), mc.get_angles() #2.9 -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3bc77655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.send_coords([172,-19.43,200,-179,0,0],20,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "69781a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel Real Sense 캡쳐 수행\n",
      "Saved: /home/ros/llm_robot/data/captures/color/2025-08-27_12-27-14.jpg /home/ros/llm_robot/data/captures/depth/2025-08-27_12-27-14.npy\n"
     ]
    }
   ],
   "source": [
    "print(\"Intel Real Sense 캡쳐 수행\")\n",
    "c_path, d_path, intr_path = capture_d455_images()\n",
    "# coords = [81.6, -67.5, 299.4, -171.96, -3.71, -94.06]\n",
    "print(\"Saved:\", c_path, d_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4ea879c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 YOLO 대상 객체: ['cube']\n",
      "\n",
      "image 1/1 /home/ros/llm_robot/data/captures/color/2025-08-27_12-27-14.jpg: 384x640 1 cube, 5.9ms\n",
      "Speed: 0.9ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "📦 추출된 객체 정보\n",
      "cube        z=0.536 m  cam=(0.468, 0.074, 0.536)\n"
     ]
    }
   ],
   "source": [
    "# RGB에서 YOLO로 바운딩 박스 얻기\n",
    "best_model = \"/home/ros/llm_robot/yolo/runs/pose/yolo11n_640_500ep/weights/best.pt\"\n",
    "target_list = [\"cube\"]\n",
    "print(\"🎯 YOLO 대상 객체:\", target_list)\n",
    "\n",
    "# bbox: 바운딩 박스 모서리\n",
    "# pixel_xy: 박스 중앙 픽셀\n",
    "# cam_xyz: 카메라 좌표 (실제 3D위치)\n",
    "camera_matrix, dist_coeffs = load_intrinsics(intr_path)\n",
    "\n",
    "outputs = detect_objects(\n",
    "    c_path=c_path,\n",
    "    d_path=d_path,\n",
    "    target_list=target_list,\n",
    "    camera_matrix=camera_matrix,\n",
    "    dist_coeffs=dist_coeffs,\n",
    "    best_model=best_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54b1315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Optional\n",
    "\n",
    "def get_cam_xyz(x, y, depth_raw, camera_matrix, dist_coeffs, depth_scale=0.001):\n",
    "    \n",
    "    # 깊이값 가져오기 (ROI 주변 평균 사용)\n",
    "    roi_size = 5\n",
    "    y1, y2 = max(0, y - roi_size), min(depth_raw.shape[0], y + roi_size + 1)\n",
    "    x1, x2 = max(0, x - roi_size), min(depth_raw.shape[1], x + roi_size + 1)\n",
    "    \n",
    "    roi = depth_raw[y1:y2, x1:x2]\n",
    "    valid_depths = roi[roi > 0]\n",
    "    \n",
    "    if valid_depths.size == 0:\n",
    "        print(f\"[경고] 점 ({x}, {y})에서 유효한 깊이값을 찾을 수 없습니다.\")\n",
    "        clicked_point = None\n",
    "        return None\n",
    "    \n",
    "    # 깊이값 계산 (중간값 사용)\n",
    "    z_mm = np.median(valid_depths)\n",
    "    z_m = z_mm * depth_scale\n",
    "    \n",
    "    # 카메라 내부 파라미터\n",
    "    # fx = camera_matrix[0, 0]\n",
    "    # fy = camera_matrix[1, 1]\n",
    "    # ppx = camera_matrix[0, 2]\n",
    "    # ppy = camera_matrix[1, 2]\n",
    "    \n",
    "    # 왜곡 보정\n",
    "    pixel = np.array([[[x, y]]], dtype=np.float32)\n",
    "    undistorted = cv2.undistortPoints(pixel, camera_matrix, dist_coeffs)\n",
    "    x_u, y_u = undistorted[0][0]\n",
    "    \n",
    "    # 픽셀 좌표를 카메라 좌표계로 변환\n",
    "    x_cam = x_u * z_m\n",
    "    y_cam = y_u * z_m\n",
    "    z_cam = z_m\n",
    "    \n",
    "    outputs = []\n",
    "    outputs.append(\n",
    "        {\"pixel_xy\": [x_u, y_u],\n",
    "        \"depth_m\": z_m,\n",
    "        \"cam_xyz\": np.round([x_cam, y_cam, z_cam], 3).tolist(),\n",
    "        \"undistroted_xyz\": np.round([x_u, y_u, z_cam], 3).tolist()}\n",
    "    )\n",
    "    # 결과 출력\n",
    "    print(f\"\\n📊 클릭한 점의 카메라 좌표:\")\n",
    "    print(f\"   픽셀 좌표: ({x}, {y})\")\n",
    "    print(f\"   왜곡보정 픽셀: ({x_u:.2f}, {y_u:.2f})\")\n",
    "    print(f\"   깊이: {z_m:.3f} m ({z_mm:.1f} mm)\")\n",
    "    print(f\"   카메라 XYZ: ({x_cam:.3f}, {y_cam:.3f}, {z_cam:.3f}) m\")\n",
    "    \n",
    "    return outputs\n",
    "    \n",
    "\n",
    "def get_clicked_point_cam_xyz(c_path: str, d_path: str, camera_matrix: np.ndarray, \n",
    "                             dist_coeffs: np.ndarray, depth_scale: float = 0.001) -> Optional[List[float]]:\n",
    "    \"\"\"\n",
    "    이미지에서 클릭한 점의 카메라 좌표계 XYZ를 구하는 함수\n",
    "    \n",
    "    Args:\n",
    "        c_path (str): 컬러 이미지 파일 경로\n",
    "        d_path (str): 깊이 이미지 파일 경로 (.npy)\n",
    "        camera_matrix (np.ndarray): 카메라 내부 파라미터 행렬 (3x3)\n",
    "        dist_coeffs (np.ndarray): 왜곡 계수\n",
    "        depth_scale (float): 깊이 스케일 (기본값: 0.001, mm -> m 변환)\n",
    "    \n",
    "    Returns:\n",
    "        Optional[List[float]]: 카메라 좌표계 XYZ [x, y, z] (미터 단위), 클릭하지 않으면 None\n",
    "    \"\"\"\n",
    "    \n",
    "    # 이미지와 깊이 데이터 로드\n",
    "    color_img = cv2.imread(c_path)\n",
    "    if color_img is None:\n",
    "        raise ValueError(f\"이미지를 로드할 수 없습니다: {c_path}\")\n",
    "    \n",
    "    depth_raw = np.load(d_path)\n",
    "    \n",
    "    # 클릭한 점을 저장할 변수\n",
    "    clicked_point = None\n",
    "    \n",
    "    def mouse_callback(event: int, x: int, y: int, flags: int, param) -> None:\n",
    "        \"\"\"마우스 클릭 콜백 함수\"\"\"\n",
    "        nonlocal clicked_point\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            clicked_point = (x, y)\n",
    "            print(f\"클릭한 점: ({x}, {y})\")\n",
    "    \n",
    "    # 윈도우 생성 및 마우스 콜백 설정\n",
    "    window_name = \"Click to get camera XYZ\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.setMouseCallback(window_name, mouse_callback)\n",
    "    \n",
    "    # 이미지 표시\n",
    "    cv2.imshow(window_name, color_img)\n",
    "    print(\"이미지에서 원하는 점을 클릭하세요. ESC를 누르면 종료됩니다.\")\n",
    "    \n",
    "    while True:\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        # ESC 키로 종료\n",
    "        if key == 27:\n",
    "            break\n",
    "        \n",
    "        # 클릭한 점이 있으면 처리\n",
    "        if clicked_point is not None:\n",
    "            x, y = clicked_point\n",
    "            outputs = get_cam_xyz(x, y, depth_raw, camera_matrix, dist_coeffs, depth_scale)\n",
    "            cv2.destroyAllWindows()\n",
    "            return outputs\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    return None\n",
    "\n",
    "def get_cam_xyz_by_input(c_path: str, d_path: str, camera_matrix: np.ndarray, \n",
    "                             dist_coeffs: np.ndarray, depth_scale: float = 0.001) -> Optional[List[float]]:\n",
    "    \n",
    "    color_img = cv2.imread(c_path)\n",
    "    depth_raw = np.load(d_path)\n",
    "    \n",
    "    x = int(input(\"Enter x: \"))\n",
    "    y = int(input(\"Enter y: \"))\n",
    "    \n",
    "    outputs = get_cam_xyz(x, y, depth_raw, camera_matrix, dist_coeffs, depth_scale)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7bcaa29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지에서 원하는 점을 클릭하세요. ESC를 누르면 종료됩니다.\n",
      "클릭한 점: (656, 79)\n",
      "\n",
      "📊 클릭한 점의 카메라 좌표:\n",
      "   픽셀 좌표: (656, 79)\n",
      "   왜곡보정 픽셀: (0.54, -0.40)\n",
      "   깊이: 0.554 m (554.0 mm)\n",
      "   카메라 XYZ: (0.301, -0.220, 0.554) m\n",
      "\n",
      "📊 클릭한 점의 카메라 좌표:\n",
      "   픽셀 좌표: (656, 79)\n",
      "   왜곡보정 픽셀: (0.54, -0.40)\n",
      "   깊이: 0.277 m (554.0 mm)\n",
      "   카메라 XYZ: (0.151, -0.110, 0.277) m\n"
     ]
    }
   ],
   "source": [
    "intr_path2 = \"/home/ros/llm_robot/data/Calibration/Eye-to-Hand11/camera_intrinsics_result.json\"\n",
    "camera_matrix2, dist_coeffs2 = load_intrinsics(intr_path2)\n",
    "\n",
    "intr_path3 = \"/home/ros/Eye-to-Hand/data/camera_calibration3/camera_params.json\"\n",
    "camera_matrix3, dist_coeffs3 = load_intrinsics(intr_path3)\n",
    "\n",
    "outputs = get_clicked_point_cam_xyz(c_path, d_path, camera_matrix, dist_coeffs,0.001)\n",
    "# outputs2 = get_cam_xyz_by_input(c_path, d_path, camera_matrix2, dist_coeffs2,0.001)\n",
    "# outputs3 = get_cam_xyz_by_input(c_path, d_path, camera_matrix3, dist_coeffs3,0.001)\n",
    "outputs3 = get_cam_xyz_by_input(c_path, d_path, camera_matrix, dist_coeffs,0.0005)\n",
    "# outputs4 = get_cam_xyz_by_input(c_path, d_path, camera_matrix, dist_coeffs,0.00085)\n",
    "# outputs5 = get_cam_xyz_by_input(c_path, d_path, camera_matrix, dist_coeffs,0.0008)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5534bd",
   "metadata": {},
   "source": [
    "# Eye-in-Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f14f6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ▶ 오일러각 → 회전행렬\n",
    "def euler_to_rotation_matrix(rx, ry, rz):\n",
    "    Rx = np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, np.cos(rx), -np.sin(rx)],\n",
    "        [0, np.sin(rx), np.cos(rx)]\n",
    "    ])\n",
    "    Ry = np.array([\n",
    "        [np.cos(ry), 0, np.sin(ry)],\n",
    "        [0, 1, 0],\n",
    "        [-np.sin(ry), 0, np.cos(ry)]\n",
    "    ])\n",
    "    Rz = np.array([\n",
    "        [np.cos(rz), -np.sin(rz), 0],\n",
    "        [np.sin(rz), np.cos(rz), 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    return Rz @ Ry @ Rx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "66b61694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     156.08,       294.6,      524.38])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam2ee_path = \"/home/ros/llm_robot/data/Calibration/Eye-to-Hand/cam2ee.json\"\n",
    "cam2ee_path2 = \"/home/ros/llm_robot/notebooks/optimized_cam2ee_RANSAC.json\"\n",
    "with open(cam2ee_path2, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "R_cam2ee = np.array(data[\"R_cam2ee\"])\n",
    "R_ee2cam = np.linalg.inv(R_cam2ee)\n",
    "t_cam2ee = np.array(data[\"t_cam2ee\"]).reshape(3, 1)\n",
    "\n",
    "T_cam2ee = np.eye(4)\n",
    "T_cam2ee[:3, :3] = R_cam2ee\n",
    "T_cam2ee[:3, 3] = t_cam2ee.flatten()\n",
    "T_ee2cam = np.linalg.inv(T_cam2ee) \n",
    "\n",
    "# 현재 로봇 포즈 가져오기 (coords 사용)\n",
    "position = np.array(coords[0:3]).reshape(3, 1) / 1000.0  # mm → m\n",
    "rx, ry, rz = np.radians(coords[3:6])\n",
    "\n",
    "R_base2ee = euler_to_rotation_matrix(rx, ry, rz)\n",
    "\n",
    "# --- Base XYZ 계산 ---\n",
    "# T_base2ee 행렬 구성\n",
    "T_base2ee = np.eye(4)\n",
    "T_base2ee[:3, :3] = R_base2ee\n",
    "T_base2ee[:3, 3] = position.flatten()\n",
    "\n",
    "cam_xyz = np.array(outputs[0][\"cam_xyz\"]).reshape(3, 1)\n",
    "cam_xyz_h = np.vstack([cam_xyz, [[1]]])  # 4x1 homogeneous vectr\n",
    "\n",
    "# base_xyz 계산\n",
    "base_xyz_h = T_base2ee @ T_cam2ee @ cam_xyz_h\n",
    "base_xyz = base_xyz_h[:3].flatten()*1000  # 최종 좌표 (단위: m)\n",
    "\n",
    "R_correction = np.array([\n",
    "    [0, 1, 0],\n",
    "    [1, 0, 0],\n",
    "    [0, 0, -1]\n",
    "])\n",
    "base_xyz_corrected = R_correction @ base_xyz\n",
    "base_xyz_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19be4862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "카메라 기준 위치: [       0.17      -0.051       0.457] (m)\n",
      "로봇 base 기준 위치: [     48.646     -270.92      717.04] (mm)\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/ros/llm_robot/notebooks/optimized_cam2ee_icp_point.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "R_cam2ee = np.array(data[\"R_cam2ee\"])\n",
    "t_cam2ee = np.array(data[\"t_cam2ee\"]).reshape(3, 1)\n",
    "\n",
    "T_cam2ee = np.eye(4)\n",
    "T_cam2ee[:3, :3] = R_cam2ee\n",
    "T_cam2ee[:3, 3] = t_cam2ee.flatten()\n",
    "\n",
    "\n",
    "# ▶ 현재 로봇 포즈 가져오기 (coords 사용)\n",
    "position = np.array(coords[0:3]).reshape(3, 1) / 1000.0  # mm → m\n",
    "rx, ry, rz = np.radians(coords[3:6])\n",
    "\n",
    "R_base2ee = euler_to_rotation_matrix(rx, ry, rz)\n",
    "\n",
    "# ▶ T_base2ee 행렬 구성\n",
    "T_base2ee = np.eye(4)\n",
    "T_base2ee[:3, :3] = R_base2ee\n",
    "T_base2ee[:3, 3] = position.flatten()\n",
    "\n",
    "cam_xyz = np.array(outputs[0][\"cam_xyz\"]).reshape(3, 1)\n",
    "cam_xyz_h = np.vstack([cam_xyz, [[1]]])  # 4x1 homogeneous vectr\n",
    "\n",
    "# ▶ base_xyz 계산\n",
    "base_xyz_h = T_base2ee @ T_cam2ee @ cam_xyz_h\n",
    "base_xyz = base_xyz_h[:3].flatten()*1000  # 최종 좌표 (단위: m)\n",
    "\n",
    "# ▶ 출력\n",
    "print(f\"카메라 기준 위치: {cam_xyz.flatten()} (m)\")\n",
    "print(f\"로봇 base 기준 위치: {base_xyz} (mm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd751eb",
   "metadata": {},
   "source": [
    "# Eye-to-Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "682e5c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = \"/home/ros/llm_robot/data/Calibration/Eye-to-Hand11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8fdb0666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cam2base_correction(cam2base_path, outputs):\n",
    "    with open(cam2base_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    R_cam2base = np.array(data[\"R_cam2base\"]).reshape(3, 3)\n",
    "    t_cam2base = np.array(data[\"t_cam2base\"]).reshape(3, 1)\n",
    "\n",
    "    T_cam2base = np.eye(4)\n",
    "    T_cam2base[:3, :3] = R_cam2base\n",
    "    T_cam2base[:3, 3] = t_cam2base.flatten()\n",
    "    \n",
    "    T_camera_to_robot_coord = np.array([\n",
    "    [ 1,  0,  0],\n",
    "    [0,  1,  0],\n",
    "    [ 0, 0,  1]\n",
    "    ]) \n",
    "\n",
    "    # 보정 적용\n",
    "    R_corrected = T_camera_to_robot_coord @ R_cam2base\n",
    "    t_corrected = T_camera_to_robot_coord @ t_cam2base\n",
    "\n",
    "    T_cam2base_corrected = np.eye(4)\n",
    "    T_cam2base_corrected[:3, :3] = R_corrected\n",
    "    T_cam2base_corrected[:3, 3] = t_corrected.flatten()\n",
    "\n",
    "    cam_xyz = np.array(outputs[0][\"cam_xyz\"]).reshape(3,1)\n",
    "    cam_homog = np.append(cam_xyz, 1.0)\n",
    "    base_homog =   T_cam2base_corrected @ cam_homog\n",
    "    base_xyz_homog = base_homog[:3]*1000      # X, Y, Z (병진 포함)\n",
    "    print(f\"Base XYZ (Homogeneous): {base_xyz_homog}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805a174c",
   "metadata": {},
   "source": [
    "### pure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6240e656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base XYZ (Homogeneous): [    -78.233      242.26       24.05]\n",
      "Base XYZ (Homogeneous): [    -97.643      145.99     -31.751]\n",
      "Base XYZ (Homogeneous): [    -88.533      242.35       21.79]\n",
      "Base XYZ (Homogeneous): [     335.42      113.61     -16.201]\n",
      "Base XYZ (Homogeneous): [     342.61      117.74     -9.2285]\n"
     ]
    }
   ],
   "source": [
    "cam2base_path = f\"{MAIN_DIR}/cam2base_icp_point.json\"\n",
    "cam2base_correction(cam2base_path, outputs)\n",
    "\n",
    "cam2base_path2 = f\"{MAIN_DIR}/cam2base_table_normal_fix.json\"\n",
    "cam2base_correction(cam2base_path2, outputs)\n",
    "# cam2base_correction(cam2base_path, outputs2)\n",
    "# cam2base_correction(cam2base_path, outputs3)\n",
    "\n",
    "cam2base_path3 = f\"{MAIN_DIR}/cam2base_calibrated.json\"\n",
    "cam2base_correction(cam2base_path3, outputs)\n",
    "\n",
    "# cam2base_path4 = f\"{MAIN_DIR}/cam2base_table_normal_fix_ransac2.json\"\n",
    "# cam2base_correction(cam2base_path4, outputs)\n",
    "\n",
    "cam2base_path5 = f\"../data/Calibration/Eye-to-Hand12/cam2base.json\"\n",
    "cam2base_correction(cam2base_path5, outputs)\n",
    "\n",
    "cam2base_path6 = f\"../data/Calibration/Eye-to-Hand12/cam2base_icp_point.json\"\n",
    "cam2base_correction(cam2base_path6, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daaf5b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base XYZ (Homogeneous): [     97.511     -43.467     -15.392]\n",
      "Base XYZ (Homogeneous): [     98.526      -45.42     -15.786]\n",
      "Base XYZ (Homogeneous): [     107.48     -39.441     -14.745]\n"
     ]
    }
   ],
   "source": [
    "cam2base_path2 = f\"{MAIN_DIR}/cam2base_icp.json\"\n",
    "cam2base_correction(cam2base_path2, outputs)\n",
    "cam2base_correction(cam2base_path2, outputs2)\n",
    "cam2base_correction(cam2base_path2, outputs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbf6bb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cam2base_correction(cam2base_path, outputs3)\n",
    "# cam2base_correction(cam2base_path, outputs4)\n",
    "# cam2base_correction(cam2base_path, outputs5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "154e83ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base XYZ (Homogeneous): [     88.931     -77.429       -24.7]\n",
      "Base XYZ (Homogeneous): [     94.053     -81.715      3.2175]\n",
      "Base XYZ (Homogeneous): [     95.202     -84.941      30.093]\n",
      "Base XYZ (Homogeneous): [     97.326     -89.242      57.913]\n",
      "Base XYZ (Homogeneous): [     98.475     -92.468      84.788]\n"
     ]
    }
   ],
   "source": [
    "cam2base_path = f\"{MAIN_DIR}/cam2base_icp_point_refined.json\"\n",
    "cam2base_correction(cam2base_path, outputs)\n",
    "cam2base_correction(cam2base_path, outputs2)\n",
    "cam2base_correction(cam2base_path, outputs3)\n",
    "cam2base_correction(cam2base_path, outputs4)\n",
    "cam2base_correction(cam2base_path, outputs5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3185adae",
   "metadata": {},
   "source": [
    "### ICP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ad49a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base XYZ (Homogeneous): [    -86.776      235.61     -24.686]\n"
     ]
    }
   ],
   "source": [
    "cam2base_path = f\"{MAIN_DIR}/cam2base_icp.json\"\n",
    "with open(cam2base_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "R_cam2base = np.array(data[\"R_cam2base\"])\n",
    "t_cam2base = np.array(data[\"t_cam2base\"]).reshape(3, 1)\n",
    "\n",
    "T_cam2base = np.eye(4)\n",
    "T_cam2base[:3, :3] = R_cam2base\n",
    "T_cam2base[:3, 3] = t_cam2base.flatten()\n",
    "\n",
    "T_camera_to_robot_coord = np.array([\n",
    "    [ 1,  0,  0],\n",
    "    [0,  1,  0],\n",
    "    [ 0, 0,  -1]\n",
    "]) \n",
    "\n",
    "# 보정 적용\n",
    "R_corrected = T_camera_to_robot_coord @ R_cam2base\n",
    "t_corrected = T_camera_to_robot_coord @ t_cam2base\n",
    "\n",
    "T_cam2base_corrected = np.eye(4)\n",
    "T_cam2base_corrected[:3, :3] = R_corrected\n",
    "T_cam2base_corrected[:3, 3] = t_corrected.flatten()\n",
    "\n",
    "cam_xyz = np.array(outputs[0][\"cam_xyz\"]).reshape(3, 1)\n",
    "cam_homog = np.append(cam_xyz, 1.0)\n",
    "base_homog =   T_cam2base_corrected @ cam_homog2\n",
    "base_xyz_homog = base_homog[:3]*1000      # X, Y, Z (병진 포함)\n",
    "print(f\"Base XYZ (Homogeneous): {base_xyz_homog}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b96e4956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base XYZ (Homogeneous): [     203.16     -28.635     -61.315]\n"
     ]
    }
   ],
   "source": [
    "cam2base_path = f\"{MAIN_DIR}/cam2base_icp_point.json\"\n",
    "with open(cam2base_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "R_cam2base = np.array(data[\"R_cam2base\"])\n",
    "t_cam2base = np.array(data[\"t_cam2base\"]).reshape(3, 1)\n",
    "\n",
    "T_cam2base = np.eye(4)\n",
    "T_cam2base[:3, :3] = R_cam2base\n",
    "T_cam2base[:3, 3] = t_cam2base.flatten()\n",
    "\n",
    "T_camera_to_robot_coord = np.array([\n",
    "    [ 1,  0,  0],\n",
    "    [0,  1,  0],\n",
    "    [ 0, 0,  -1]\n",
    "]) \n",
    "\n",
    "# 보정 적용\n",
    "R_corrected = T_camera_to_robot_coord @ R_cam2base\n",
    "t_corrected = T_camera_to_robot_coord @ t_cam2base\n",
    "\n",
    "T_cam2base_corrected = np.eye(4)\n",
    "T_cam2base_corrected[:3, :3] = R_corrected\n",
    "T_cam2base_corrected[:3, 3] = t_corrected.flatten()\n",
    "\n",
    "cam_xyz = np.array(outputs[0][\"cam_xyz\"]).reshape(3, 1)\n",
    "cam_homog = np.append(cam_xyz, 1.0)\n",
    "base_homog =   T_cam2base_corrected @ cam_homog\n",
    "base_xyz_homog = base_homog[:3]*1000      # X, Y, Z (병진 포함)\n",
    "print(f\"Base XYZ (Homogeneous): {base_xyz_homog}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4c0f122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base XYZ (Homogeneous): [      210.1      60.259      -27.35]\n"
     ]
    }
   ],
   "source": [
    "cam2base_path = \"/home/ros/llm_robot/data/Calibration/Eye-to-Hand5/cam2base_icp_point1.json\"\n",
    "with open(cam2base_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "R_cam2base = np.array(data[\"R_cam2base\"])\n",
    "t_cam2base = np.array(data[\"t_cam2base\"]).reshape(3, 1)\n",
    "\n",
    "T_cam2base = np.eye(4)\n",
    "T_cam2base[:3, :3] = R_cam2base\n",
    "T_cam2base[:3, 3] = t_cam2base.flatten()\n",
    "\n",
    "T_camera_to_robot_coord = np.array([\n",
    "    [ 1,  0,  0],\n",
    "    [0,  1,  0],\n",
    "    [ 0, 0,  -1]\n",
    "]) \n",
    "\n",
    "# 보정 적용\n",
    "R_corrected = T_camera_to_robot_coord @ R_cam2base\n",
    "t_corrected = T_camera_to_robot_coord @ t_cam2base\n",
    "\n",
    "T_cam2base_corrected = np.eye(4)\n",
    "T_cam2base_corrected[:3, :3] = R_corrected\n",
    "T_cam2base_corrected[:3, 3] = t_corrected.flatten()\n",
    "\n",
    "cam_xyz = np.array(outputs[0][\"cam_xyz\"]).reshape(3, 1)\n",
    "cam_homog = np.append(cam_xyz, 1.0)\n",
    "base_homog =   T_cam2base_corrected @ cam_homog\n",
    "base_xyz_homog = base_homog[:3]*1000      # X, Y, Z (병진 포함)\n",
    "print(f\"Base XYZ (Homogeneous): {base_xyz_homog}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3636b2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3f134286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "def cam2base(cam_xyz, cam2base_path):\n",
    "    with open(cam2base_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    R_cam2base = np.array(data[\"R_cam2base\"]).reshape(3,3)\n",
    "    t_cam2base = np.array(data[\"t_cam2base\"]).reshape(3, 1)\n",
    "\n",
    "    cam_xyz = np.array(cam_xyz).reshape(3, 1)\n",
    "    cam_xyz_h = np.vstack([cam_xyz, [[1]]])  # 4x1 homogeneous vectr\n",
    "    \n",
    "    T_cam2base = np.eye(4)\n",
    "    T_cam2base[:3, :3] = R_cam2base\n",
    "    T_cam2base[:3, 3] = t_cam2base.flatten()\n",
    "\n",
    "    # base_xyz 계산\n",
    "    base_xyz_h = T_cam2base @ cam_xyz_h\n",
    "    base_xyz = base_xyz_h[:3].flatten()*1000  # 최종 좌표 (단위: m)\n",
    "    \n",
    "    return base_xyz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e26d2364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.0607), np.float64(0.0354), np.float64(0.517)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0][\"cam_xyz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "15c7dfb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     197.43,      52.929,     -7.5923])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam2base(outputs[0][\"cam_xyz\"], cam2base_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
