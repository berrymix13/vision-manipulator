{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a565bfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import json\n",
    "from glob import glob\n",
    "import os\n",
    "import cv2\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e980c770",
   "metadata": {},
   "source": [
    "# Eye-in-Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609b7c5a",
   "metadata": {},
   "source": [
    "## 1. Target PCD용 pcd 정합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad41d4",
   "metadata": {},
   "source": [
    "### (1) 파일변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e2841a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = \"/home/ros/llm_robot/data/Calibration/Eye-to-Hand4\"\n",
    "\n",
    "rgb_paths = glob(f\"{MAIN_PATH}/color/*.jpg\")\n",
    "depth_paths = glob(f\"{MAIN_PATH}/depth/*.npy\")\n",
    "intr_paths = glob(f\"{MAIN_PATH}/intrinsics/*.json\")\n",
    "pose_paths = glob(f\"{MAIN_PATH}/poses/*.json\")\n",
    "cam2ee_path = f\"{MAIN_PATH}/cam2base.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8c8d4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ros/llm_robot/data/Calibration/Eye-to-Hand4/depth/converted_png/20_2025-08-07_19-18-58.png',\n",
       " '/home/ros/llm_robot/data/Calibration/Eye-to-Hand4/depth/converted_png/21_2025-08-07_19-19-24.png',\n",
       " '/home/ros/llm_robot/data/Calibration/Eye-to-Hand4/depth/converted_png/18_2025-08-07_19-18-00.png',\n",
       " '/home/ros/llm_robot/data/Calibration/Eye-to-Hand4/depth/converted_png/02_2025-08-07_19-14-05.png',\n",
       " '/home/ros/llm_robot/data/Calibration/Eye-to-Hand4/depth/converted_png/06_2025-08-07_19-14-48.png']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_npy_dir = f\"{MAIN_PATH}/depth\"\n",
    "output_dir = os.path.join(depth_npy_dir, \"converted_png\")\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "depth_paths = glob(f\"{depth_npy_dir}/*.npy\")\n",
    "converted_files = []\n",
    "for npy_path in depth_paths:\n",
    "    try:\n",
    "        depth = np.load(npy_path).astype(np.uint16)\n",
    "        filename = os.path.splitext(os.path.basename(npy_path))[0] + \".png\"\n",
    "        png_path = os.path.join(output_dir, filename)\n",
    "        cv2.imwrite(png_path, depth)\n",
    "        converted_files.append(png_path)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ {npy_path} 변환 실패: {e}\")\n",
    "\n",
    "converted_files[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed378930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgbd_to_pcd(rgb_path, depth_path, intrinsic_path, depth_scale=1000.0, depth_trunc=1.5):\n",
    "    color_raw = o3d.io.read_image(rgb_path)\n",
    "    depth_raw = o3d.io.read_image(depth_path)\n",
    "\n",
    "    with open(intrinsic_path, \"r\") as f:\n",
    "        intr_data = json.load(f)[\"color_intrinsics\"]\n",
    "        \n",
    "    width = intr_data[\"width\"]\n",
    "    height = intr_data[\"height\"]\n",
    "    fx = intr_data[\"fx\"]\n",
    "    fy = intr_data[\"fy\"]\n",
    "    cx = intr_data[\"ppx\"]\n",
    "    cy = intr_data[\"ppy\"]\n",
    "        \n",
    "    intrinsic = o3d.camera.PinholeCameraIntrinsic(\n",
    "        width=width, height=height, fx=fx, fy=fy, cx=cx, cy=cy\n",
    "    )\n",
    "\n",
    "    rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        color_raw, depth_raw,\n",
    "        depth_scale=depth_scale,\n",
    "        depth_trunc=depth_trunc,\n",
    "        convert_rgb_to_intensity=False\n",
    "    )\n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd, intrinsic)\n",
    "    return pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b36b82a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "848"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(intr_paths[0], \"r\") as f:\n",
    "    intr_data = json.load(f)\n",
    "    \n",
    "intr_data[\"color_intrinsics\"][\"width\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b480d58e",
   "metadata": {},
   "source": [
    "### (2) 여러 프레임을 T_cam2base로 정렬하여 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7307577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pcds_with_transforms(pcd_list, transform_list):\n",
    "    merged = o3d.geometry.PointCloud()\n",
    "    for pcd, T in zip(pcd_list, transform_list):\n",
    "        pcd_transformed = pcd.transform(T)\n",
    "        merged += pcd_transformed\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fb5b06",
   "metadata": {},
   "source": [
    "### (3) T_cam2base 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae0a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cam2ee_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "R_cam2base = np.array(data[\"R_cam2base\"])\n",
    "t_cam2base = np.array(data[\"t_cam2base\"]).reshape(3, 1)\n",
    "\n",
    "T_cam2base = np.eye(4)\n",
    "T_cam2base[:3, :3] = R_cam2base\n",
    "T_cam2base[:3, 3] = t_cam2base.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ec47991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_to_transform(pose_file):\n",
    "    with open(pose_file, \"r\") as f:\n",
    "        pose = json.load(f)\n",
    "    R_base2ee = np.array(pose[\"R_base2ee\"])\n",
    "    t_base2ee = np.array(pose[\"t_base2ee\"]).reshape(3, 1)\n",
    "    T_base2ee = np.eye(4)\n",
    "    T_base2ee[:3, :3] = R_base2ee\n",
    "    T_base2ee[:3, 3] = t_base2ee.flatten()\n",
    "    return T_base2ee @ T_cam2ee  # T_cam2base = T_base2ee * T_cam2ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c3b9b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed to load /home/ros/llm_robot/data/Calibration/Eye-to-Hand2/color/2025-08-07_15-49-07.jpg: name 'T_cam2ee' is not defined\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'❌ 변환 가능한 PCD가 없습니다.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcds = []\n",
    "T_list = []\n",
    "for rgb, depth, intr, pose in zip(rgb_paths, converted_files, intr_paths, pose_paths):\n",
    "    try:\n",
    "        pcd = rgbd_to_pcd(rgb, depth, intr)\n",
    "        T = pose_to_transform(pose)\n",
    "        pcds.append(pcd)\n",
    "        T_list.append(T)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load {rgb}: {e}\")\n",
    "\n",
    "if pcds:\n",
    "    try:\n",
    "        merged_pcd = merge_pcds_with_transforms(pcds, T_list)\n",
    "        save_path = \"./merged_target_pcd.ply\"\n",
    "        o3d.io.write_point_cloud(save_path, merged_pcd)\n",
    "        result = f\"✅ 평균 기준 PCD 저장 완료: {save_path}\"\n",
    "    except Exception as e:\n",
    "        result = f\"❌ 평균 기준 PCD 저장 실패: {e}\"\n",
    "else:\n",
    "    result = \"❌ 변환 가능한 PCD가 없습니다.\"\n",
    "    \n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb86da5",
   "metadata": {},
   "source": [
    "## 2. 관찰 PC 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "985fbfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd = rgbd_to_pcd(rgb_paths[0], converted_files[0], intr_paths[0])\n",
    "o3d.io.write_point_cloud(\"./camera_observed.ply\", pcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609e8a90",
   "metadata": {},
   "source": [
    "## 3. ICP 최적화 (Point-to-Point ICP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf3b963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Eye in Hand #####\n",
    "# === 초기 Tsai-Lenz 기반 ee2cam 변환행렬 불러오기 ===\n",
    "T_ee2cam = np.eye(4)\n",
    "T_ee2cam[:3, :3] = R_ee2cam  # Tsai-Lenz 결과\n",
    "T_ee2cam[:3, 3] = t_ee2cam.flatten()\n",
    "\n",
    "# === PCD 불러오기 ===\n",
    "source_pcd = o3d.io.read_point_cloud(\"camera_observed.ply\")  # EE 위치에서 관측한 것\n",
    "target_pcd = o3d.io.read_point_cloud(\"merged_target_pcd.ply\")  # 기준 Target\n",
    "\n",
    "# === 초기 정렬 적용 ===\n",
    "source_pcd.transform(T_ee2cam)\n",
    "\n",
    "# === ICP 보정 ===\n",
    "threshold = 0.01  # 1cm 허용 오차\n",
    "icp_result = o3d.pipelines.registration.registration_icp(\n",
    "    source_pcd, target_pcd,\n",
    "    threshold,\n",
    "    np.eye(4),\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    ")\n",
    "\n",
    "# === 최종 보정 행렬 ===\n",
    "T_icp = icp_result.transformation\n",
    "T_ee2cam_refined = T_icp @ T_ee2cam\n",
    "\n",
    "# === 최종 R, t 추출 ===\n",
    "R_final = T_ee2cam_refined[:3, :3]\n",
    "t_final = T_ee2cam_refined[:3, 3].reshape(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4543d73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\n",
    "    \"R_cam2ee\": R_final.tolist(),\n",
    "    \"t_cam2ee\": t_final.flatten().tolist()  # 1D 리스트로 저장\n",
    "}\n",
    "\n",
    "# 저장\n",
    "with open(\"optimized_cam2ee_icp_point.json\", \"w\") as f:\n",
    "    json.dump(result, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c379475",
   "metadata": {},
   "source": [
    "## 4.Point-to-Plane ICP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c935a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ICP fitness: 0.0\n",
      "✅ ICP inlier RMSE: 0.0\n",
      "✅ 보정 행렬 (delta T):\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# === 정규 벡터 추정 (PointToPlane ICP requires this)\n",
    "source_pcd.estimate_normals(\n",
    "    search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.02, max_nn=30)\n",
    ")\n",
    "target_pcd.estimate_normals(\n",
    "    search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.02, max_nn=30)\n",
    ")\n",
    "\n",
    "# === ICP 실행 ===\n",
    "threshold = 0.01  # 1cm\n",
    "icp_result = o3d.pipelines.registration.registration_icp(\n",
    "    source_pcd, target_pcd,\n",
    "    threshold,\n",
    "    np.eye(4),  # 이미 정렬했기 때문에 초기값은 identity\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    ")\n",
    "\n",
    "# === 결과 확인 ===\n",
    "print(\"✅ ICP fitness:\", icp_result.fitness)\n",
    "print(\"✅ ICP inlier RMSE:\", icp_result.inlier_rmse)\n",
    "print(\"✅ 보정 행렬 (delta T):\")\n",
    "print(icp_result.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fcb48545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: optimized_cam2ee_icp_plane.json\n"
     ]
    }
   ],
   "source": [
    "# === 최종 보정된 cam2ee = ΔT × 기존 T_cam2ee\n",
    "T_refined = T_cam2ee @ icp_result.transformation \n",
    "R_final = T_refined[:3, :3]\n",
    "t_final = T_refined[:3, 3].reshape(3, 1)\n",
    "\n",
    "# === JSON 저장\n",
    "result = {\n",
    "    \"R_cam2ee\": R_final.tolist(),\n",
    "    \"t_cam2ee\": t_final.flatten().tolist()\n",
    "}\n",
    "with open(\"optimized_cam2ee_icp_plane.json\", \"w\") as f:\n",
    "    json.dump(result, f, indent=2)\n",
    "print(\"✅ 저장 완료: optimized_cam2ee_icp_plane.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e27fb74",
   "metadata": {},
   "source": [
    "### 번외. PCD 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47eaf232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_ply(filepath):\n",
    "    \"\"\"\n",
    "    단일 PLY 파일을 시각화하는 함수\n",
    "    \"\"\"\n",
    "    pcd = o3d.io.read_point_cloud(filepath)\n",
    "    print(f\"Loaded point cloud: {pcd}\")\n",
    "    o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "def animate_ply_sequence(directory, num_frames, basename=\"frame\", ext=\".ply\", delay=0.1):\n",
    "    \"\"\"\n",
    "    연속된 ply 파일 시퀀스를 애니메이션으로 시각화하는 함수.\n",
    "    예: frame0000.ply, frame0001.ply, ...\n",
    "    - directory: 파일 경로\n",
    "    - num_frames: 총 프레임 수\n",
    "    - basename: 파일명 기준 이름\n",
    "    - ext: 확장자\n",
    "    - delay: 프레임 간 대기 시간 (초)\n",
    "    \"\"\"\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "    geometry = o3d.geometry.PointCloud()\n",
    "    vis.add_geometry(geometry)\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        filename = f\"{directory}/{basename}{i:04d}{ext}\"\n",
    "        pcd = o3d.io.read_point_cloud(filename)\n",
    "        geometry.points = pcd.points\n",
    "        if pcd.has_colors():\n",
    "            geometry.colors = pcd.colors\n",
    "        vis.update_geometry(geometry)\n",
    "        vis.poll_events()\n",
    "        vis.update_renderer()\n",
    "        o3d.utility.sleep(delay)\n",
    "\n",
    "    vis.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb90942e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded point cloud: PointCloud with 5462791 points.\n"
     ]
    }
   ],
   "source": [
    "visualize_ply(\"/home/ros/llm_robot/data/Calibration/Eye-in-Hand2/merged_target_pcd.ply\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74b93a2",
   "metadata": {},
   "source": [
    "# Eye-to-Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe1169a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = \"/home/ros/llm_robot/data/Calibration/Eye-to-Hand12\"\n",
    "\n",
    "rgb_paths = glob(f\"{MAIN_PATH}/color/*.jpg\")\n",
    "depth_paths = glob(f\"{MAIN_PATH}/depth/*.npy\")\n",
    "intr_paths = glob(f\"{MAIN_PATH}/intrinsics/*.json\")\n",
    "pose_paths = glob(f\"{MAIN_PATH}/poses/*.json\")\n",
    "charuco_files = sorted(Path(MAIN_PATH).glob(\"*.json\"))[:25]\n",
    "\n",
    "cam2ee_path = f\"{MAIN_PATH}/cam2base.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d78c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ros/llm_robot/data/Calibration/Eye-to-Hand12/depth/converted_png/20_2025-08-27_12-19-31.png',\n",
       " '/home/ros/llm_robot/data/Calibration/Eye-to-Hand12/depth/converted_png/23_2025-08-27_12-20-04.png',\n",
       " '/home/ros/llm_robot/data/Calibration/Eye-to-Hand12/depth/converted_png/12_2025-08-27_12-17-44.png',\n",
       " '/home/ros/llm_robot/data/Calibration/Eye-to-Hand12/depth/converted_png/18_2025-08-27_12-19-15.png',\n",
       " '/home/ros/llm_robot/data/Calibration/Eye-to-Hand12/depth/converted_png/02_2025-08-27_12-15-58.png']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_npy_dir = f\"{MAIN_PATH}/depth\"\n",
    "output_dir = os.path.join(depth_npy_dir, \"converted_png\")\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "depth_paths = glob(f\"{depth_npy_dir}/*.npy\")\n",
    "converted_files = []\n",
    "for npy_path in depth_paths:\n",
    "    try:\n",
    "        depth = np.load(npy_path).astype(np.uint16)\n",
    "        filename = os.path.splitext(os.path.basename(npy_path))[0] + \".png\"\n",
    "        png_path = os.path.join(output_dir, filename)\n",
    "        cv2.imwrite(png_path, depth)\n",
    "        converted_files.append(png_path)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ {npy_path} 변환 실패: {e}\")\n",
    "\n",
    "converted_files[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a196c4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgbd_to_pcd(rgb_path, depth_path, intrinsic_path, depth_scale=1000.0, depth_trunc=1.5):\n",
    "    color_raw = o3d.io.read_image(rgb_path)\n",
    "    depth_raw = o3d.io.read_image(depth_path)\n",
    "    # depth_raw = np.load(depth_path)\n",
    "\n",
    "    with open(intrinsic_path, \"r\") as f:\n",
    "        intr_data = json.load(f)[\"color_intrinsics\"]\n",
    "        \n",
    "    width = intr_data[\"width\"]\n",
    "    height = intr_data[\"height\"]\n",
    "    fx = intr_data[\"fx\"]\n",
    "    fy = intr_data[\"fy\"]\n",
    "    cx = intr_data[\"ppx\"]\n",
    "    cy = intr_data[\"ppy\"]\n",
    "        \n",
    "    intrinsic = o3d.camera.PinholeCameraIntrinsic(\n",
    "        width=width, height=height, fx=fx, fy=fy, cx=cx, cy=cy\n",
    "    )\n",
    "\n",
    "    rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        color_raw, depth_raw,\n",
    "        depth_scale=depth_scale,\n",
    "        depth_trunc=depth_trunc,\n",
    "        convert_rgb_to_intensity=False\n",
    "    )\n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd, intrinsic)\n",
    "    return pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0034107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pcds_with_transforms(pcd_list, transform_list):\n",
    "    merged = o3d.geometry.PointCloud()\n",
    "    for pcd, T in zip(pcd_list, transform_list):\n",
    "        pcd_transformed = pcd.transform(T)\n",
    "        merged += pcd_transformed\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ede7a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cam2ee_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "R_cam2base = np.array(data[\"R_cam2base\"])\n",
    "t_cam2base = np.array(data[\"t_cam2base\"]).reshape(3, 1)\n",
    "\n",
    "T_cam2base = np.eye(4)\n",
    "T_cam2base[:3, :3] = R_cam2base\n",
    "T_cam2base[:3, 3] = t_cam2base.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "346ec904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_pcd = o3d.geometry.PointCloud()\n",
    "T_target_in_base =[]\n",
    "for i, (pose_path, charuco_path) in enumerate(zip(pose_paths, charuco_files)):\n",
    "    with open(pose_path, \"r\") as f1, open(charuco_path, \"r\") as f2:\n",
    "        pose = json.load(f1)\n",
    "        charuco = json.load(f2)\n",
    "        \n",
    "    # === 보드의 T_cam2target 변환행렬\n",
    "    rvec = np.array(charuco[\"rvec_target2cam\"]).reshape(3)\n",
    "    tvec = np.array(charuco[\"tvec_target2cam\"]).reshape(3, 1)\n",
    "    R = o3d.geometry.get_rotation_matrix_from_axis_angle(rvec)\n",
    "    T_cam2target = np.eye(4)\n",
    "    T_cam2target[:3, :3] = R\n",
    "    T_cam2target[:3, 3] = tvec.flatten()\n",
    "    \n",
    "    # === 로봇의 T_base2ee\n",
    "    R_base2ee = np.array(pose[\"R_base2ee\"])\n",
    "    t_base2ee = np.array(pose[\"t_base2ee\"]).reshape(3, 1)\n",
    "    T_base2ee = np.eye(4)\n",
    "    T_base2ee[:3, :3] = R_base2ee\n",
    "    T_base2ee[:3, 3] = t_base2ee.flatten()\n",
    "    \n",
    "    # === 보드의 base 기준 위치 계산\n",
    "    T_target2cam = np.linalg.inv(T_cam2target)\n",
    "    T_base2target = T_base2ee @ np.eye(4)  # T_ee2target이 없으므로 단위행렬\n",
    "\n",
    "    T_target_in_base.append(T_base2target @ T_cam2base @ T_target2cam)\n",
    "\n",
    "len(T_target_in_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8896dc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 평균 기준 PCD 저장 완료: /home/ros/llm_robot/data/Calibration/Eye-to-Hand12/camera_observed.ply\n"
     ]
    }
   ],
   "source": [
    "pcds = []\n",
    "merged = o3d.geometry.PointCloud()\n",
    "for rgb, depth, intr, T in zip(rgb_paths[:10], converted_files[:10], intr_paths[:10], T_target_in_base[:10]):\n",
    "    \n",
    "    pcd = rgbd_to_pcd(rgb, depth, intr)\n",
    "    pcd_transformed = pcd.transform(T)\n",
    "    merged += pcd_transformed\n",
    "\n",
    "save_path = f\"{MAIN_PATH}/camera_observed.ply\"\n",
    "o3d.io.write_point_cloud(save_path, merged)\n",
    "print(f\"✅ 평균 기준 PCD 저장 완료: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a4868c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 평균 기준 PCD 저장 완료: /home/ros/llm_robot/data/Calibration/Eye-to-Hand12/merged_target_pcd.ply\n"
     ]
    }
   ],
   "source": [
    "pcds = []\n",
    "merged = o3d.geometry.PointCloud()\n",
    "for rgb, depth, intr, T in zip(rgb_paths[10:], converted_files[10:], intr_paths[10:], T_target_in_base[10:]):\n",
    "    \n",
    "    pcd = rgbd_to_pcd(rgb, depth, intr)\n",
    "    pcd_transformed = pcd.transform(T)\n",
    "    merged += pcd_transformed\n",
    "\n",
    "save_path = f\"{MAIN_PATH}/merged_target_pcd.ply\"\n",
    "o3d.io.write_point_cloud(save_path, merged)\n",
    "print(f\"✅ 평균 기준 PCD 저장 완료: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc4bbdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 R_cam2base:\n",
      "[[ 0.99865734  0.03501759  0.03817444]\n",
      " [ 0.03408911 -0.99911334  0.02470781]\n",
      " [ 0.0390058  -0.0233733  -0.99896558]]\n",
      "최종 t_cam2base:\n",
      "[[ 0.0285736 ]\n",
      " [-0.12601269]\n",
      " [ 0.52731557]]\n"
     ]
    }
   ],
   "source": [
    "# === PCD 불러오기 ===\n",
    "source_pcd = o3d.io.read_point_cloud(f\"{MAIN_PATH}/camera_observed.ply\")  # 카메라 좌표계\n",
    "target_pcd = o3d.io.read_point_cloud(f\"{MAIN_PATH}/merged_target_pcd.ply\")  # base 기준 기준 모델\n",
    "\n",
    "# === 초기 정렬 적용: 카메라 좌표계 → base 좌표계\n",
    "z_mean = np.mean(np.asarray(source_pcd.points)[:, 2])\n",
    "source_pcd.translate((0, 0, -z_mean))\n",
    "source_pcd.transform(T_cam2base)\n",
    "\n",
    "source_pcd = source_pcd.select_by_index(\n",
    "    np.where(np.asarray(source_pcd.points)[:, 2] < 1.0)[0]\n",
    ")\n",
    "\n",
    "# === ICP 정합\n",
    "threshold = 0.01  # 허용 거리 (m)\n",
    "icp_result = o3d.pipelines.registration.registration_icp(\n",
    "    source_pcd, target_pcd,\n",
    "    threshold,\n",
    "    np.eye(4),\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    ")\n",
    "\n",
    "# === 보정된 행렬\n",
    "T_icp = icp_result.transformation\n",
    "T_cam2base_refined = T_icp @ T_cam2base\n",
    "\n",
    "# === 최종 R, t 추출\n",
    "R_final = T_cam2base_refined[:3, :3]\n",
    "t_final = T_cam2base_refined[:3, 3].reshape(3, 1)\n",
    "\n",
    "print(\"최종 R_cam2base:\")\n",
    "print(R_final)\n",
    "print(\"최종 t_cam2base:\")\n",
    "print(t_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2e97416",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\n",
    "    \"R_cam2base\": R_final.tolist(),\n",
    "    \"t_cam2base\": t_final.flatten().tolist()  # 1D 리스트로 저장\n",
    "}\n",
    "\n",
    "# 저장\n",
    "with open(f\"{MAIN_PATH}/cam2base_icp_point.json\", \"w\") as f:\n",
    "    json.dump(result, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa39b797",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# === ICP 정합\u001b[39;00m\n\u001b[1;32m     17\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m  \u001b[38;5;66;03m# 허용 거리 (m)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m icp_result \u001b[38;5;241m=\u001b[39m \u001b[43mo3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipelines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistration_icp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_pcd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_pcd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 이미 source_pcd는 transform된 상태이므로 초기값은 단위행렬\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mo3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipelines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTransformationEstimationPointToPlane\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# === 보정된 행렬\u001b[39;00m\n\u001b[1;32m     26\u001b[0m T_icp \u001b[38;5;241m=\u001b[39m icp_result\u001b[38;5;241m.\u001b[39mtransformation\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# === PCD 불러오기 ===\n",
    "source_pcd = o3d.io.read_point_cloud(f\"{MAIN_PATH}/camera_observed.ply\")\n",
    "target_pcd = o3d.io.read_point_cloud(f\"{MAIN_PATH}/merged_target_pcd.ply\")\n",
    "\n",
    "# === source는 이미 transform 된 상태\n",
    "source_pcd.transform(T_cam2base)\n",
    "\n",
    "# ✅ target에도 노말 계산 추가!\n",
    "target_pcd.estimate_normals(\n",
    "    search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.02, max_nn=30)\n",
    ")\n",
    "\n",
    "# === 초기 정렬 적용: 카메라 좌표계 → base 좌표계\n",
    "source_pcd.transform(T_cam2base)\n",
    "\n",
    "# === ICP 정합\n",
    "threshold = 0.01  # 허용 거리 (m)\n",
    "icp_result = o3d.pipelines.registration.registration_icp(\n",
    "    source_pcd, target_pcd,\n",
    "    threshold,\n",
    "    np.eye(4),  # 이미 source_pcd는 transform된 상태이므로 초기값은 단위행렬\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    ")\n",
    "\n",
    "# === 보정된 행렬\n",
    "T_icp = icp_result.transformation\n",
    "T_cam2base_refined = T_icp @ T_cam2base @ T_cam2base\n",
    "\n",
    "# === 최종 R, t 추출\n",
    "R_final = T_cam2base_refined[:3, :3]\n",
    "t_final = T_cam2base_refined[:3, 3].reshape(3, 1)\n",
    "\n",
    "print(\"최종 R_cam2base:\")\n",
    "print(R_final)\n",
    "print(\"최종 t_cam2base:\")\n",
    "print(t_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82df5a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\n",
    "    \"R_cam2base\": R_final.tolist(),\n",
    "    \"t_cam2base\": t_final.flatten().tolist()  # 1D 리스트로 저장\n",
    "}\n",
    "\n",
    "# 저장\n",
    "with open(f\"{MAIN_PATH}/cam2base2_icp_plane.json\", \"w\") as f:\n",
    "    json.dump(result, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f65da57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_pcd.paint_uniform_color([1, 0, 0])  # 빨강\n",
    "target_pcd.paint_uniform_color([0, 1, 0])  # 초록\n",
    "\n",
    "o3d.visualization.draw_geometries([source_pcd, target_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb0b048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
